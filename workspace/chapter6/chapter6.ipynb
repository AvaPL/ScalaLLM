{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73e9304-0b46-4a79-81f5-af4e977bf44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $file.^.Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87b69a7-66f9-475b-9cf1-b8e88f67ec29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mzipName\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"sms+spam+collection.zip\"\u001b[39m\n",
       "\u001b[36mdatasetUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\u001b[39m\n",
       "\u001b[36moutputDir\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/sms-spam-raw\"\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val zipName = \"sms+spam+collection.zip\"\n",
    "val datasetUrl = s\"https://archive.ics.uci.edu/static/public/228/$zipName\"\n",
    "val outputDir = \"data/sms-spam-raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048673b9-9ae6-4d7c-8d60-60a1a383f667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  198k    0  198k    0     0   153k      0 --:--:--  0:00:01 --:--:--  153k\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"curl\", \"--create-dirs\", \"-O\", \"--output-dir\", outputDir, datasetUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fdc00a5-7737-4164-90b6-7914a4332ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/sms-spam-raw/sms+spam+collection.zip\n",
      "  inflating: data/sms-spam-raw/SMSSpamCollection  \n",
      "  inflating: data/sms-spam-raw/readme  \n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"unzip\", \"-o\", s\"$outputDir/$zipName\", \"-d\", outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28347282-363e-45e5-93c9-4385a6631506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam count: 747\n",
      "Not spam count: 4827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\u001b[39m\n",
       "\u001b[36mdatasetRaw\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
       "ham\tOk lar... Joking wif u oni...\n",
       "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
       "ham\tU dun say so early hor... U c already then say...\n",
       "ham\tNah I don't think he goes to usf, he lives around here though\n",
       "spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
       "ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
       "ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
       "spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
       "spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
       "ham\tI'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
       "spam\tSIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
       "spam\tURGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
       "ham\tI've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
       "ham\tI HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "spam\tXXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL\n",
       "ham\tOh k...i'm watching here:)\n",
       "ham\tEh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.\n",
       "ham\tFine if thats the way u feel. Thats the way its gota b\n",
       "spam\tEngland v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+\n",
       "ham\tIs that seriously how you spell his name?\n",
       "ham\tI‘m going to try for 2 months ha ha only joking\n",
       "\u001b[39m...\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mSmsSpamRecord\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mDataset\u001b[39m\n",
       "\u001b[36msmsSpamRecords\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Ok lar... Joking wif u oni...\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"U dun say so early hor... U c already then say...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Nah I don't think he goes to usf, he lives around here though\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Even my brother is not like to speak with me. They treat me like aids patent.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "...\n",
       "\u001b[36mspamRecords\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mSmsSpamRecord\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCB\u001b[39m...\n",
       "\u001b[36mnotSpamRecords\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mSmsSpamRecord\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Ok lar... Joking wif u oni...\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"U dun say so early hor... U c already then say...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Nah I don't think he goes to usf, he lives around here though\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Even my brother is not like to speak with me. They treat me like aids patent.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"I HAVE A DATE ON SUNDAY WITH WILL!!\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Oh k...i'm watching here:)\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.io.Source\n",
    "\n",
    "val datasetRaw = Source.fromFile(s\"$outputDir/SMSSpamCollection\").mkString\n",
    "\n",
    "case class SmsSpamRecord(\n",
    "  text: String,\n",
    "  isSpam: Boolean\n",
    ")\n",
    "\n",
    "type Dataset = Vector[SmsSpamRecord]\n",
    "\n",
    "val smsSpamRecords: Dataset = datasetRaw.split(\"\\n\").map {\n",
    "  case s\"spam\\t$text\" => SmsSpamRecord(text, isSpam = true)\n",
    "  case s\"ham\\t$text\" => SmsSpamRecord(text, isSpam = false)\n",
    "}.toVector\n",
    "\n",
    "val (spamRecords, notSpamRecords) = smsSpamRecords.partition(_.isSpam)\n",
    "println(s\"Spam count: ${spamRecords.size}\")\n",
    "println(s\"Not spam count: ${notSpamRecords.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e244291-9733-4821-a534-f6cd331a4ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\u001b[39m\n",
       "\u001b[36mbalancedDataset\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCB\u001b[39m..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable\n",
    "import scala.util.Random\n",
    "\n",
    "val balancedDataset: Dataset = {\n",
    "\n",
    "  def sample(records: Vector[SmsSpamRecord], targetSize: Int): Vector[SmsSpamRecord] = {\n",
    "    val balancedDatasetSpam = mutable.Map[String, SmsSpamRecord]()\n",
    "    while (balancedDatasetSpam.size < targetSize) {\n",
    "      val randomRecord = records(Random.nextInt(records.size))\n",
    "      if (!balancedDatasetSpam.contains(randomRecord.text))\n",
    "        balancedDatasetSpam += randomRecord.text -> randomRecord\n",
    "    }\n",
    "    balancedDatasetSpam.values.toVector\n",
    "  }\n",
    "\n",
    "  if (spamRecords.size < notSpamRecords.size)\n",
    "    spamRecords ++ sample(notSpamRecords, targetSize = spamRecords.size)\n",
    "  else\n",
    "    notSpamRecords ++ sample(spamRecords, targetSize = notSpamRecords.size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba96609-d9fa-440e-9556-b3d0f3b104d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mTraining\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mValidation\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mTest\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mrandomSplit\u001b[39m\n",
       "\u001b[36mtraining\u001b[39m: \u001b[32mTraining\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Ur HMV Quiz cash-balance is currently £500 - to maximize ur cash-in now send HMV1 to 86688 only 150p/msg\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Went fast asleep dear.take care.\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Dear Subscriber ur draw 4 £100 gift voucher will b entered on receipt of a correct ans. When was Elvis Presleys Birthday? TXT answer to 80062\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"No shit, but I wasn't that surprised, so I went and spent the evening with that french guy I met in town here and we fooled around a bit but I didn't let him fuck me\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Someone U know has asked our dating service 2 contact you! Cant Guess who? CALL 09058097189 NOW all will be revealed. POBox 6, LS15HB 150p \"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"I wait 4 ü inside da car park...\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Do you want 750 anytime any network mins 150 text and a NEW video phone for only five pounds per week call 08000776320 now or reply for delivery Tomorrow\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT. Important information for 02 user. Today is your lucky day! 2 find out why , log onto http://www.urawinner.com there is a fantastic surprise awaiting you !\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"R U &SAM P IN EACHOTHER. IF WE MEET WE CAN GO 2 MY HOUSE\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "...\n",
       "\u001b[36mvalidation\u001b[39m: \u001b[32mValidation\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Dear Voucher Holder 2 claim your 1st class airport lounge passes when using Your holiday voucher call 08704439680. When booking quote 1st class x 2\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"okmail: Dear Dave this is your final notice to collect your 4* Tenerife Holiday or #5000 CASH award! Call 09061743806 from landline. TCs SAE Box326 CW25WX 150ppm\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FREE for 1st week! No1 Nokia tone 4 ur mobile every week just txt NOKIA to 8077 Get txting and tell ur mates. www.getzed.co.uk POBox 36504 W45WQ 16+ norm150p/tone\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Had your mobile 10 mths? Update to latest Orange camera/video phones for FREE. Save £s with Free texts/weekend calls. Text YES for a callback orno to opt out\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Howz pain?hope u r fine..\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Oh, my love, it's soooo good to hear from you. Omg I missed you so much today. I'm sorry your having problems with the provider but thank you for tming me\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Teach me apps da. When you come to college.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Thk some of em find wtc too far... Weiyi not goin... E rest i dunno yet... R ur goin 4 dinner den i might b able to join...\"\u001b[39m,\n",
       "...\n",
       "\u001b[36mtest\u001b[39m: \u001b[32mTest\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Morning only i can ok.\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"4mths half price Orange line rental & latest camera phones 4 FREE. Had your phone 11mths ? Call MobilesDirect free on 08000938767 to update now! or2stoptxt\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"This is the 2nd time we have tried to contact u. U have won the £400 prize. 2 claim is easy, just call 087104711148 NOW! Only 10p per minute. BT-national-rate\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I'm in inside office..still filling forms.don know when they leave me.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Hello. We need some posh birds and chaps to user trial prods for champneys. Can i put you down? I need your address and dob asap. Ta r\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"INTERFLORA - It's not too late to order Interflora flowers for christmas call 0800 505060 to place your order before Midnight tomorrow.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Oh k...i'm watching here:)\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"HMV BONUS SPECIAL 500 pounds of genuine HMV vouchers to be won. Just answer 4 easy questions. Play Now! Send HMV to 86688 More info:www.100percent-real.com\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"For taking part in our mobile survey yesterday! You can now have 500 texts 2 use however you wish. 2 get txts just send TXT to 80160 T&C www.txt43.c\u001b[39m..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Training = Dataset\n",
    "type Validation = Dataset\n",
    "type Test = Dataset\n",
    "\n",
    "def randomSplit(dataset: Vector[SmsSpamRecord], trainingFraction: Double, validationFraction: Double): (Training, Validation, Test) = {\n",
    "  val shuffledDataset = Random.shuffle(dataset)\n",
    "  val trainingSize = (shuffledDataset.size * trainingFraction).floor.toInt\n",
    "  val validationSize = (shuffledDataset.size * validationFraction).floor.toInt\n",
    "\n",
    "  val (training, remainingRecords) = shuffledDataset.splitAt(trainingSize)\n",
    "  val (validation, test) = remainingRecords.splitAt(validationSize)\n",
    "  (training, validation, test)\n",
    "}\n",
    "\n",
    "val (training, validation, test) = randomSplit(balancedDataset, trainingFraction = 0.7, validationFraction = 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c33bb0b-ea20-4a02-8606-a28dab16f9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Using\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.github.tototoshi.csv.CSVWriter\u001b[39m\n",
       "\u001b[36mtextHeader\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Text\"\u001b[39m\n",
       "\u001b[36mlabelHeader\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Label\"\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mwriteToCsv\u001b[39m\n",
       "\u001b[36mtrainingCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/training.csv\"\u001b[39m\n",
       "\u001b[36mvalidationCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/validation.csv\"\u001b[39m\n",
       "\u001b[36mtestCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/test.csv\"\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.github.tototoshi::scala-csv:2.0.0`\n",
    "\n",
    "import scala.util.Using\n",
    "import com.github.tototoshi.csv.CSVWriter\n",
    "\n",
    "val textHeader = \"Text\"\n",
    "val labelHeader = \"Label\"\n",
    "\n",
    "def writeToCsv(path: String, dataset: Dataset): Unit = {\n",
    "  val headers = Vector(textHeader, labelHeader)\n",
    "\n",
    "  Using.resource(CSVWriter.open(path)) { writer =>\n",
    "    val rows = dataset.map {\n",
    "      case SmsSpamRecord(text, isSpam) => Vector(text, if (isSpam) \"1\" else \"0\")\n",
    "    }\n",
    "    writer.writeAll(headers +: rows)\n",
    "  }\n",
    "}\n",
    "\n",
    "val trainingCsv = \"data/training.csv\"\n",
    "writeToCsv(trainingCsv, training)\n",
    "val validationCsv = \"data/validation.csv\"\n",
    "writeToCsv(validationCsv, validation)\n",
    "val testCsv = \"data/test.csv\"\n",
    "writeToCsv(testCsv, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ba9697-4121-41ec-ad86-4ca468d8caad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken==0.7.* in /usr/local/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/site-packages (from tiktoken==0.7.*) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/site-packages (from tiktoken==0.7.*) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"tiktoken==0.7.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ac863ee-648b-40f4-bb1d-275a7b2657bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mme.shadaj.scalapy.py\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mpy.SeqConverters\u001b[39m\n",
       "\u001b[36mtiktoken\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'tiktoken' from '/usr/local/lib/python3.12/site-packages/tiktoken/__init__.py'>\n",
       "\u001b[36mtokenizer\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <Encoding 'gpt2'>\n",
       "\u001b[36mendOfTextToken\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"<|endoftext|>\"\u001b[39m\n",
       "\u001b[36mencodedEndOfTextToken\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = [50256]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`dev.scalapy::scalapy-core:0.5.3`\n",
    "\n",
    "import me.shadaj.scalapy.py\n",
    "import py.SeqConverters\n",
    "\n",
    "val tiktoken = py.module(\"tiktoken\")\n",
    "\n",
    "val tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "val endOfTextToken = \"<|endoftext|>\"\n",
    "val encodedEndOfTextToken = tokenizer.encode(endOfTextToken, allowed_special = py.Dynamic.global.set(Seq(endOfTextToken).toPythonProxy))\n",
    "println(encodedEndOfTextToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d18733-4b85-41ed-8717-07f261b5ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.4.* in /usr/local/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (75.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch==2.4.*) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy->torch==2.4.*) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"torch==2.4.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910a813f-f2c6-4410-9c73-8687f41294ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mcom.github.tototoshi.csv.CSVReader\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mpy.PyQuote\u001b[39m\n",
       "\u001b[36mtorch\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'torch' from '/usr/local/lib/python3.12/site-packages/torch/__init__.py'>\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mTokenizer\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mSpamDataset\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.github.tototoshi.csv.CSVReader\n",
    "import py.PyQuote\n",
    "\n",
    "val torch = py.module(\"torch\")\n",
    "\n",
    "type Tokenizer = py.Dynamic\n",
    "\n",
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"from torch.utils.data import Dataset\n",
    "     |\n",
    "     |class SpamDataset(Dataset):\n",
    "     |  def __init__(self, init):\n",
    "     |    init(self)\n",
    "     |\n",
    "     |  def __getitem__(self, index):\n",
    "     |    return self.getItem(index)\n",
    "     |  \n",
    "     |  def __len__(self):\n",
    "     |    return self.len()\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def SpamDataset(\n",
    "  csvPath: String,\n",
    "  tokenizer: Tokenizer,\n",
    "  maxLength: Option[Int] = None,\n",
    "  paddingTokenId: Int = 50_256\n",
    "): py.Dynamic = {\n",
    "  val smsSpamRecords = Using.resource(CSVReader.open(csvPath)) { csvReader =>\n",
    "    csvReader.iteratorWithHeaders.map { row =>\n",
    "      SmsSpamRecord(text = row(textHeader), isSpam = row(labelHeader).toInt > 0)\n",
    "    }.toVector\n",
    "  }\n",
    "  val encodedTexts = {\n",
    "    val encodedTexts = smsSpamRecords.map(_.text).map(tokenizer.encode(_).as[Seq[Int]].toVector)\n",
    "    val padToLength = maxLength.getOrElse(encodedTexts.map(_.length).max)\n",
    "    encodedTexts.map(_.padTo(padToLength, paddingTokenId))\n",
    "  }\n",
    "    \n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.maxLength = encodedTexts.head.length\n",
    "    \n",
    "    val getItem = (index: Int) => {\n",
    "      val textTensor = torch.tensor(encodedTexts(index).toPythonProxy, dtype = torch.long)\n",
    "      val labelTensor = torch.tensor(if (smsSpamRecords(index).isSpam) 1 else 0, dtype = torch.long)\n",
    "      (textTensor, labelTensor)\n",
    "    }\n",
    "    self.getItem = getItem\n",
    "\n",
    "    val len = () => smsSpamRecords.size\n",
    "    self.len = len\n",
    "  }\n",
    "  py.Dynamic.global.SpamDataset(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3db6947e-949f-465d-90f3-2588cd796fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingDataset\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <SpamDataset object at 0xffff4671be30>\n",
       "\u001b[36mvalidationDataset\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <SpamDataset object at 0xffff5403c200>\n",
       "\u001b[36mtestDataset\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <SpamDataset object at 0xffff54096420>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingDataset = SpamDataset(trainingCsv, tokenizer)\n",
    "val validationDataset = SpamDataset(validationCsv, tokenizer, maxLength = Some(trainingDataset.maxLength.as[Int]))\n",
    "val testDataset = SpamDataset(testCsv, tokenizer, maxLength = Some(trainingDataset.maxLength.as[Int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9939eb92-a199-4019-91c4-67833cc92e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mbatchSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m8\u001b[39m\n",
       "\u001b[36mres15_1\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xffff6072c770>\n",
       "\u001b[36mtrainingDataLoader\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch.utils.data.dataloader.DataLoader object at 0xffff46719460>\n",
       "\u001b[36mvalidationDataLoader\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch.utils.data.dataloader.DataLoader object at 0xffff46b8bd10>\n",
       "\u001b[36mtestDataLoader\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch.utils.data.dataloader.DataLoader object at 0xffff60b75400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val batchSize = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "val trainingDataLoader = torch.utils.data.DataLoader(\n",
    "  dataset = trainingDataset, \n",
    "  batch_size = batchSize,\n",
    "  shuffle = true,\n",
    "  num_workers = 0,\n",
    "  drop_last = true\n",
    ")\n",
    "val validationDataLoader = torch.utils.data.DataLoader(\n",
    "  dataset = validationDataset, \n",
    "  batch_size = batchSize,\n",
    "  num_workers = 0,\n",
    "  drop_last = false\n",
    ")\n",
    "val testDataLoader = torch.utils.data.DataLoader(\n",
    "  dataset = testDataset, \n",
    "  batch_size = batchSize,\n",
    "  num_workers = 0,\n",
    "  drop_last = false\n",
    ")\n",
    "\n",
    "println(s\"${py.Dynamic.global.len(trainingDataLoader)} training batches\")\n",
    "println(s\"${py.Dynamic.global.len(validationDataLoader)} validation batches\")\n",
    "println(s\"${py.Dynamic.global.len(testDataLoader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26d34644-7ac9-4277-9ae4-b6aaa38bc6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mGPTConfig\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class GPTConfig(\n",
    "  vocabularySize: Int,\n",
    "  contextLength: Int,\n",
    "  embeddingDimension: Int,\n",
    "  attentionHeadsCount: Int,\n",
    "  layersCount: Int,\n",
    "  dropoutRate: Double,\n",
    "  queryKeyValueBias: Boolean\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2dfd43d-f02c-4c1a-8eb3-817c92b539a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mTorchTensor\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mMultiHeadAttention\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type TorchTensor = py.Dynamic\n",
    "\n",
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class MultiHeadAttention(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def MultiHeadAttention(\n",
    "  inputDimension: Int,\n",
    "  outputDimension: Int,\n",
    "  dropoutProbability: Double,\n",
    "  contextLength: Int,\n",
    "  headsCount: Int,\n",
    "  queryKeyValueBias: Boolean\n",
    "): py.Dynamic = {\n",
    "  assert(outputDimension % headsCount == 0, \"Output dimension must be a multiple of heads count\")\n",
    "  val headDimension = outputDimension / headsCount\n",
    "    \n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.weightsQuery = torch.nn.Linear(inputDimension, outputDimension, bias = queryKeyValueBias)\n",
    "    self.weightsKey = torch.nn.Linear(inputDimension, outputDimension, bias = queryKeyValueBias)\n",
    "    self.weightsValue = torch.nn.Linear(inputDimension, outputDimension, bias = queryKeyValueBias)\n",
    "    self.outputProjection = torch.nn.Linear(outputDimension, outputDimension)\n",
    "    self.dropout = torch.nn.Dropout(dropoutProbability)\n",
    "    self.register_buffer(\"mask\", torch.triu(torch.ones(contextLength, contextLength), diagonal = 1))\n",
    "      \n",
    "    val forward = (batchedInputs: TorchTensor) => {\n",
    "      val (batchesCount, tokensCount, tokenDimension) = batchedInputs.shape.as[(Int, Int, Int)]\n",
    "      val queries = self.weightsQuery(batchedInputs)\n",
    "        .view(batchesCount, tokensCount, headsCount, headDimension)\n",
    "        .transpose(1, 2)\n",
    "      val keys = self.weightsKey(batchedInputs)\n",
    "        .view(batchesCount, tokensCount, headsCount, headDimension)\n",
    "        .transpose(1, 2)\n",
    "      val values = self.weightsValue(batchedInputs)\n",
    "        .view(batchesCount, tokensCount, headsCount, headDimension)\n",
    "        .transpose(1, 2)\n",
    "      val attentionScores = py\"$queries @ $keys.transpose(2, 3)\"\n",
    "      attentionScores.masked_fill_(py\"${self.mask}.bool()[:$tokensCount, :$tokensCount]\", -torch.inf)\n",
    "      val attentionWeights = self.dropout(torch.softmax(py\"$attentionScores / $headDimension**0.5\", dim = -1))\n",
    "      self.outputProjection(\n",
    "        py\"$attentionWeights @ $values\"\n",
    "          .transpose(1, 2)\n",
    "          .reshape(batchesCount, tokensCount, outputDimension)\n",
    "      )\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.MultiHeadAttention(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7799670d-e179-4188-b8c9-d9393033d141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mGELU\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "// Because it mostly uses Python operators, it's implemented fully in Python\n",
    "py.exec {\n",
    "  s\"\"\"import torch\n",
    "     |import torch.nn as nn\n",
    "     |\n",
    "     |class GELU(nn.Module):\n",
    "     |  def __init__(self):\n",
    "     |    super().__init__()\n",
    "     |\n",
    "     |  def forward(self, inputs):\n",
    "     |    return 0.5 * inputs * (\n",
    "     |      1 + torch.tanh(\n",
    "     |        torch.sqrt(torch.tensor(2.0 / torch.pi)) * (inputs + 0.044715 * torch.pow(inputs, 3))\n",
    "     |      )\n",
    "     |    )\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def GELU() = py.Dynamic.global.GELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cb61e38-8be9-4729-9e86-6c90eb8de235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mFeedForward\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class FeedForward(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def FeedForward(\n",
    "  embeddingDimension: Int\n",
    "): py.Dynamic = {\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.layers = torch.nn.Sequential(\n",
    "      torch.nn.Linear(embeddingDimension, 4 * embeddingDimension),\n",
    "      GELU(),\n",
    "      torch.nn.Linear(4 * embeddingDimension, embeddingDimension)\n",
    "    )\n",
    "      \n",
    "    val forward = (inputs: TorchTensor) => self.layers(inputs)\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.FeedForward(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3a80736-2a99-4310-b59f-20edb7bbac85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mNormalizationLayer\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class NormalizationLayer(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def NormalizationLayer(\n",
    "  embeddingDimension: Int\n",
    "): py.Dynamic = {\n",
    "  val epsilon = 1e-5\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.scale = torch.nn.Parameter(torch.ones(embeddingDimension))\n",
    "    self.shift = torch.nn.Parameter(torch.zeros(embeddingDimension))\n",
    "      \n",
    "    val forward = (inputs: TorchTensor) => {\n",
    "      val mean = inputs.mean(dim = -1, keepdim = true)\n",
    "      val variance = inputs.`var`(dim = -1, keepdim = true, unbiased = false)\n",
    "      val normalizedInputs = py\"($inputs - $mean) / torch.sqrt($variance + $epsilon)\"\n",
    "      py\"${self.scale} * $normalizedInputs + ${self.shift}\"\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.NormalizationLayer(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1b07cba-e201-4209-9980-21948569c2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.chaining._\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mTransformerBlock\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.util.chaining._\n",
    "\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class TransformerBlock(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def TransformerBlock(\n",
    "  config: GPTConfig\n",
    "): py.Dynamic = {\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.multiHeadAttention = MultiHeadAttention(\n",
    "      inputDimension = config.embeddingDimension,\n",
    "      outputDimension = config.embeddingDimension,\n",
    "      dropoutProbability = config.dropoutRate,\n",
    "      contextLength = config.contextLength,\n",
    "      headsCount = config.attentionHeadsCount,\n",
    "      queryKeyValueBias = config.queryKeyValueBias\n",
    "    )\n",
    "    self.feedForward = FeedForward(config.embeddingDimension)\n",
    "    self.normalization1 = NormalizationLayer(config.embeddingDimension)\n",
    "    self.normalization2 = NormalizationLayer(config.embeddingDimension)\n",
    "    self.dropoutShortcut = torch.nn.Dropout(config.dropoutRate)\n",
    "    \n",
    "    val forward = (inputs: TorchTensor) => {\n",
    "      val shortcut = inputs\n",
    "      val newShortcut = inputs\n",
    "        .pipe(self.normalization1(_))\n",
    "        .pipe(self.multiHeadAttention(_))\n",
    "        .pipe(self.dropoutShortcut(_))\n",
    "        .pipe(o => py\"$o + $shortcut\")\n",
    "      newShortcut\n",
    "        .pipe(self.normalization2(_))\n",
    "        .pipe(self.feedForward(_))\n",
    "        .pipe(self.dropoutShortcut(_))\n",
    "        .pipe(o => py\"$o + $newShortcut\")\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.TransformerBlock(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2974f19c-5b76-4ed2-a6d7-5bca875ddaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mModel\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mGPTModel\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class GPTModel(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "type Model = py.Dynamic\n",
    "def GPTModel(\n",
    "  config: GPTConfig\n",
    "): Model = {\n",
    "  val transformerBlocks = Seq.fill(config.layersCount)(TransformerBlock(config))\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.tokenEmbeddingLayer = torch.nn.Embedding(config.vocabularySize, config.embeddingDimension)\n",
    "    self.positionEmbeddingLayer = torch.nn.Embedding(config.contextLength, config.embeddingDimension)\n",
    "    self.dropoutEmbeddingLayer = torch.nn.Dropout(config.dropoutRate)\n",
    "    self.transformerBlocksLayer = py\"nn.Sequential(*${transformerBlocks.toPythonProxy})\"\n",
    "    self.finalNormalizationLayer = NormalizationLayer(config.embeddingDimension)\n",
    "    self.outputLayer = torch.nn.Linear(config.embeddingDimension, config.vocabularySize, bias = false)\n",
    "      \n",
    "    val forward = (batchedInputs: TorchTensor) => {\n",
    "      val (_, sequenceLength) = batchedInputs.shape.as[(Int, Int)]\n",
    "      val tokenEmbeddings = self.tokenEmbeddingLayer(batchedInputs)\n",
    "      val positionEmbeddings = self.positionEmbeddingLayer(torch.arange(sequenceLength, device = batchedInputs.device))\n",
    "      py\"$tokenEmbeddings + $positionEmbeddings\"\n",
    "        .pipe(self.dropoutEmbeddingLayer(_))\n",
    "        .pipe(self.transformerBlocksLayer(_))\n",
    "        .pipe(self.finalNormalizationLayer(_))\n",
    "        .pipe(self.outputLayer(_))\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.GPTModel(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e2bb752-7eb2-4fcb-9e0d-425bbb51f8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbaseUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2/124M\"\u001b[39m\n",
       "\u001b[36mhparamsFilename\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"hparams.json\"\u001b[39m\n",
       "\u001b[36mfilenames\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m\"checkpoint\"\u001b[39m,\n",
       "  \u001b[32m\"encoder.json\"\u001b[39m,\n",
       "  \u001b[32m\"hparams.json\"\u001b[39m,\n",
       "  \u001b[32m\"model.ckpt.data-00000-of-00001\"\u001b[39m,\n",
       "  \u001b[32m\"model.ckpt.index\"\u001b[39m,\n",
       "  \u001b[32m\"model.ckpt.meta\"\u001b[39m,\n",
       "  \u001b[32m\"vocab.bpe\"\u001b[39m\n",
       ")\n",
       "\u001b[36moutputDir\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/openai124M\"\u001b[39m"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val baseUrl = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2/124M\" // backup\n",
    "// val baseUrl = \"https://openaipublic.blob.core.windows.net/gpt-2/models/124M\" // backup\n",
    "val hparamsFilename = \"hparams.json\"\n",
    "val filenames = List(\"checkpoint\", \"encoder.json\", hparamsFilename, \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\", \"model.ckpt.meta\", \"vocab.bpe\")\n",
    "\n",
    "val outputDir = \"data/openai124M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff93551d-b4f8-42e8-8ff7-9394cb75125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    77  100    77    0     0     74      0  0:00:01  0:00:01 --:--:--    74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading encoder.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  5 1017k    5 56906    0     0  50551      0  0:00:20  0:00:01  0:00:19 50538\n",
      "100 1017k  100 1017k    0     0   543k      0  0:00:01  0:00:01 --:--:--  543k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading hparams.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    90  100    90    0     0    134      0 --:--:-- --:--:-- --:--:--   134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model.ckpt.data-00000-of-00001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  474M    0  391k    0     0   253k      0  0:31:55  0:00:01  0:31:54  253k\n",
      "  2  474M    2 10.3M    0     0  4083k      0  0:01:59  0:00:02  0:01:57 4082k\n",
      "  5  474M    5 25.1M    0     0  7176k      0  0:01:07  0:00:03  0:01:04 7175k\n",
      "  8  474M    8 40.2M    0     0  8982k      0  0:00:54  0:00:04  0:00:50 8982k\n",
      " 11  474M   11 56.5M    0     0  10.1M      0  0:00:46  0:00:05  0:00:41 11.3M\n",
      " 15  474M   15 71.4M    0     0  10.9M      0  0:00:43  0:00:06  0:00:37 14.2M\n",
      " 18  474M   18 86.1M    0     0  11.4M      0  0:00:41  0:00:07  0:00:34 15.3M\n",
      " 21  474M   21  103M    0     0  12.0M      0  0:00:39  0:00:08  0:00:31 15.6M\n",
      " 25  474M   25  119M    0     0  12.4M      0  0:00:38  0:00:09  0:00:29 15.8M\n",
      " 28  474M   28  134M    0     0  12.7M      0  0:00:37  0:00:10  0:00:27 15.5M\n",
      " 31  474M   31  150M    0     0  13.0M      0  0:00:36  0:00:11  0:00:25 15.7M\n",
      " 33  474M   33  158M    0     0  12.5M      0  0:00:37  0:00:12  0:00:25 14.3M\n",
      " 36  474M   36  175M    0     0  12.8M      0  0:00:36  0:00:13  0:00:23 14.2M\n",
      " 40  474M   40  189M    0     0  12.9M      0  0:00:36  0:00:14  0:00:22 14.0M\n",
      " 43  474M   43  204M    0     0  13.1M      0  0:00:36  0:00:15  0:00:21 14.0M\n",
      " 46  474M   46  220M    0     0  13.3M      0  0:00:35  0:00:16  0:00:19 14.0M\n",
      " 50  474M   50  237M    0     0  13.4M      0  0:00:35  0:00:17  0:00:18 15.7M\n",
      " 53  474M   53  252M    0     0  13.5M      0  0:00:34  0:00:18  0:00:16 15.5M\n",
      " 56  474M   56  268M    0     0  13.6M      0  0:00:34  0:00:19  0:00:15 15.6M\n",
      " 59  474M   59  284M    0     0  13.7M      0  0:00:34  0:00:20  0:00:14 15.5M\n",
      " 62  474M   62  298M    0     0  13.8M      0  0:00:34  0:00:21  0:00:13 15.5M\n",
      " 65  474M   65  312M    0     0  13.8M      0  0:00:34  0:00:22  0:00:12 15.2M\n",
      " 69  474M   69  329M    0     0  13.9M      0  0:00:34  0:00:23  0:00:11 15.3M\n",
      " 70  474M   70  336M    0     0  13.6M      0  0:00:34  0:00:24  0:00:10 13.7M\n",
      " 73  474M   73  351M    0     0  13.7M      0  0:00:34  0:00:25  0:00:09 13.6M\n",
      " 76  474M   76  365M    0     0  13.7M      0  0:00:34  0:00:26  0:00:08 13.3M\n",
      " 80  474M   80  381M    0     0  13.8M      0  0:00:34  0:00:27  0:00:07 13.6M\n",
      " 83  474M   83  396M    0     0  13.8M      0  0:00:34  0:00:28  0:00:06 13.3M\n",
      " 86  474M   86  411M    0     0  13.8M      0  0:00:34  0:00:29  0:00:05 14.8M\n",
      " 89  474M   89  426M    0     0  13.9M      0  0:00:34  0:00:30  0:00:04 14.8M\n",
      " 92  474M   92  441M    0     0  13.9M      0  0:00:33  0:00:31  0:00:02 15.3M\n",
      " 96  474M   96  456M    0     0  14.0M      0  0:00:33  0:00:32  0:00:01 15.3M\n",
      " 99  474M   99  471M    0     0  14.0M      0  0:00:33  0:00:33 --:--:-- 15.3M\n",
      "100  474M  100  474M    0     0  14.0M      0  0:00:33  0:00:33 --:--:-- 14.9M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model.ckpt.index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  5215  100  5215    0     0   7723      0 --:--:-- --:--:-- --:--:--  7714\n",
      "100  5215  100  5215    0     0   7721      0 --:--:-- --:--:-- --:--:--  7714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model.ckpt.meta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  8  460k    8 40512    0     0  42148      0  0:00:11 --:--:--  0:00:11 42112\n",
      "100  460k  100  460k    0     0   290k      0  0:00:01  0:00:01 --:--:--  290k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab.bpe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 46  445k   46  207k    0     0   152k      0  0:00:02  0:00:01  0:00:01  152k\n",
      "100  445k  100  445k    0     0   285k      0  0:00:01  0:00:01 --:--:--  285k\n"
     ]
    }
   ],
   "source": [
    "filenames.foreach { filename =>\n",
    "  println(s\"Downloading $filename...\")\n",
    "  Magic.!(\"curl\", \"--create-dirs\", \"-O\", \"--output-dir\", outputDir, s\"$baseUrl/$filename\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba140fe2-fc98-46cb-b3aa-5f76b94e332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.16.* in /usr/local/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.*) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.*) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"tensorflow==2.16.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17d95f90-6312-4cab-9434-73d340ee1a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\u001b[39m\n",
       "\u001b[36mhparamsMap\u001b[39m: \u001b[32mujson\u001b[39m.\u001b[32mValue\u001b[39m.\u001b[32mValue\u001b[39m = \u001b[33mObj\u001b[39m(\n",
       "  value = \u001b[33mMap\u001b[39m(\n",
       "    \u001b[32m\"n_vocab\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m50257.0\u001b[39m),\n",
       "    \u001b[32m\"n_ctx\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m1024.0\u001b[39m),\n",
       "    \u001b[32m\"n_embd\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m768.0\u001b[39m),\n",
       "    \u001b[32m\"n_head\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m12.0\u001b[39m),\n",
       "    \u001b[32m\"n_layer\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m12.0\u001b[39m)\n",
       "  )\n",
       ")\n",
       "\u001b[36mgptConfig\u001b[39m: \u001b[32mGPTConfig\u001b[39m = \u001b[33mGPTConfig\u001b[39m(\n",
       "  vocabularySize = \u001b[32m50257\u001b[39m,\n",
       "  contextLength = \u001b[32m1024\u001b[39m,\n",
       "  embeddingDimension = \u001b[32m768\u001b[39m,\n",
       "  attentionHeadsCount = \u001b[32m12\u001b[39m,\n",
       "  layersCount = \u001b[32m12\u001b[39m,\n",
       "  dropoutRate = \u001b[32m0.1\u001b[39m,\n",
       "  queryKeyValueBias = \u001b[32mtrue\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.lihaoyi::ujson:4.1.0`\n",
    "\n",
    "import scala.io.Source\n",
    "\n",
    "val hparamsMap = ujson.read(Source.fromFile(s\"$outputDir/$hparamsFilename\").mkString)\n",
    "\n",
    "val gptConfig = GPTConfig(\n",
    "  vocabularySize = hparamsMap(\"n_vocab\").num.toInt,\n",
    "  contextLength = hparamsMap(\"n_ctx\").num.toInt,\n",
    "  embeddingDimension = hparamsMap(\"n_embd\").num.toInt,\n",
    "  attentionHeadsCount = hparamsMap(\"n_head\").num.toInt,\n",
    "  layersCount = hparamsMap(\"n_layer\").num.toInt,\n",
    "  dropoutRate = 0.1,\n",
    "  queryKeyValueBias = true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc8b8a66-3bbe-41d2-a719-8fbe8c1023cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtf\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'tensorflow' from '/usr/local/lib/python3.12/site-packages/tensorflow/__init__.py'>\n",
       "\u001b[36mnp\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'numpy' from '/usr/local/lib/python3.12/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tf = py.module(\"tensorflow\")\n",
    "val np = py.module(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a353053b-7a30-45b9-8c63-6166a708a832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/h0/attn/c_attn/b\n",
      "model/h0/attn/c_attn/w\n",
      "model/h0/attn/c_proj/b\n",
      "model/h0/attn/c_proj/w\n",
      "model/h0/ln_1/b\n",
      "model/h0/ln_1/g\n",
      "model/h0/ln_2/b\n",
      "model/h0/ln_2/g\n",
      "model/h0/mlp/c_fc/b\n",
      "model/h0/mlp/c_fc/w\n",
      "model/h0/mlp/c_proj/b\n",
      "model/h0/mlp/c_proj/w\n",
      "model/h1/attn/c_attn/b\n",
      "model/h1/attn/c_attn/w\n",
      "model/h1/attn/c_proj/b\n",
      "model/h1/attn/c_proj/w\n",
      "model/h1/ln_1/b\n",
      "model/h1/ln_1/g\n",
      "model/h1/ln_2/b\n",
      "model/h1/ln_2/g\n",
      "model/h1/mlp/c_fc/b\n",
      "model/h1/mlp/c_fc/w\n",
      "model/h1/mlp/c_proj/b\n",
      "model/h1/mlp/c_proj/w\n",
      "model/h10/attn/c_attn/b\n",
      "model/h10/attn/c_attn/w\n",
      "model/h10/attn/c_proj/b\n",
      "model/h10/attn/c_proj/w\n",
      "model/h10/ln_1/b\n",
      "model/h10/ln_1/g\n",
      "model/h10/ln_2/b\n",
      "model/h10/ln_2/g\n",
      "model/h10/mlp/c_fc/b\n",
      "model/h10/mlp/c_fc/w\n",
      "model/h10/mlp/c_proj/b\n",
      "model/h10/mlp/c_proj/w\n",
      "model/h11/attn/c_attn/b\n",
      "model/h11/attn/c_attn/w\n",
      "model/h11/attn/c_proj/b\n",
      "model/h11/attn/c_proj/w\n",
      "model/h11/ln_1/b\n",
      "model/h11/ln_1/g\n",
      "model/h11/ln_2/b\n",
      "model/h11/ln_2/g\n",
      "model/h11/mlp/c_fc/b\n",
      "model/h11/mlp/c_fc/w\n",
      "model/h11/mlp/c_proj/b\n",
      "model/h11/mlp/c_proj/w\n",
      "model/h2/attn/c_attn/b\n",
      "model/h2/attn/c_attn/w\n",
      "model/h2/attn/c_proj/b\n",
      "model/h2/attn/c_proj/w\n",
      "model/h2/ln_1/b\n",
      "model/h2/ln_1/g\n",
      "model/h2/ln_2/b\n",
      "model/h2/ln_2/g\n",
      "model/h2/mlp/c_fc/b\n",
      "model/h2/mlp/c_fc/w\n",
      "model/h2/mlp/c_proj/b\n",
      "model/h2/mlp/c_proj/w\n",
      "model/h3/attn/c_attn/b\n",
      "model/h3/attn/c_attn/w\n",
      "model/h3/attn/c_proj/b\n",
      "model/h3/attn/c_proj/w\n",
      "model/h3/ln_1/b\n",
      "model/h3/ln_1/g\n",
      "model/h3/ln_2/b\n",
      "model/h3/ln_2/g\n",
      "model/h3/mlp/c_fc/b\n",
      "model/h3/mlp/c_fc/w\n",
      "model/h3/mlp/c_proj/b\n",
      "model/h3/mlp/c_proj/w\n",
      "model/h4/attn/c_attn/b\n",
      "model/h4/attn/c_attn/w\n",
      "model/h4/attn/c_proj/b\n",
      "model/h4/attn/c_proj/w\n",
      "model/h4/ln_1/b\n",
      "model/h4/ln_1/g\n",
      "model/h4/ln_2/b\n",
      "model/h4/ln_2/g\n",
      "model/h4/mlp/c_fc/b\n",
      "model/h4/mlp/c_fc/w\n",
      "model/h4/mlp/c_proj/b\n",
      "model/h4/mlp/c_proj/w\n",
      "model/h5/attn/c_attn/b\n",
      "model/h5/attn/c_attn/w\n",
      "model/h5/attn/c_proj/b\n",
      "model/h5/attn/c_proj/w\n",
      "model/h5/ln_1/b\n",
      "model/h5/ln_1/g\n",
      "model/h5/ln_2/b\n",
      "model/h5/ln_2/g\n",
      "model/h5/mlp/c_fc/b\n",
      "model/h5/mlp/c_fc/w\n",
      "model/h5/mlp/c_proj/b\n",
      "model/h5/mlp/c_proj/w\n",
      "model/h6/attn/c_attn/b\n",
      "model/h6/attn/c_attn/w\n",
      "model/h6/attn/c_proj/b\n",
      "model/h6/attn/c_proj/w\n",
      "model/h6/ln_1/b\n",
      "model/h6/ln_1/g\n",
      "model/h6/ln_2/b\n",
      "model/h6/ln_2/g\n",
      "model/h6/mlp/c_fc/b\n",
      "model/h6/mlp/c_fc/w\n",
      "model/h6/mlp/c_proj/b\n",
      "model/h6/mlp/c_proj/w\n",
      "model/h7/attn/c_attn/b\n",
      "model/h7/attn/c_attn/w\n",
      "model/h7/attn/c_proj/b\n",
      "model/h7/attn/c_proj/w\n",
      "model/h7/ln_1/b\n",
      "model/h7/ln_1/g\n",
      "model/h7/ln_2/b\n",
      "model/h7/ln_2/g\n",
      "model/h7/mlp/c_fc/b\n",
      "model/h7/mlp/c_fc/w\n",
      "model/h7/mlp/c_proj/b\n",
      "model/h7/mlp/c_proj/w\n",
      "model/h8/attn/c_attn/b\n",
      "model/h8/attn/c_attn/w\n",
      "model/h8/attn/c_proj/b\n",
      "model/h8/attn/c_proj/w\n",
      "model/h8/ln_1/b\n",
      "model/h8/ln_1/g\n",
      "model/h8/ln_2/b\n",
      "model/h8/ln_2/g\n",
      "model/h8/mlp/c_fc/b\n",
      "model/h8/mlp/c_fc/w\n",
      "model/h8/mlp/c_proj/b\n",
      "model/h8/mlp/c_proj/w\n",
      "model/h9/attn/c_attn/b\n",
      "model/h9/attn/c_attn/w\n",
      "model/h9/attn/c_proj/b\n",
      "model/h9/attn/c_proj/w\n",
      "model/h9/ln_1/b\n",
      "model/h9/ln_1/g\n",
      "model/h9/ln_2/b\n",
      "model/h9/ln_2/g\n",
      "model/h9/mlp/c_fc/b\n",
      "model/h9/mlp/c_fc/w\n",
      "model/h9/mlp/c_proj/b\n",
      "model/h9/mlp/c_proj/w\n",
      "model/ln_f/b\n",
      "model/ln_f/g\n",
      "model/wpe\n",
      "model/wte\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcheckpoint\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = data/openai124M/model.ckpt\n",
       "\u001b[36mvariableNames\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m\"model/h0/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/attn/c_attn/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/attn/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/attn/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_1/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_1/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_2/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_2/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_fc/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_fc/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_attn/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_1/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_1/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_2/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_2/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_fc/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_fc/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_attn/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_1/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_1/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_2/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_2/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_fc/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_fc/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h11/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h11/attn/c_attn/w\"\u001b[39m,\n",
       "..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val checkpoint = tf.train.latest_checkpoint(outputDir)\n",
    "val variableNames = tf.train.list_variables(checkpoint).as[Seq[(String, Seq[Int])]].map { \n",
    "  case (variableName, _) => variableName \n",
    "}.toList\n",
    "variableNames.sorted.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11392e9f-eb7c-4a1a-a892-2a37e04d9298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd29.sc:18: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd29.sc:29: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd29.sc:15: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"c_attn\", \"c_proj\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd29.sc:37: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"g\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd29.sc:44: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"g\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd29.sc:53: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd29.sc:59: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd29.sc:50: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"c_fc\", \"c_proj\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd29.sc:12: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"attn\", \"ln_1\", \"ln_2\", \"mlp\"))), Nil\n",
      "        tail match {\n",
      "        ^\n",
      "cmd29.sc:68: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"g\"))), Nil\n",
      "        tail match {\n",
      "        ^\n",
      "cmd29.sc:9: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"ln_f\", \"wpe\", \"wte\"))), Nil\n",
      "    variableName.split(\"/\").drop(1).toList match {\n",
      "                                    ^\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mNpArray\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtoTorchParameter\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mloadModelWeights\u001b[39m"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type NpArray = py.Dynamic\n",
    "\n",
    "def toTorchParameter(npArray: NpArray) =\n",
    "  torch.nn.Parameter(torch.tensor(npArray))\n",
    "\n",
    "def loadModelWeights(model: Model): Unit =\n",
    "  variableNames.foreach { variableName =>\n",
    "    val variableValue = np.squeeze(tf.train.load_variable(checkpoint, variableName))\n",
    "    variableName.split(\"/\").drop(1).toList match {\n",
    "      case s\"h$transformerBlockIndexString\" :: tail =>\n",
    "        val transformerBlockIndex = transformerBlockIndexString.toInt\n",
    "        tail match {\n",
    "          case \"attn\" :: tail =>\n",
    "            val multiHeadAttention = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).multiHeadAttention\n",
    "            tail match {\n",
    "              case \"c_attn\" :: tail =>\n",
    "                val Seq(queryVariableValue, keyVariableValue, valueVariableValue) = np.split(variableValue, 3, axis = -1).as[Seq[NpArray]]\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => \n",
    "                    multiHeadAttention.weightsQuery.bias = toTorchParameter(queryVariableValue)\n",
    "                    multiHeadAttention.weightsKey.bias = toTorchParameter(keyVariableValue)\n",
    "                    multiHeadAttention.weightsValue.bias = toTorchParameter(valueVariableValue)\n",
    "                  case \"w\" :: _ => \n",
    "                    multiHeadAttention.weightsQuery.weight = toTorchParameter(queryVariableValue.T)\n",
    "                    multiHeadAttention.weightsKey.weight = toTorchParameter(keyVariableValue.T)\n",
    "                    multiHeadAttention.weightsValue.weight = toTorchParameter(valueVariableValue.T)\n",
    "                }\n",
    "              case \"c_proj\" :: tail =>\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => multiHeadAttention.outputProjection.bias = toTorchParameter(variableValue)\n",
    "                  case \"w\" :: _ => multiHeadAttention.outputProjection.weight = toTorchParameter(variableValue.T)\n",
    "                }\n",
    "            }\n",
    "          case \"ln_1\" :: tail =>\n",
    "            val normalization1 = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).normalization1\n",
    "            val torchParameter = toTorchParameter(variableValue)\n",
    "            tail match {\n",
    "              case \"b\" :: _ => normalization1.shift = torchParameter\n",
    "              case \"g\" :: _ => normalization1.scale = torchParameter\n",
    "            }\n",
    "          case \"ln_2\" :: tail =>\n",
    "            val normalization2 = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).normalization2\n",
    "            val torchParameter = toTorchParameter(variableValue)\n",
    "            tail match {\n",
    "              case \"b\" :: _ => normalization2.shift = torchParameter\n",
    "              case \"g\" :: _ => normalization2.scale = torchParameter\n",
    "            }\n",
    "          case \"mlp\" :: tail =>\n",
    "            val feedForward = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).feedForward\n",
    "            tail match {\n",
    "              case \"c_fc\" :: tail =>\n",
    "                val layer0 = feedForward.layers.bracketAccess(0)\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => layer0.bias = toTorchParameter(variableValue)\n",
    "                  case \"w\" :: _ => layer0.weight = toTorchParameter(variableValue.T)\n",
    "                }\n",
    "              case \"c_proj\" :: tail =>\n",
    "                val layer2 = feedForward.layers.bracketAccess(2)\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => layer2.bias = toTorchParameter(variableValue)\n",
    "                  case \"w\" :: _ => layer2.weight = toTorchParameter(variableValue.T)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "      case \"ln_f\" :: tail =>\n",
    "        val finalNormalizationLayer = model.finalNormalizationLayer\n",
    "        val torchParameter = toTorchParameter(variableValue)\n",
    "        tail match {\n",
    "          case \"b\" :: _ => finalNormalizationLayer.shift = torchParameter\n",
    "          case \"g\" :: _ => finalNormalizationLayer.scale = torchParameter\n",
    "        }\n",
    "      case \"wpe\" :: _ => model.positionEmbeddingLayer.weight = toTorchParameter(variableValue)\n",
    "      case \"wte\" :: _ => \n",
    "        val torchParameter = toTorchParameter(variableValue)\n",
    "        model.tokenEmbeddingLayer.weight = torchParameter\n",
    "        model.outputLayer.weight = torchParameter\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2d088fe-9916-4b26-8a8f-9b0c835e92bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodel\u001b[39m: \u001b[32mModel\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36mdevice\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = cpu\n",
       "\u001b[36mres30_3\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36mres30_4\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = GPTModel(gptConfig)\n",
    "loadModelWeights(model)\n",
    "val device = torch.device(if (torch.cuda.is_available().as[Boolean]) \"cuda\" else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0326838d-0cec-4330-9f6a-3972cd501fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtextToTokenIds\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtokenIdsToText\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgenerateTextSimple\u001b[39m"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def textToTokenIds(\n",
    "  text: String, \n",
    "  tokenizer: Tokenizer\n",
    "): TorchTensor = {\n",
    "  val allowedSpecial = py.Dynamic.global.set(Seq(\"<|endoftext|>\").toPythonProxy)\n",
    "  val encodedText = tokenizer.encode(text, allowed_special = allowedSpecial)\n",
    "  torch.tensor(encodedText).unsqueeze(0)\n",
    "}\n",
    "    \n",
    "def tokenIdsToText(\n",
    "  tokenIds: TorchTensor, \n",
    "  tokenizer: Tokenizer\n",
    "): String =\n",
    "  tokenizer.decode(tokenIds.squeeze(0).tolist()).as[String]\n",
    "\n",
    "def generateTextSimple(\n",
    "  model: Model,\n",
    "  maxNewTokens: Int,\n",
    "  contextLength: Int\n",
    ")(\n",
    "  encodedInput: TorchTensor\n",
    "): TorchTensor =\n",
    "  LazyList.iterate(encodedInput) { currentEncodedOutput =>\n",
    "    val croppedInput = py\"$currentEncodedOutput[:, -$contextLength:]\"\n",
    "    val logits = py.`with`(torch.no_grad()) { _ =>\n",
    "      model(croppedInput)\n",
    "    }\n",
    "    py\"$logits[:, -1, :]\"\n",
    "      .pipe(torch.softmax(_, dim = -1))\n",
    "      .pipe(torch.argmax(_, dim = -1, keepdim = true))\n",
    "      .pipe(nextEncodedOutput => torch.cat((currentEncodedOutput, nextEncodedOutput), dim = 1))\n",
    "  }.drop(maxNewTokens).head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e05a5396-3059-414c-852d-cc5092ea59e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mexampleText\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Every effort moves you\"\u001b[39m\n",
       "\u001b[36mencodedText\u001b[39m: \u001b[32mTorchTensor\u001b[39m = tensor([[6109, 3626, 6100,  345]])\n",
       "\u001b[36mencodedTextOutput\u001b[39m: \u001b[32mTorchTensor\u001b[39m = tensor([[6109, 3626, 6100,  345, 2651,   13,  198,  198,  464,  717, 2239,  318,\n",
       "          284, 1833,  262, 6817,  286,  534,  670]])\n",
       "\u001b[36mdecodedTextOutput\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"Every effort moves you forward.\n",
       "\n",
       "The first step is to understand the importance of your work\"\"\"\u001b[39m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val exampleText = \"Every effort moves you\"\n",
    "val encodedText = textToTokenIds(exampleText, tokenizer)\n",
    "val encodedTextOutput = generateTextSimple(model, maxNewTokens = 15, contextLength = gptConfig.contextLength)(encodedText)\n",
    "val decodedTextOutput = tokenIdsToText(encodedTextOutput, tokenizer)\n",
    "println(decodedTextOutput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13.14",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
