{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73e9304-0b46-4a79-81f5-af4e977bf44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $file.^.Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87b69a7-66f9-475b-9cf1-b8e88f67ec29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mzipName\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"sms+spam+collection.zip\"\u001b[39m\n",
       "\u001b[36mdatasetUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\u001b[39m\n",
       "\u001b[36moutputDir\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/sms-spam-raw\"\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val zipName = \"sms+spam+collection.zip\"\n",
    "val datasetUrl = s\"https://archive.ics.uci.edu/static/public/228/$zipName\"\n",
    "val outputDir = \"data/sms-spam-raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048673b9-9ae6-4d7c-8d60-60a1a383f667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   99k    0   99k    0     0  77139      0 --:--:--  0:00:01 --:--:-- 77110\n",
      "100  198k    0  198k    0     0   146k      0 --:--:--  0:00:01 --:--:--  146k\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"curl\", \"--create-dirs\", \"-O\", \"--output-dir\", outputDir, datasetUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fdc00a5-7737-4164-90b6-7914a4332ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/sms-spam-raw/sms+spam+collection.zip\n",
      "  inflating: data/sms-spam-raw/SMSSpamCollection  \n",
      "  inflating: data/sms-spam-raw/readme  \n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"unzip\", \"-o\", s\"$outputDir/$zipName\", \"-d\", outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28347282-363e-45e5-93c9-4385a6631506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam count: 747\n",
      "Not spam count: 4827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\u001b[39m\n",
       "\u001b[36mdatasetRaw\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
       "ham\tOk lar... Joking wif u oni...\n",
       "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
       "ham\tU dun say so early hor... U c already then say...\n",
       "ham\tNah I don't think he goes to usf, he lives around here though\n",
       "spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
       "ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
       "ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
       "spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
       "spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
       "ham\tI'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
       "spam\tSIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
       "spam\tURGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
       "ham\tI've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
       "ham\tI HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "spam\tXXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL\n",
       "ham\tOh k...i'm watching here:)\n",
       "ham\tEh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.\n",
       "ham\tFine if thats the way u feel. Thats the way its gota b\n",
       "spam\tEngland v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+\n",
       "ham\tIs that seriously how you spell his name?\n",
       "ham\tI‘m going to try for 2 months ha ha only joking\n",
       "\u001b[39m...\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mSmsSpamRecord\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mDataset\u001b[39m\n",
       "\u001b[36msmsSpamRecords\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Ok lar... Joking wif u oni...\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"U dun say so early hor... U c already then say...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Nah I don't think he goes to usf, he lives around here though\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Even my brother is not like to speak with me. They treat me like aids patent.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "...\n",
       "\u001b[36mspamRecords\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mSmsSpamRecord\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCB\u001b[39m...\n",
       "\u001b[36mnotSpamRecords\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mSmsSpamRecord\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Ok lar... Joking wif u oni...\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"U dun say so early hor... U c already then say...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Nah I don't think he goes to usf, he lives around here though\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Even my brother is not like to speak with me. They treat me like aids patent.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"I HAVE A DATE ON SUNDAY WITH WILL!!\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Oh k...i'm watching here:)\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.io.Source\n",
    "\n",
    "val datasetRaw = Source.fromFile(s\"$outputDir/SMSSpamCollection\").mkString\n",
    "\n",
    "case class SmsSpamRecord(\n",
    "  text: String,\n",
    "  isSpam: Boolean\n",
    ")\n",
    "\n",
    "type Dataset = Vector[SmsSpamRecord]\n",
    "\n",
    "val smsSpamRecords: Dataset = datasetRaw.split(\"\\n\").map {\n",
    "  case s\"spam\\t$text\" => SmsSpamRecord(text, isSpam = true)\n",
    "  case s\"ham\\t$text\" => SmsSpamRecord(text, isSpam = false)\n",
    "}.toVector\n",
    "\n",
    "val (spamRecords, notSpamRecords) = smsSpamRecords.partition(_.isSpam)\n",
    "println(s\"Spam count: ${spamRecords.size}\")\n",
    "println(s\"Not spam count: ${notSpamRecords.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e244291-9733-4821-a534-f6cd331a4ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\u001b[39m\n",
       "\u001b[36mbalancedDataset\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCB\u001b[39m..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable\n",
    "import scala.util.Random\n",
    "\n",
    "val balancedDataset: Dataset = {\n",
    "\n",
    "  def sample(records: Vector[SmsSpamRecord], targetSize: Int): Vector[SmsSpamRecord] = {\n",
    "    val balancedDatasetSpam = mutable.Map[String, SmsSpamRecord]()\n",
    "    while (balancedDatasetSpam.size < targetSize) {\n",
    "      val randomRecord = records(Random.nextInt(records.size))\n",
    "      if (!balancedDatasetSpam.contains(randomRecord.text))\n",
    "        balancedDatasetSpam += randomRecord.text -> randomRecord\n",
    "    }\n",
    "    balancedDatasetSpam.values.toVector\n",
    "  }\n",
    "\n",
    "  if (spamRecords.size < notSpamRecords.size)\n",
    "    spamRecords ++ sample(notSpamRecords, targetSize = spamRecords.size)\n",
    "  else\n",
    "    notSpamRecords ++ sample(spamRecords, targetSize = notSpamRecords.size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba96609-d9fa-440e-9556-b3d0f3b104d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mTraining\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mValidation\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mTest\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mrandomSplit\u001b[39m\n",
       "\u001b[36mtraining\u001b[39m: \u001b[32mTraining\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"PRIVATE! Your 2003 Account Statement for 078\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Apart from the one i told you about yesterday?\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"No 1 POLYPHONIC tone 4 ur mob every week! Just txt PT2 to 87575. 1st Tone FREE ! so get txtin now and tell ur friends. 150p/tone. 16 reply HL 4info\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\";-) ok. I feel like john lennon.\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free video camera phones with Half Price line rental for 12 mths and 500 cross ntwk mins 100 txts. Call MobileUpd8 08001950382 or Call2OptOut/674\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Er yep sure. Props?\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"&lt;#&gt;  w jetton ave if you forgot\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Detroit. The home of snow. Enjoy it.\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I've told you everything will stop. Just dont let her get dehydrated.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"WHAT TIME U WRKIN?\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"You will be receiving this week's Triple Echo ringtone shortly. Enjoy it!\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I am taking half day leave bec i am not well\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "...\n",
       "\u001b[36mvalidation\u001b[39m: \u001b[32mValidation\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free msg. Sorry, a service you ordered from 81303 could not be delivered as you do not have sufficient credit. Please top up to receive the service.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"It means u could not keep ur words.\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"YOUR CHANCE TO BE ON A REALITY FANTASY SHOW call now = 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national = rate call\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"\\\"Speak only when you feel your words are better than the silence...\\\" Gud mrng:-)\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"House-Maid is the murderer, coz the man was murdered on  &lt;#&gt; th January.. As public holiday all govt.instituitions are closed,including post office..\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"I'm hungry buy smth home...\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I think if he rule tamilnadu..then its very tough for our people.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Ok im not sure what time i finish tomorrow but i wanna spend the evening with you cos that would be vewy vewy lubly! Love me xxx\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"This message is free. Welcome to the new & improved Sex & Dogging club! To unsubscribe from this service reply STOP. msgs@150p 18 only\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "...\n",
       "\u001b[36mtest\u001b[39m: \u001b[32mTest\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Sorry de i went to shop.\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"I'm coming home 4 dinner.\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"At home also.\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Hello from Orange. For 1 month's free access to games, news and sport, plus 10 free texts and 20 photo messages, reply YES. Terms apply: www.orange.co.uk/ow\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Have you heard from this week?\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Cbe is really good nowadays:)lot of shop and showrooms:)city is shaping good.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Do you want a new Video handset? 750 any time any network mins? UNLIMITED TEXT? Camcorder? Reply or Call now 08000930705 for del Sat AM\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"You won't believe it but it's true. It's Incredible Txts! Reply G now to learn truly amazing things that will blow your mind. From O2FWD only 18p/txt\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT!: Your Mobile No. was awarded a £2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9755 BOX95QU\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"January Male Sale! Hot Gay chat now cheaper, call 08709222922. National rate from 1.5p/min cheap to 7.8p/min peak! To stop texts call 08712460324 (10p/min)\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Uncle Abbey! Happy New Year. Abiola\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Training = Dataset\n",
    "type Validation = Dataset\n",
    "type Test = Dataset\n",
    "\n",
    "def randomSplit(dataset: Vector[SmsSpamRecord], trainingFraction: Double, validationFraction: Double): (Training, Validation, Test) = {\n",
    "  val shuffledDataset = Random.shuffle(dataset)\n",
    "  val trainingSize = (shuffledDataset.size * trainingFraction).floor.toInt\n",
    "  val validationSize = (shuffledDataset.size * validationFraction).floor.toInt\n",
    "\n",
    "  val (training, remainingRecords) = shuffledDataset.splitAt(trainingSize)\n",
    "  val (validation, test) = remainingRecords.splitAt(validationSize)\n",
    "  (training, validation, test)\n",
    "}\n",
    "\n",
    "val (training, validation, test) = randomSplit(balancedDataset, trainingFraction = 0.7, validationFraction = 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c33bb0b-ea20-4a02-8606-a28dab16f9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Using\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.github.tototoshi.csv.CSVWriter\u001b[39m\n",
       "\u001b[36mtextHeader\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Text\"\u001b[39m\n",
       "\u001b[36mlabelHeader\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Label\"\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mwriteToCsv\u001b[39m\n",
       "\u001b[36mtrainingCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/training.csv\"\u001b[39m\n",
       "\u001b[36mvalidationCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/validation.csv\"\u001b[39m\n",
       "\u001b[36mtestCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/test.csv\"\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.github.tototoshi::scala-csv:2.0.0`\n",
    "\n",
    "import scala.util.Using\n",
    "import com.github.tototoshi.csv.CSVWriter\n",
    "\n",
    "val textHeader = \"Text\"\n",
    "val labelHeader = \"Label\"\n",
    "\n",
    "def writeToCsv(path: String, dataset: Dataset): Unit = {\n",
    "  val headers = Vector(textHeader, labelHeader)\n",
    "\n",
    "  Using.resource(CSVWriter.open(path)) { writer =>\n",
    "    val rows = dataset.map {\n",
    "      case SmsSpamRecord(text, isSpam) => Vector(text, if (isSpam) \"1\" else \"0\")\n",
    "    }\n",
    "    writer.writeAll(headers +: rows)\n",
    "  }\n",
    "}\n",
    "\n",
    "val trainingCsv = \"data/training.csv\"\n",
    "writeToCsv(trainingCsv, training)\n",
    "val validationCsv = \"data/validation.csv\"\n",
    "writeToCsv(validationCsv, validation)\n",
    "val testCsv = \"data/test.csv\"\n",
    "writeToCsv(testCsv, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ba9697-4121-41ec-ad86-4ca468d8caad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken==0.7.* in /usr/local/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/site-packages (from tiktoken==0.7.*) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/site-packages (from tiktoken==0.7.*) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"tiktoken==0.7.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac863ee-648b-40f4-bb1d-275a7b2657bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mme.shadaj.scalapy.py\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mpy.SeqConverters\u001b[39m\n",
       "\u001b[36mtiktoken\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'tiktoken' from '/usr/local/lib/python3.12/site-packages/tiktoken/__init__.py'>\n",
       "\u001b[36mtokenizer\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <Encoding 'gpt2'>\n",
       "\u001b[36mendOfTextToken\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"<|endoftext|>\"\u001b[39m\n",
       "\u001b[36mencodedEndOfTextToken\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = [50256]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`dev.scalapy::scalapy-core:0.5.3`\n",
    "\n",
    "import me.shadaj.scalapy.py\n",
    "import py.SeqConverters\n",
    "\n",
    "val tiktoken = py.module(\"tiktoken\")\n",
    "\n",
    "val tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "val endOfTextToken = \"<|endoftext|>\"\n",
    "val encodedEndOfTextToken = tokenizer.encode(endOfTextToken, allowed_special = py.Dynamic.global.set(Seq(endOfTextToken).toPythonProxy))\n",
    "println(encodedEndOfTextToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67d18733-4b85-41ed-8717-07f261b5ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.4.* in /usr/local/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (75.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch==2.4.*) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy->torch==2.4.*) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"torch==2.4.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910a813f-f2c6-4410-9c73-8687f41294ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mcom.github.tototoshi.csv.CSVReader\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mpy.PyQuote\u001b[39m\n",
       "\u001b[36mtorch\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'torch' from '/usr/local/lib/python3.12/site-packages/torch/__init__.py'>\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mTokenizer\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mSpamDataset\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.github.tototoshi.csv.CSVReader\n",
    "import py.PyQuote\n",
    "\n",
    "val torch = py.module(\"torch\")\n",
    "\n",
    "type Tokenizer = py.Dynamic\n",
    "\n",
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"from torch.utils.data import Dataset\n",
    "     |\n",
    "     |class SpamDataset(Dataset):\n",
    "     |  def __init__(self, init):\n",
    "     |    init(self)\n",
    "     |\n",
    "     |  def __getitem__(self, index):\n",
    "     |    return self.getItem(index)\n",
    "     |  \n",
    "     |  def __len__(self):\n",
    "     |    return self.len()\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def SpamDataset(\n",
    "  csvPath: String,\n",
    "  tokenizer: Tokenizer,\n",
    "  maxLength: Option[Int] = None,\n",
    "  paddingTokenId: Int = 50_256\n",
    "): py.Dynamic = {\n",
    "  val smsSpamRecords = Using.resource(CSVReader.open(csvPath)) { csvReader =>\n",
    "    csvReader.iteratorWithHeaders.map { row =>\n",
    "      SmsSpamRecord(text = row(textHeader), isSpam = row(labelHeader).toInt > 0)\n",
    "    }.toVector\n",
    "  }\n",
    "  val encodedTexts = {\n",
    "    val encodedTexts = smsSpamRecords.map(_.text).map(tokenizer.encode(_).as[Seq[Int]].toVector)\n",
    "    val padToLength = maxLength.getOrElse(encodedTexts.map(_.length).max)\n",
    "    encodedTexts.map(_.padTo(padToLength, paddingTokenId))\n",
    "  }\n",
    "    \n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.maxLength = encodedTexts.head.length\n",
    "    \n",
    "    val getItem = (index: Int) => {\n",
    "      val textTensor = torch.tensor(encodedTexts(index).toPythonProxy, dtype = torch.long)\n",
    "      val labelTensor = torch.tensor(if (smsSpamRecords(index).isSpam) 1 else 0, dtype = torch.long)\n",
    "      (textTensor, labelTensor)\n",
    "    }\n",
    "    self.getItem = getItem\n",
    "\n",
    "    val len = () => smsSpamRecords.size\n",
    "    self.len = len\n",
    "  }\n",
    "  py.Dynamic.global.SpamDataset(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db6947e-949f-465d-90f3-2588cd796fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingDataset\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <SpamDataset object at 0xffff442ebfe0>\n",
       "\u001b[36mvalidationDataset\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <SpamDataset object at 0xffff4414c200>\n",
       "\u001b[36mtestDataset\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <SpamDataset object at 0xffff4414e210>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingDataset = SpamDataset(trainingCsv, tokenizer)\n",
    "val validationDataset = SpamDataset(validationCsv, tokenizer, maxLength = Some(trainingDataset.maxLength.as[Int]))\n",
    "val testDataset = SpamDataset(testCsv, tokenizer, maxLength = Some(trainingDataset.maxLength.as[Int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9939eb92-a199-4019-91c4-67833cc92e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mbatchSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m8\u001b[39m\n",
       "\u001b[36mres14_1\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xffff5672c6f0>\n",
       "\u001b[36mtrainingLoader\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch.utils.data.dataloader.DataLoader object at 0xffff4414e330>\n",
       "\u001b[36mvalidationLoader\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch.utils.data.dataloader.DataLoader object at 0xffff4427f6b0>\n",
       "\u001b[36mtestLoader\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch.utils.data.dataloader.DataLoader object at 0xffff4427f620>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val batchSize = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "val trainingLoader = torch.utils.data.DataLoader(\n",
    "  dataset = trainingDataset, \n",
    "  batch_size = batchSize,\n",
    "  shuffle = true,\n",
    "  num_workers = 0,\n",
    "  drop_last = true\n",
    ")\n",
    "val validationLoader = torch.utils.data.DataLoader(\n",
    "  dataset = validationDataset, \n",
    "  batch_size = batchSize,\n",
    "  num_workers = 0,\n",
    "  drop_last = false\n",
    ")\n",
    "val testLoader = torch.utils.data.DataLoader(\n",
    "  dataset = testDataset, \n",
    "  batch_size = batchSize,\n",
    "  num_workers = 0,\n",
    "  drop_last = false\n",
    ")\n",
    "\n",
    "println(s\"${py.Dynamic.global.len(trainingLoader)} training batches\")\n",
    "println(s\"${py.Dynamic.global.len(validationLoader)} validation batches\")\n",
    "println(s\"${py.Dynamic.global.len(testLoader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d34644-7ac9-4277-9ae4-b6aaa38bc6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mGPTConfig\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class GPTConfig(\n",
    "  vocabularySize: Int,\n",
    "  contextLength: Int,\n",
    "  embeddingDimension: Int,\n",
    "  attentionHeadsCount: Int,\n",
    "  layersCount: Int,\n",
    "  dropoutRate: Double,\n",
    "  queryKeyValueBias: Boolean\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2dfd43d-f02c-4c1a-8eb3-817c92b539a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mTorchTensor\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mMultiHeadAttention\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type TorchTensor = py.Dynamic\n",
    "\n",
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class MultiHeadAttention(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def MultiHeadAttention(\n",
    "  inputDimension: Int,\n",
    "  outputDimension: Int,\n",
    "  dropoutProbability: Double,\n",
    "  contextLength: Int,\n",
    "  headsCount: Int,\n",
    "  queryKeyValueBias: Boolean\n",
    "): py.Dynamic = {\n",
    "  assert(outputDimension % headsCount == 0, \"Output dimension must be a multiple of heads count\")\n",
    "  val headDimension = outputDimension / headsCount\n",
    "    \n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.weightsQuery = torch.nn.Linear(inputDimension, outputDimension, bias = queryKeyValueBias)\n",
    "    self.weightsKey = torch.nn.Linear(inputDimension, outputDimension, bias = queryKeyValueBias)\n",
    "    self.weightsValue = torch.nn.Linear(inputDimension, outputDimension, bias = queryKeyValueBias)\n",
    "    self.outputProjection = torch.nn.Linear(outputDimension, outputDimension)\n",
    "    self.dropout = torch.nn.Dropout(dropoutProbability)\n",
    "    self.register_buffer(\"mask\", torch.triu(torch.ones(contextLength, contextLength), diagonal = 1))\n",
    "      \n",
    "    val forward = (batchedInputs: TorchTensor) => {\n",
    "      val (batchesCount, tokensCount, tokenDimension) = batchedInputs.shape.as[(Int, Int, Int)]\n",
    "      val queries = self.weightsQuery(batchedInputs)\n",
    "        .view(batchesCount, tokensCount, headsCount, headDimension)\n",
    "        .transpose(1, 2)\n",
    "      val keys = self.weightsKey(batchedInputs)\n",
    "        .view(batchesCount, tokensCount, headsCount, headDimension)\n",
    "        .transpose(1, 2)\n",
    "      val values = self.weightsValue(batchedInputs)\n",
    "        .view(batchesCount, tokensCount, headsCount, headDimension)\n",
    "        .transpose(1, 2)\n",
    "      val attentionScores = py\"$queries @ $keys.transpose(2, 3)\"\n",
    "      attentionScores.masked_fill_(py\"${self.mask}.bool()[:$tokensCount, :$tokensCount]\", -torch.inf)\n",
    "      val attentionWeights = self.dropout(torch.softmax(py\"$attentionScores / $headDimension**0.5\", dim = -1))\n",
    "      self.outputProjection(\n",
    "        py\"$attentionWeights @ $values\"\n",
    "          .transpose(1, 2)\n",
    "          .reshape(batchesCount, tokensCount, outputDimension)\n",
    "      )\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.MultiHeadAttention(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7799670d-e179-4188-b8c9-d9393033d141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mGELU\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "// Because it mostly uses Python operators, it's implemented fully in Python\n",
    "py.exec {\n",
    "  s\"\"\"import torch\n",
    "     |import torch.nn as nn\n",
    "     |\n",
    "     |class GELU(nn.Module):\n",
    "     |  def __init__(self):\n",
    "     |    super().__init__()\n",
    "     |\n",
    "     |  def forward(self, inputs):\n",
    "     |    return 0.5 * inputs * (\n",
    "     |      1 + torch.tanh(\n",
    "     |        torch.sqrt(torch.tensor(2.0 / torch.pi)) * (inputs + 0.044715 * torch.pow(inputs, 3))\n",
    "     |      )\n",
    "     |    )\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def GELU() = py.Dynamic.global.GELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb61e38-8be9-4729-9e86-6c90eb8de235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mFeedForward\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class FeedForward(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def FeedForward(\n",
    "  embeddingDimension: Int\n",
    "): py.Dynamic = {\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.layers = torch.nn.Sequential(\n",
    "      torch.nn.Linear(embeddingDimension, 4 * embeddingDimension),\n",
    "      GELU(),\n",
    "      torch.nn.Linear(4 * embeddingDimension, embeddingDimension)\n",
    "    )\n",
    "      \n",
    "    val forward = (inputs: TorchTensor) => self.layers(inputs)\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.FeedForward(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3a80736-2a99-4310-b59f-20edb7bbac85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mNormalizationLayer\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class NormalizationLayer(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def NormalizationLayer(\n",
    "  embeddingDimension: Int\n",
    "): py.Dynamic = {\n",
    "  val epsilon = 1e-5\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.scale = torch.nn.Parameter(torch.ones(embeddingDimension))\n",
    "    self.shift = torch.nn.Parameter(torch.zeros(embeddingDimension))\n",
    "      \n",
    "    val forward = (inputs: TorchTensor) => {\n",
    "      val mean = inputs.mean(dim = -1, keepdim = true)\n",
    "      val variance = inputs.`var`(dim = -1, keepdim = true, unbiased = false)\n",
    "      val normalizedInputs = py\"($inputs - $mean) / torch.sqrt($variance + $epsilon)\"\n",
    "      py\"${self.scale} * $normalizedInputs + ${self.shift}\"\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.NormalizationLayer(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1b07cba-e201-4209-9980-21948569c2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.chaining._\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mTransformerBlock\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.util.chaining._\n",
    "\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class TransformerBlock(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def TransformerBlock(\n",
    "  config: GPTConfig\n",
    "): py.Dynamic = {\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.multiHeadAttention = MultiHeadAttention(\n",
    "      inputDimension = config.embeddingDimension,\n",
    "      outputDimension = config.embeddingDimension,\n",
    "      dropoutProbability = config.dropoutRate,\n",
    "      contextLength = config.contextLength,\n",
    "      headsCount = config.attentionHeadsCount,\n",
    "      queryKeyValueBias = config.queryKeyValueBias\n",
    "    )\n",
    "    self.feedForward = FeedForward(config.embeddingDimension)\n",
    "    self.normalization1 = NormalizationLayer(config.embeddingDimension)\n",
    "    self.normalization2 = NormalizationLayer(config.embeddingDimension)\n",
    "    self.dropoutShortcut = torch.nn.Dropout(config.dropoutRate)\n",
    "    \n",
    "    val forward = (inputs: TorchTensor) => {\n",
    "      val shortcut = inputs\n",
    "      val newShortcut = inputs\n",
    "        .pipe(self.normalization1(_))\n",
    "        .pipe(self.multiHeadAttention(_))\n",
    "        .pipe(self.dropoutShortcut(_))\n",
    "        .pipe(o => py\"$o + $shortcut\")\n",
    "      newShortcut\n",
    "        .pipe(self.normalization2(_))\n",
    "        .pipe(self.feedForward(_))\n",
    "        .pipe(self.dropoutShortcut(_))\n",
    "        .pipe(o => py\"$o + $newShortcut\")\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.TransformerBlock(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2974f19c-5b76-4ed2-a6d7-5bca875ddaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mModel\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mGPTModel\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class GPTModel(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "type Model = py.Dynamic\n",
    "def GPTModel(\n",
    "  config: GPTConfig\n",
    "): Model = {\n",
    "  val transformerBlocks = Seq.fill(config.layersCount)(TransformerBlock(config))\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.tokenEmbeddingLayer = torch.nn.Embedding(config.vocabularySize, config.embeddingDimension)\n",
    "    self.positionEmbeddingLayer = torch.nn.Embedding(config.contextLength, config.embeddingDimension)\n",
    "    self.dropoutEmbeddingLayer = torch.nn.Dropout(config.dropoutRate)\n",
    "    self.transformerBlocksLayer = py\"nn.Sequential(*${transformerBlocks.toPythonProxy})\"\n",
    "    self.finalNormalizationLayer = NormalizationLayer(config.embeddingDimension)\n",
    "    self.outputLayer = torch.nn.Linear(config.embeddingDimension, config.vocabularySize, bias = false)\n",
    "      \n",
    "    val forward = (batchedInputs: TorchTensor) => {\n",
    "      val (_, sequenceLength) = batchedInputs.shape.as[(Int, Int)]\n",
    "      val tokenEmbeddings = self.tokenEmbeddingLayer(batchedInputs)\n",
    "      val positionEmbeddings = self.positionEmbeddingLayer(torch.arange(sequenceLength, device = batchedInputs.device))\n",
    "      py\"$tokenEmbeddings + $positionEmbeddings\"\n",
    "        .pipe(self.dropoutEmbeddingLayer(_))\n",
    "        .pipe(self.transformerBlocksLayer(_))\n",
    "        .pipe(self.finalNormalizationLayer(_))\n",
    "        .pipe(self.outputLayer(_))\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.GPTModel(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e2bb752-7eb2-4fcb-9e0d-425bbb51f8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbaseUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2/124M\"\u001b[39m\n",
       "\u001b[36mhparamsFilename\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"hparams.json\"\u001b[39m\n",
       "\u001b[36mfilenames\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m\"checkpoint\"\u001b[39m,\n",
       "  \u001b[32m\"encoder.json\"\u001b[39m,\n",
       "  \u001b[32m\"hparams.json\"\u001b[39m,\n",
       "  \u001b[32m\"model.ckpt.data-00000-of-00001\"\u001b[39m,\n",
       "  \u001b[32m\"model.ckpt.index\"\u001b[39m,\n",
       "  \u001b[32m\"model.ckpt.meta\"\u001b[39m,\n",
       "  \u001b[32m\"vocab.bpe\"\u001b[39m\n",
       ")\n",
       "\u001b[36moutputDir\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/openai124M\"\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val baseUrl = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2/124M\"\n",
    "// val baseUrl = \"https://openaipublic.blob.core.windows.net/gpt-2/models/124M\" // backup\n",
    "val hparamsFilename = \"hparams.json\"\n",
    "val filenames = List(\"checkpoint\", \"encoder.json\", hparamsFilename, \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\", \"model.ckpt.meta\", \"vocab.bpe\")\n",
    "\n",
    "val outputDir = \"data/openai124M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff93551d-b4f8-42e8-8ff7-9394cb75125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    77  100    77    0     0     67      0  0:00:01  0:00:01 --:--:--    67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading encoder.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  3 1017k    3 40522    0     0  31553      0  0:00:33  0:00:01  0:00:32 31534\n",
      "100 1017k  100 1017k    0     0   457k      0  0:00:02  0:00:02 --:--:--  457k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading hparams.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    90  100    90    0     0    101      0 --:--:-- --:--:-- --:--:--   101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model.ckpt.data-00000-of-00001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  474M    0 81421    0     0  71722      0  1:55:40  0:00:01  1:55:39 71673\n",
      "  0  474M    0 3239k    0     0  1522k      0  0:05:19  0:00:02  0:05:17 1522k\n",
      "  3  474M    3 18.5M    0     0  6070k      0  0:01:20  0:00:03  0:01:17 6068k\n",
      "  6  474M    6 33.1M    0     0  8213k      0  0:00:59  0:00:04  0:00:55 8213k\n",
      " 10  474M   10 48.3M    0     0  9645k      0  0:00:50  0:00:05  0:00:45  9.8M\n",
      " 13  474M   13 63.0M    0     0  10.2M      0  0:00:46  0:00:06  0:00:40 12.6M\n",
      " 16  474M   16 78.5M    0     0  10.9M      0  0:00:43  0:00:07  0:00:36 14.8M\n",
      " 19  474M   19 93.8M    0     0  11.5M      0  0:00:41  0:00:08  0:00:33 15.0M\n",
      " 22  474M   22  107M    0     0  11.7M      0  0:00:40  0:00:09  0:00:31 14.7M\n",
      " 25  474M   25  122M    0     0  12.0M      0  0:00:39  0:00:10  0:00:29 14.7M\n",
      " 28  474M   28  137M    0     0  12.3M      0  0:00:38  0:00:11  0:00:27 14.9M\n",
      " 32  474M   32  152M    0     0  12.5M      0  0:00:37  0:00:12  0:00:25 14.9M\n",
      " 33  474M   33  159M    0     0  12.1M      0  0:00:38  0:00:13  0:00:25 13.1M\n",
      " 37  474M   37  176M    0     0  12.4M      0  0:00:38  0:00:14  0:00:24 13.8M\n",
      " 40  474M   40  190M    0     0  12.6M      0  0:00:37  0:00:15  0:00:22 13.7M\n",
      " 43  474M   43  206M    0     0  12.7M      0  0:00:37  0:00:16  0:00:21 13.7M\n",
      " 46  474M   46  220M    0     0  12.8M      0  0:00:36  0:00:17  0:00:19 13.6M\n",
      " 49  474M   49  235M    0     0  12.9M      0  0:00:36  0:00:18  0:00:18 15.1M\n",
      " 52  474M   52  250M    0     0  13.1M      0  0:00:36  0:00:19  0:00:17 14.8M\n",
      " 56  474M   56  267M    0     0  13.2M      0  0:00:35  0:00:20  0:00:15 15.3M\n",
      " 59  474M   59  283M    0     0  13.3M      0  0:00:35  0:00:21  0:00:14 15.3M\n",
      " 62  474M   62  298M    0     0  13.4M      0  0:00:35  0:00:22  0:00:13 15.2M\n",
      " 66  474M   66  313M    0     0  13.5M      0  0:00:35  0:00:23  0:00:12 15.6M\n",
      " 69  474M   69  329M    0     0  13.6M      0  0:00:34  0:00:24  0:00:10 15.6M\n",
      " 72  474M   72  345M    0     0  13.7M      0  0:00:34  0:00:25  0:00:09 15.4M\n",
      " 76  474M   76  360M    0     0  13.8M      0  0:00:34  0:00:26  0:00:08 15.5M\n",
      " 79  474M   79  376M    0     0  13.8M      0  0:00:34  0:00:27  0:00:07 15.8M\n",
      " 80  474M   80  383M    0     0  13.6M      0  0:00:34  0:00:28  0:00:06 13.8M\n",
      " 83  474M   83  398M    0     0  13.6M      0  0:00:34  0:00:29  0:00:05 13.9M\n",
      " 87  474M   87  413M    0     0  13.7M      0  0:00:34  0:00:30  0:00:04 13.7M\n",
      " 90  474M   90  429M    0     0  13.7M      0  0:00:34  0:00:31  0:00:03 13.6M\n",
      " 93  474M   93  445M    0     0  13.8M      0  0:00:34  0:00:32  0:00:02 13.7M\n",
      " 96  474M   96  460M    0     0  13.8M      0  0:00:34  0:00:33  0:00:01 15.3M\n",
      "100  474M  100  474M    0     0  13.9M      0  0:00:34  0:00:34 --:--:-- 15.4M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model.ckpt.index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  5215  100  5215    0     0   7777      0 --:--:-- --:--:-- --:--:--  7771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model.ckpt.meta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 24  460k   24  111k    0     0  84757      0  0:00:05  0:00:01  0:00:04 84747\n",
      "100  460k  100  460k    0     0   268k      0  0:00:01  0:00:01 --:--:--  268k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab.bpe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  445k  100  445k    0     0   288k      0  0:00:01  0:00:01 --:--:--  288k\n"
     ]
    }
   ],
   "source": [
    "filenames.foreach { filename =>\n",
    "  println(s\"Downloading $filename...\")\n",
    "  Magic.!(\"curl\", \"--create-dirs\", \"-O\", \"--output-dir\", outputDir, s\"$baseUrl/$filename\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba140fe2-fc98-46cb-b3aa-5f76b94e332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.16.* in /usr/local/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.*) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.*) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"tensorflow==2.16.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17d95f90-6312-4cab-9434-73d340ee1a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\u001b[39m\n",
       "\u001b[36mhparamsMap\u001b[39m: \u001b[32mujson\u001b[39m.\u001b[32mValue\u001b[39m.\u001b[32mValue\u001b[39m = \u001b[33mObj\u001b[39m(\n",
       "  value = \u001b[33mMap\u001b[39m(\n",
       "    \u001b[32m\"n_vocab\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m50257.0\u001b[39m),\n",
       "    \u001b[32m\"n_ctx\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m1024.0\u001b[39m),\n",
       "    \u001b[32m\"n_embd\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m768.0\u001b[39m),\n",
       "    \u001b[32m\"n_head\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m12.0\u001b[39m),\n",
       "    \u001b[32m\"n_layer\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m12.0\u001b[39m)\n",
       "  )\n",
       ")\n",
       "\u001b[36mgptConfig\u001b[39m: \u001b[32mGPTConfig\u001b[39m = \u001b[33mGPTConfig\u001b[39m(\n",
       "  vocabularySize = \u001b[32m50257\u001b[39m,\n",
       "  contextLength = \u001b[32m1024\u001b[39m,\n",
       "  embeddingDimension = \u001b[32m768\u001b[39m,\n",
       "  attentionHeadsCount = \u001b[32m12\u001b[39m,\n",
       "  layersCount = \u001b[32m12\u001b[39m,\n",
       "  dropoutRate = \u001b[32m0.1\u001b[39m,\n",
       "  queryKeyValueBias = \u001b[32mtrue\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.lihaoyi::ujson:4.1.0`\n",
    "\n",
    "import scala.io.Source\n",
    "\n",
    "val hparamsMap = ujson.read(Source.fromFile(s\"$outputDir/$hparamsFilename\").mkString)\n",
    "\n",
    "val gptConfig = GPTConfig(\n",
    "  vocabularySize = hparamsMap(\"n_vocab\").num.toInt,\n",
    "  contextLength = hparamsMap(\"n_ctx\").num.toInt,\n",
    "  embeddingDimension = hparamsMap(\"n_embd\").num.toInt,\n",
    "  attentionHeadsCount = hparamsMap(\"n_head\").num.toInt,\n",
    "  layersCount = hparamsMap(\"n_layer\").num.toInt,\n",
    "  dropoutRate = 0.1,\n",
    "  queryKeyValueBias = true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc8b8a66-3bbe-41d2-a719-8fbe8c1023cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtf\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'tensorflow' from '/usr/local/lib/python3.12/site-packages/tensorflow/__init__.py'>\n",
       "\u001b[36mnp\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'numpy' from '/usr/local/lib/python3.12/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tf = py.module(\"tensorflow\")\n",
    "val np = py.module(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a353053b-7a30-45b9-8c63-6166a708a832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/h0/attn/c_attn/b\n",
      "model/h0/attn/c_attn/w\n",
      "model/h0/attn/c_proj/b\n",
      "model/h0/attn/c_proj/w\n",
      "model/h0/ln_1/b\n",
      "model/h0/ln_1/g\n",
      "model/h0/ln_2/b\n",
      "model/h0/ln_2/g\n",
      "model/h0/mlp/c_fc/b\n",
      "model/h0/mlp/c_fc/w\n",
      "model/h0/mlp/c_proj/b\n",
      "model/h0/mlp/c_proj/w\n",
      "model/h1/attn/c_attn/b\n",
      "model/h1/attn/c_attn/w\n",
      "model/h1/attn/c_proj/b\n",
      "model/h1/attn/c_proj/w\n",
      "model/h1/ln_1/b\n",
      "model/h1/ln_1/g\n",
      "model/h1/ln_2/b\n",
      "model/h1/ln_2/g\n",
      "model/h1/mlp/c_fc/b\n",
      "model/h1/mlp/c_fc/w\n",
      "model/h1/mlp/c_proj/b\n",
      "model/h1/mlp/c_proj/w\n",
      "model/h10/attn/c_attn/b\n",
      "model/h10/attn/c_attn/w\n",
      "model/h10/attn/c_proj/b\n",
      "model/h10/attn/c_proj/w\n",
      "model/h10/ln_1/b\n",
      "model/h10/ln_1/g\n",
      "model/h10/ln_2/b\n",
      "model/h10/ln_2/g\n",
      "model/h10/mlp/c_fc/b\n",
      "model/h10/mlp/c_fc/w\n",
      "model/h10/mlp/c_proj/b\n",
      "model/h10/mlp/c_proj/w\n",
      "model/h11/attn/c_attn/b\n",
      "model/h11/attn/c_attn/w\n",
      "model/h11/attn/c_proj/b\n",
      "model/h11/attn/c_proj/w\n",
      "model/h11/ln_1/b\n",
      "model/h11/ln_1/g\n",
      "model/h11/ln_2/b\n",
      "model/h11/ln_2/g\n",
      "model/h11/mlp/c_fc/b\n",
      "model/h11/mlp/c_fc/w\n",
      "model/h11/mlp/c_proj/b\n",
      "model/h11/mlp/c_proj/w\n",
      "model/h2/attn/c_attn/b\n",
      "model/h2/attn/c_attn/w\n",
      "model/h2/attn/c_proj/b\n",
      "model/h2/attn/c_proj/w\n",
      "model/h2/ln_1/b\n",
      "model/h2/ln_1/g\n",
      "model/h2/ln_2/b\n",
      "model/h2/ln_2/g\n",
      "model/h2/mlp/c_fc/b\n",
      "model/h2/mlp/c_fc/w\n",
      "model/h2/mlp/c_proj/b\n",
      "model/h2/mlp/c_proj/w\n",
      "model/h3/attn/c_attn/b\n",
      "model/h3/attn/c_attn/w\n",
      "model/h3/attn/c_proj/b\n",
      "model/h3/attn/c_proj/w\n",
      "model/h3/ln_1/b\n",
      "model/h3/ln_1/g\n",
      "model/h3/ln_2/b\n",
      "model/h3/ln_2/g\n",
      "model/h3/mlp/c_fc/b\n",
      "model/h3/mlp/c_fc/w\n",
      "model/h3/mlp/c_proj/b\n",
      "model/h3/mlp/c_proj/w\n",
      "model/h4/attn/c_attn/b\n",
      "model/h4/attn/c_attn/w\n",
      "model/h4/attn/c_proj/b\n",
      "model/h4/attn/c_proj/w\n",
      "model/h4/ln_1/b\n",
      "model/h4/ln_1/g\n",
      "model/h4/ln_2/b\n",
      "model/h4/ln_2/g\n",
      "model/h4/mlp/c_fc/b\n",
      "model/h4/mlp/c_fc/w\n",
      "model/h4/mlp/c_proj/b\n",
      "model/h4/mlp/c_proj/w\n",
      "model/h5/attn/c_attn/b\n",
      "model/h5/attn/c_attn/w\n",
      "model/h5/attn/c_proj/b\n",
      "model/h5/attn/c_proj/w\n",
      "model/h5/ln_1/b\n",
      "model/h5/ln_1/g\n",
      "model/h5/ln_2/b\n",
      "model/h5/ln_2/g\n",
      "model/h5/mlp/c_fc/b\n",
      "model/h5/mlp/c_fc/w\n",
      "model/h5/mlp/c_proj/b\n",
      "model/h5/mlp/c_proj/w\n",
      "model/h6/attn/c_attn/b\n",
      "model/h6/attn/c_attn/w\n",
      "model/h6/attn/c_proj/b\n",
      "model/h6/attn/c_proj/w\n",
      "model/h6/ln_1/b\n",
      "model/h6/ln_1/g\n",
      "model/h6/ln_2/b\n",
      "model/h6/ln_2/g\n",
      "model/h6/mlp/c_fc/b\n",
      "model/h6/mlp/c_fc/w\n",
      "model/h6/mlp/c_proj/b\n",
      "model/h6/mlp/c_proj/w\n",
      "model/h7/attn/c_attn/b\n",
      "model/h7/attn/c_attn/w\n",
      "model/h7/attn/c_proj/b\n",
      "model/h7/attn/c_proj/w\n",
      "model/h7/ln_1/b\n",
      "model/h7/ln_1/g\n",
      "model/h7/ln_2/b\n",
      "model/h7/ln_2/g\n",
      "model/h7/mlp/c_fc/b\n",
      "model/h7/mlp/c_fc/w\n",
      "model/h7/mlp/c_proj/b\n",
      "model/h7/mlp/c_proj/w\n",
      "model/h8/attn/c_attn/b\n",
      "model/h8/attn/c_attn/w\n",
      "model/h8/attn/c_proj/b\n",
      "model/h8/attn/c_proj/w\n",
      "model/h8/ln_1/b\n",
      "model/h8/ln_1/g\n",
      "model/h8/ln_2/b\n",
      "model/h8/ln_2/g\n",
      "model/h8/mlp/c_fc/b\n",
      "model/h8/mlp/c_fc/w\n",
      "model/h8/mlp/c_proj/b\n",
      "model/h8/mlp/c_proj/w\n",
      "model/h9/attn/c_attn/b\n",
      "model/h9/attn/c_attn/w\n",
      "model/h9/attn/c_proj/b\n",
      "model/h9/attn/c_proj/w\n",
      "model/h9/ln_1/b\n",
      "model/h9/ln_1/g\n",
      "model/h9/ln_2/b\n",
      "model/h9/ln_2/g\n",
      "model/h9/mlp/c_fc/b\n",
      "model/h9/mlp/c_fc/w\n",
      "model/h9/mlp/c_proj/b\n",
      "model/h9/mlp/c_proj/w\n",
      "model/ln_f/b\n",
      "model/ln_f/g\n",
      "model/wpe\n",
      "model/wte\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcheckpoint\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = data/openai124M/model.ckpt\n",
       "\u001b[36mvariableNames\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m\"model/h0/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/attn/c_attn/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/attn/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/attn/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_1/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_1/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_2/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_2/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_fc/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_fc/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_attn/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_1/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_1/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_2/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_2/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_fc/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_fc/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_attn/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_1/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_1/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_2/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_2/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_fc/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_fc/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h11/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h11/attn/c_attn/w\"\u001b[39m,\n",
       "..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val checkpoint = tf.train.latest_checkpoint(outputDir)\n",
    "val variableNames = tf.train.list_variables(checkpoint).as[Seq[(String, Seq[Int])]].map { \n",
    "  case (variableName, _) => variableName \n",
    "}.toList\n",
    "variableNames.sorted.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11392e9f-eb7c-4a1a-a892-2a37e04d9298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd28.sc:18: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd28.sc:29: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd28.sc:15: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"c_attn\", \"c_proj\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd28.sc:37: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"g\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd28.sc:44: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"g\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd28.sc:53: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd28.sc:59: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd28.sc:50: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"c_fc\", \"c_proj\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd28.sc:12: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"attn\", \"ln_1\", \"ln_2\", \"mlp\"))), Nil\n",
      "        tail match {\n",
      "        ^\n",
      "cmd28.sc:68: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"g\"))), Nil\n",
      "        tail match {\n",
      "        ^\n",
      "cmd28.sc:9: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"ln_f\", \"wpe\", \"wte\"))), Nil\n",
      "    variableName.split(\"/\").drop(1).toList match {\n",
      "                                    ^\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mNpArray\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtoTorchParameter\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mloadModelWeights\u001b[39m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type NpArray = py.Dynamic\n",
    "\n",
    "def toTorchParameter(npArray: NpArray) =\n",
    "  torch.nn.Parameter(torch.tensor(npArray))\n",
    "\n",
    "def loadModelWeights(model: Model): Unit =\n",
    "  variableNames.foreach { variableName =>\n",
    "    val variableValue = np.squeeze(tf.train.load_variable(checkpoint, variableName))\n",
    "    variableName.split(\"/\").drop(1).toList match {\n",
    "      case s\"h$transformerBlockIndexString\" :: tail =>\n",
    "        val transformerBlockIndex = transformerBlockIndexString.toInt\n",
    "        tail match {\n",
    "          case \"attn\" :: tail =>\n",
    "            val multiHeadAttention = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).multiHeadAttention\n",
    "            tail match {\n",
    "              case \"c_attn\" :: tail =>\n",
    "                val Seq(queryVariableValue, keyVariableValue, valueVariableValue) = np.split(variableValue, 3, axis = -1).as[Seq[NpArray]]\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => \n",
    "                    multiHeadAttention.weightsQuery.bias = toTorchParameter(queryVariableValue)\n",
    "                    multiHeadAttention.weightsKey.bias = toTorchParameter(keyVariableValue)\n",
    "                    multiHeadAttention.weightsValue.bias = toTorchParameter(valueVariableValue)\n",
    "                  case \"w\" :: _ => \n",
    "                    multiHeadAttention.weightsQuery.weight = toTorchParameter(queryVariableValue.T)\n",
    "                    multiHeadAttention.weightsKey.weight = toTorchParameter(keyVariableValue.T)\n",
    "                    multiHeadAttention.weightsValue.weight = toTorchParameter(valueVariableValue.T)\n",
    "                }\n",
    "              case \"c_proj\" :: tail =>\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => multiHeadAttention.outputProjection.bias = toTorchParameter(variableValue)\n",
    "                  case \"w\" :: _ => multiHeadAttention.outputProjection.weight = toTorchParameter(variableValue.T)\n",
    "                }\n",
    "            }\n",
    "          case \"ln_1\" :: tail =>\n",
    "            val normalization1 = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).normalization1\n",
    "            val torchParameter = toTorchParameter(variableValue)\n",
    "            tail match {\n",
    "              case \"b\" :: _ => normalization1.shift = torchParameter\n",
    "              case \"g\" :: _ => normalization1.scale = torchParameter\n",
    "            }\n",
    "          case \"ln_2\" :: tail =>\n",
    "            val normalization2 = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).normalization2\n",
    "            val torchParameter = toTorchParameter(variableValue)\n",
    "            tail match {\n",
    "              case \"b\" :: _ => normalization2.shift = torchParameter\n",
    "              case \"g\" :: _ => normalization2.scale = torchParameter\n",
    "            }\n",
    "          case \"mlp\" :: tail =>\n",
    "            val feedForward = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).feedForward\n",
    "            tail match {\n",
    "              case \"c_fc\" :: tail =>\n",
    "                val layer0 = feedForward.layers.bracketAccess(0)\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => layer0.bias = toTorchParameter(variableValue)\n",
    "                  case \"w\" :: _ => layer0.weight = toTorchParameter(variableValue.T)\n",
    "                }\n",
    "              case \"c_proj\" :: tail =>\n",
    "                val layer2 = feedForward.layers.bracketAccess(2)\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => layer2.bias = toTorchParameter(variableValue)\n",
    "                  case \"w\" :: _ => layer2.weight = toTorchParameter(variableValue.T)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "      case \"ln_f\" :: tail =>\n",
    "        val finalNormalizationLayer = model.finalNormalizationLayer\n",
    "        val torchParameter = toTorchParameter(variableValue)\n",
    "        tail match {\n",
    "          case \"b\" :: _ => finalNormalizationLayer.shift = torchParameter\n",
    "          case \"g\" :: _ => finalNormalizationLayer.scale = torchParameter\n",
    "        }\n",
    "      case \"wpe\" :: _ => model.positionEmbeddingLayer.weight = toTorchParameter(variableValue)\n",
    "      case \"wte\" :: _ => \n",
    "        val torchParameter = toTorchParameter(variableValue)\n",
    "        model.tokenEmbeddingLayer.weight = torchParameter\n",
    "        model.outputLayer.weight = torchParameter\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2d088fe-9916-4b26-8a8f-9b0c835e92bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodel\u001b[39m: \u001b[32mModel\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36mdevice\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = cpu\n",
       "\u001b[36mres29_3\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36mres29_4\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = GPTModel(gptConfig)\n",
    "loadModelWeights(model)\n",
    "val device = torch.device(if (torch.cuda.is_available().as[Boolean]) \"cuda\" else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0326838d-0cec-4330-9f6a-3972cd501fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtextToTokenIds\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtokenIdsToText\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgenerateTextSimple\u001b[39m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def textToTokenIds(\n",
    "  text: String, \n",
    "  tokenizer: Tokenizer\n",
    "): TorchTensor = {\n",
    "  val allowedSpecial = py.Dynamic.global.set(Seq(\"<|endoftext|>\").toPythonProxy)\n",
    "  val encodedText = tokenizer.encode(text, allowed_special = allowedSpecial)\n",
    "  torch.tensor(encodedText).unsqueeze(0)\n",
    "}\n",
    "    \n",
    "def tokenIdsToText(\n",
    "  tokenIds: TorchTensor, \n",
    "  tokenizer: Tokenizer\n",
    "): String =\n",
    "  tokenizer.decode(tokenIds.squeeze(0).tolist()).as[String]\n",
    "\n",
    "def generateTextSimple(\n",
    "  model: Model,\n",
    "  maxNewTokens: Int,\n",
    "  contextLength: Int\n",
    ")(\n",
    "  encodedInput: TorchTensor\n",
    "): TorchTensor =\n",
    "  LazyList.iterate(encodedInput) { currentEncodedOutput =>\n",
    "    val croppedInput = py\"$currentEncodedOutput[:, -$contextLength:]\"\n",
    "    val logits = py.`with`(torch.no_grad()) { _ =>\n",
    "      model(croppedInput)\n",
    "    }\n",
    "    py\"$logits[:, -1, :]\"\n",
    "      .pipe(torch.softmax(_, dim = -1))\n",
    "      .pipe(torch.argmax(_, dim = -1, keepdim = true))\n",
    "      .pipe(nextEncodedOutput => torch.cat((currentEncodedOutput, nextEncodedOutput), dim = 1))\n",
    "  }.drop(maxNewTokens).head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e05a5396-3059-414c-852d-cc5092ea59e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mexampleText\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Every effort moves you\"\u001b[39m\n",
       "\u001b[36mencodedText\u001b[39m: \u001b[32mTorchTensor\u001b[39m = tensor([[6109, 3626, 6100,  345]])\n",
       "\u001b[36mencodedTextOutput\u001b[39m: \u001b[32mTorchTensor\u001b[39m = tensor([[6109, 3626, 6100,  345, 2651,   13,  198,  198,  464,  717, 2239,  318,\n",
       "          284, 1833,  262, 6817,  286,  534,  670]])\n",
       "\u001b[36mdecodedTextOutput\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"Every effort moves you forward.\n",
       "\n",
       "The first step is to understand the importance of your work\"\"\"\u001b[39m"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val exampleText = \"Every effort moves you\"\n",
    "val encodedText = textToTokenIds(exampleText, tokenizer)\n",
    "val encodedTextOutput = generateTextSimple(model, maxNewTokens = 15, contextLength = gptConfig.contextLength)(encodedText)\n",
    "val decodedTextOutput = tokenIdsToText(encodedTextOutput, tokenizer)\n",
    "println(decodedTextOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75388780-9ff8-49f1-985f-f4958b339296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text spam? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text spam? Answer with 'yes' or 'no': 'You are a winner you have\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspamClassificationPrompt\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Is the following text spam? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\"\u001b[39m\n",
       "\u001b[36mspamClassificationPromptAnswer\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"Is the following text spam? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
       "\n",
       "The following text spam? Answer with 'yes' or 'no': 'You are a winner you have\"\"\"\u001b[39m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spamClassificationPrompt = \"Is the following text spam? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\"\n",
    "val spamClassificationPromptAnswer = \n",
    "  textToTokenIds(spamClassificationPrompt, tokenizer)\n",
    "    .pipe(generateTextSimple(model, maxNewTokens = 23, contextLength = gptConfig.contextLength))\n",
    "    .pipe(tokenIdsToText(_, tokenizer))\n",
    "println(spamClassificationPromptAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cb4db64-577c-48aa-9533-0c6a703bb6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.annotation.tailrec\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mforeachPy\u001b[39m"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.annotation.tailrec\n",
    "\n",
    "def foreachPy(iterable: py.Dynamic)(f: py.Dynamic => Unit): Unit = {\n",
    "  val iterator = py\"iter($iterable)\"\n",
    "\n",
    "  @tailrec\n",
    "  def loop(): Unit = {\n",
    "    val currentValue = py\"next($iterator, None)\"\n",
    "    if (currentValue != py.Dynamic.global.None) {\n",
    "      f(currentValue)\n",
    "      loop()\n",
    "    }\n",
    "  }\n",
    "\n",
    "  loop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51a622c0-0d1b-4b74-9d4f-fc719e27de15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres34_1\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xffff5672c6f0>\n",
       "\u001b[36mclassesCount\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m2\u001b[39m"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreachPy(model.parameters()) { parameter =>\n",
    "  parameter.requires_grad = false\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "val classesCount = 2\n",
    "model.outputLayer = torch.nn.Linear(\n",
    "  in_features = gptConfig.embeddingDimension,\n",
    "  out_features = classesCount\n",
    ")\n",
    "\n",
    "foreachPy(model.transformerBlocksLayer.bracketAccess(-1).parameters()) { parameter =>\n",
    "  parameter.requires_grad = true\n",
    "}\n",
    "\n",
    "foreachPy(model.finalNormalizationLayer.parameters()) { parameter =>\n",
    "  parameter.requires_grad = true\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc38427f-3f23-47bf-b56a-1f18d832f81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mDevice\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mDataLoader\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcalculateDataLoaderAccuracy\u001b[39m"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Device = py.Dynamic\n",
    "type DataLoader = py.Dynamic\n",
    "\n",
    "def calculateDataLoaderAccuracy(\n",
    "  model: Model,\n",
    "  device: Device\n",
    ")(\n",
    "  dataLoader: DataLoader,\n",
    "  batchesCountOpt: Option[Int] = None\n",
    "): Double = { \n",
    "  val batchesCount = batchesCountOpt match {\n",
    "    case Some(batchesCount) => batchesCount\n",
    "    case None => py\"len($dataLoader)\".as[Int]\n",
    "  }\n",
    "  assert(batchesCount > 0, \"There were no batches to process\")\n",
    "  var correctPredictions = 0\n",
    "  var examplesSeen = 0\n",
    "  var currentBatchIndex = 0\n",
    "  foreachPy(dataLoader) { currentBatch =>\n",
    "    if (currentBatchIndex < batchesCount) \n",
    "      py.local {\n",
    "        val Seq(inputBatch, targetBatch) = currentBatch.as[Seq[TorchTensor]]\n",
    "        val logits = py.`with`(torch.no_grad()) { _ =>\n",
    "          model(inputBatch.to(device))\n",
    "        }\n",
    "        val predictedClasses = torch.argmax(py\"$logits[:, -1, :]\", dim = -1)\n",
    "        examplesSeen += predictedClasses.shape.bracketAccess(0).as[Int]\n",
    "        correctPredictions += py\"$predictedClasses == $targetBatch\".sum().item().as[Int]\n",
    "      }\n",
    "    currentBatchIndex += 1\n",
    "  }\n",
    "  correctPredictions.toDouble / examplesSeen\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1307302-ee7e-4eb4-8ca7-d871baa17ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 55.00%\n",
      "Validation accuracy: 55.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres36_0\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xffff5672c6f0>\n",
       "\u001b[36mtrainingAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.55\u001b[39m\n",
       "\u001b[36mvalidationAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.55\u001b[39m\n",
       "\u001b[36mtestAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.4875\u001b[39m"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "val trainingAccuracy = calculateDataLoaderAccuracy(model, device)(trainingLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Training accuracy: ${trainingAccuracy * 100}%.2f%%\")\n",
    "val validationAccuracy = calculateDataLoaderAccuracy(model, device)(validationLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Validation accuracy: ${validationAccuracy * 100}%.2f%%\")\n",
    "val testAccuracy = calculateDataLoaderAccuracy(model, device)(testLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Test accuracy: ${testAccuracy * 100}%.2f%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d94da9a-a636-467b-9194-d110d1eef072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcalculateBatchLoss\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcalculateDataLoaderLoss\u001b[39m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateBatchLoss(\n",
    "  model: Model,\n",
    "  device: Device\n",
    ")(\n",
    "  inputBatch: TorchTensor,\n",
    "  targetBatch: TorchTensor\n",
    "): TorchTensor = {\n",
    "  val logits = model(inputBatch.to(device))\n",
    "  torch.nn.functional.cross_entropy(py\"$logits[:, -1, :]\", targetBatch.to(device))\n",
    "}\n",
    "\n",
    "def calculateDataLoaderLoss(\n",
    "  model: Model,\n",
    "  device: Device\n",
    ")(\n",
    "  dataLoader: DataLoader,\n",
    "  batchesCountOpt: Option[Int] = None\n",
    "): Double = { \n",
    "  val batchesCount = batchesCountOpt match {\n",
    "    case Some(batchesCount) => batchesCount\n",
    "    case None => py\"len($dataLoader)\".as[Int]\n",
    "  }\n",
    "  assert(batchesCount > 0, \"There were no batches to process\")\n",
    "  var totalLoss = 0.0\n",
    "  var currentBatchIndex = 0\n",
    "  foreachPy(dataLoader) { currentBatch =>\n",
    "    if (currentBatchIndex < batchesCount) \n",
    "      py.local {\n",
    "        val Seq(inputBatch, targetBatch) = currentBatch.as[Seq[TorchTensor]]\n",
    "        totalLoss += calculateBatchLoss(model, device)(inputBatch, targetBatch).item().as[Double]\n",
    "      }\n",
    "    currentBatchIndex += 1\n",
    "  }\n",
    "  totalLoss / batchesCount\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59857197-4ef6-4ed8-ac2e-b973fe2381cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.6738205671310424\n",
      "Validation loss: 2.060702216625214\n",
      "Test loss: 2.308347225189209\n"
     ]
    }
   ],
   "source": [
    "py.`with`(torch.no_grad()) { _ =>\n",
    "  val trainingLoss = calculateDataLoaderLoss(model, device)(trainingLoader, batchesCountOpt = Some(5))\n",
    "  println(s\"Training loss: $trainingLoss\")\n",
    "  val validationLoss = calculateDataLoaderLoss(model, device)(validationLoader, batchesCountOpt = Some(5))\n",
    "  println(s\"Validation loss: $validationLoss\")\n",
    "  val testLoss = calculateDataLoaderLoss(model, device)(testLoader, batchesCountOpt = Some(5))\n",
    "  println(s\"Test loss: $testLoss\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2629323-80e7-4a4d-8473-590f27fb3eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mLoss\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mTrainingStep\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mAccuracy\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mTrainingEpoch\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mModelEvaluator\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mOptimizer\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtrainClassifierSimple\u001b[39m"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Loss(\n",
    "  trainingLoss: Double,\n",
    "  validationLoss: Double\n",
    ")\n",
    "\n",
    "case class TrainingStep(\n",
    "  loss: Loss,\n",
    "  examplesSeen: Long\n",
    ")\n",
    "\n",
    "case class Accuracy(\n",
    "  trainingAccuracy: Double,\n",
    "  validationAccuracy: Double\n",
    ")\n",
    "\n",
    "case class TrainingEpoch(\n",
    "  trainingSteps: List[TrainingStep],\n",
    "  accuracy: Accuracy\n",
    ")\n",
    "\n",
    "class ModelEvaluator(\n",
    "  device: Device,\n",
    "  trainingLoader: DataLoader,\n",
    "  validationLoader: DataLoader,\n",
    "  evaluationEpochsCount: Int,\n",
    "  evaluationFrequencySteps: Int\n",
    ") {\n",
    "\n",
    "  def calculateLossCond(currentStep: Int)(model: Model): Option[Loss] =\n",
    "    Option.when(currentStep % evaluationFrequencySteps == 0) {\n",
    "      println(s\"Step $currentStep\")\n",
    "      calculateLoss(model)\n",
    "    }\n",
    "    \n",
    "  def calculateLoss(model: Model): Loss = {\n",
    "    model.eval()\n",
    "    py.`with`(torch.no_grad()) { _ =>\n",
    "      val trainingLoss = calculateDataLoaderLoss(model, device)(trainingLoader, batchesCountOpt = Some(evaluationEpochsCount))\n",
    "      val validationLoss = calculateDataLoaderLoss(model, device)(validationLoader, batchesCountOpt = Some(evaluationEpochsCount))\n",
    "      println(\n",
    "        s\"\"\"- training loss: $trainingLoss\n",
    "           |- validation loss: $validationLoss\"\"\".stripMargin\n",
    "      )\n",
    "      model.train()\n",
    "      Loss(trainingLoss, validationLoss)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  def calculateAccuracy(model: Model): Accuracy = {\n",
    "    model.eval()\n",
    "    py.`with`(torch.no_grad()) { _ =>\n",
    "      val trainingAccuracy = calculateDataLoaderAccuracy(model, device)(trainingLoader, batchesCountOpt = Some(evaluationEpochsCount))\n",
    "      val validationAccuracy = calculateDataLoaderAccuracy(model, device)(validationLoader, batchesCountOpt = Some(evaluationEpochsCount))\n",
    "      println(\n",
    "        f\"\"\"Training accuracy: ${trainingAccuracy * 100}%.2f%%\n",
    "           |Validation accuracy: ${validationAccuracy * 100}%.2f%%\"\"\".stripMargin\n",
    "      )\n",
    "      model.train()\n",
    "      Accuracy(trainingAccuracy, validationAccuracy)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "type Optimizer = py.Dynamic\n",
    "def trainClassifierSimple(\n",
    "  model: Model,\n",
    "  device: Device,\n",
    "  trainingLoader: DataLoader,\n",
    "  validationLoader: DataLoader,\n",
    "  optimizer: Optimizer,\n",
    "  epochsCount: Int,\n",
    "  modelEvaluator: ModelEvaluator\n",
    "): List[TrainingEpoch] = {\n",
    "  var stepsCount = 0\n",
    "  var examplesSeen = 0L\n",
    "  val trainingEpochs =\n",
    "    for {\n",
    "      epoch <- 1 to epochsCount\n",
    "    } yield py.local {\n",
    "      println(s\"=> Epoch $epoch\")\n",
    "      model.train()\n",
    "      val trainingSteps = mutable.ListBuffer[TrainingStep]()\n",
    "      foreachPy(trainingLoader) { batch =>\n",
    "        py.local {\n",
    "          val Seq(inputBatch, targetBatch) = batch.as[Seq[TorchTensor]]\n",
    "          optimizer.zero_grad()\n",
    "          val loss = calculateBatchLoss(model, device)(inputBatch, targetBatch)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          stepsCount += 1\n",
    "          examplesSeen += inputBatch.shape.bracketAccess(0).as[Long]\n",
    "          modelEvaluator.calculateLossCond(stepsCount)(model).foreach { loss =>\n",
    "            trainingSteps.append(TrainingStep(loss, examplesSeen))\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      val accuracy = py.local(modelEvaluator.calculateAccuracy(model))\n",
    "      TrainingEpoch(trainingSteps.toList, accuracy)\n",
    "    }\n",
    "  trainingEpochs.toList\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bccab35b-3b51-4db7-83f3-3e73b60912a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres40_0\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xffff5672c6f0>\n",
       "\u001b[36mmodel\u001b[39m: \u001b[32mModel\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36mres40_2\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36moptimizer\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 5e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0.1\n",
       ")\n",
       "\u001b[36mepochsCount\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m1\u001b[39m\n",
       "\u001b[36mmodelEvaluator\u001b[39m: \u001b[32mModelEvaluator\u001b[39m = ammonite.$sess.cmd39$Helper$ModelEvaluator@60da4cdb"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "val model = GPTModel(gptConfig)\n",
    "model.to(device)\n",
    "val optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-5, weight_decay = 0.1)\n",
    "// val epochsCount = 5\n",
    "val epochsCount = 2 // Simplification to speed up the training\n",
    "val modelEvaluator = new ModelEvaluator(\n",
    "  device = device, \n",
    "  trainingLoader = trainingLoader, \n",
    "  validationLoader = validationLoader, \n",
    "  // evaluationEpochsCount = 5,\n",
    "  evaluationEpochsCount = 1, // Simplification to speed up the training\n",
    "  // evaluationFrequencySteps = 50\n",
    "  evaluationFrequencySteps = 100 // Simplification to speed up the training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7daf94b-2a8c-4e9d-ba41-434f69464195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "Step 100\n",
      "- training loss: 0.7839783430099487\n",
      "- validation loss: 0.7070853114128113\n",
      "Training accuracy: 100.00%\n",
      "Validation accuracy: 87.50%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingEpochs\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mTrainingEpoch\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[33mTrainingEpoch\u001b[39m(\n",
       "    trainingSteps = \u001b[33mList\u001b[39m(\n",
       "      \u001b[33mTrainingStep\u001b[39m(\n",
       "        loss = \u001b[33mLoss\u001b[39m(\n",
       "          trainingLoss = \u001b[32m0.7839783430099487\u001b[39m,\n",
       "          validationLoss = \u001b[32m0.7070853114128113\u001b[39m\n",
       "        ),\n",
       "        examplesSeen = \u001b[32m111200L\u001b[39m\n",
       "      )\n",
       "    ),\n",
       "    accuracy = \u001b[33mAccuracy\u001b[39m(trainingAccuracy = \u001b[32m1.0\u001b[39m, validationAccuracy = \u001b[32m0.875\u001b[39m)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingEpochs = trainClassifierSimple(model, device, trainingLoader, validationLoader, optimizer, epochsCount, modelEvaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0283cb73-4871-4f9d-9d2f-2e593101fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.9.*\n",
      "  Downloading matplotlib-3.9.4-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.9.*)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.*)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.*)\n",
      "  Downloading fonttools-4.56.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.*)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib==3.9.*)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.*)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.*) (1.17.0)\n",
      "Downloading matplotlib-3.9.4-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (8.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (307 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (4.8 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.5 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading pillow-11.1.0-cp312-cp312-manylinux_2_28_aarch64.whl (4.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.9.4 pillow-11.1.0 pyparsing-3.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"matplotlib==3.9.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2daef9b2-8338-49b2-b2b3-d68f293b1bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling /workspace/DisplaySupport.sc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$\u001b[39m"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $file.^.DisplaySupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09296305-ccbe-451a-83e3-1ff9b83c24a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAEsCAYAAAA1u0HIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAeElEQVR4nO3de1hU1eI+8HcGmOF+EYQB5aKJqIRIKoSaUpJgpmKmRl7QY5p5ofKSebyA9u2QZkqpaRliVkcMU4+l4QW1vKB4FwIpS0GNi0qAoAIy6/eHP3aOIEIOgpv38zz7Oc7aa6+19jrTvOw9e89WCCEEiIiI6LGmbOgBEBER0cNjoBMREckAA52IiEgGGOhEREQywEAnIiKSAQY6ERGRDDDQiYiIZICBTkREJAMMdCIiIhlgoBMREckAA52IiEgGGOhEREQywEAnIiKSAQY6ERGRDDDQiUivAgIC8NZbbzX0MIiaHAY6USMzevRoKBSKKktwcHBDD42IGjHDhh4AEVUVHByM2NhYnTK1Wt1AoyGixwGP0IkaIbVaDY1Go7PY2NgAAPbt2weVSoX9+/dL9RctWgR7e3vk5uYCABISEtCjRw9YW1vD1tYWL774In7//Xep/oULF6BQKPDtt9/imWeegYmJCbp27Ypff/0VR48eRZcuXWBubo6+ffviypUr0najR49GSEgI5s+fj+bNm8PS0hITJkxAWVnZffeltLQU06dPR4sWLWBmZgY/Pz/s27dPWp+ZmYn+/fvDxsYGZmZm8PT0xPbt2+/b3qeffgp3d3cYGxvDwcEBL7/8srROq9UiKioKrVq1gomJCby9vbFx40ad7VNTU9G3b1+Ym5vDwcEBI0eOxNWrV6X1AQEBCA8PxzvvvINmzZpBo9EgMjLyvuMhaiwY6ESPmcrvqEeOHInCwkKcPHkSc+fOxRdffAEHBwcAQElJCaZOnYpjx44hMTERSqUSgwYNglar1WkrIiICc+bMwYkTJ2BoaIhXX30V77zzDj7++GPs378f586dw7x583S2SUxMRHp6Ovbt24f169dj06ZNmD9//n3HO3nyZCQlJSEuLg5nzpzBkCFDEBwcjN9++w0AMGnSJJSWluLnn39GSkoKFi5cCHNz82rbOnbsGMLDw7FgwQJkZGQgISEBPXv2lNZHRUVh3bp1WLVqFX755Re8/fbbGDFiBH766ScAQEFBAZ577jn4+Pjg2LFjSEhIQG5uLoYOHarTz5dffgkzMzMcOXIEixYtwoIFC7Br165a/j9E1EAEETUqYWFhwsDAQJiZmeks77//vlSntLRUdOrUSQwdOlR06NBBjBs3rsY2r1y5IgCIlJQUIYQQ58+fFwDEF198IdVZv369ACASExOlsqioKOHh4aEztmbNmomSkhKpbOXKlcLc3FxUVFQIIYTo1auXePPNN4UQQmRmZgoDAwNx+fJlnfH07t1bzJo1SwghhJeXl4iMjKzV3Hz33XfC0tJSFBUVVVl369YtYWpqKg4dOqRTPnbsWBEaGiqEEOK9994Tffr00Vl/8eJFAUBkZGRI4+/Ro4dOna5du4qZM2fWaoxEDYXfoRM1Qs8++yxWrlypU9asWTPp3yqVCt988w06duwIV1dXLF26VKfub7/9hnnz5uHIkSO4evWqdGSelZWFJ598UqrXsWNH6d+VR/deXl46ZXl5eTpte3t7w9TUVHrt7++P4uJiXLx4Ea6urjp1U1JSUFFRgbZt2+qUl5aWwtbWFgAQHh6ON954Azt37kRgYCAGDx6sM667Pf/883B1dUXr1q0RHByM4OBgDBo0CKampjh37hxu3LiB559/XmebsrIy+Pj4AABOnz6NvXv3VnsG4Pfff5fGeW//jo6OVeaBqLFhoBM1QmZmZmjTpk2NdQ4dOgQAyM/PR35+PszMzKR1/fv3h6urK1avXg0nJydotVo8+eSTVb7rNjIykv6tUCiqLbv3NH1dFBcXw8DAAMePH4eBgYHOuspQfe211xAUFIRt27Zh586diIqKwkcffYQpU6ZUac/CwgInTpzAvn37sHPnTsybNw+RkZE4evQoiouLAQDbtm1DixYtdLarvKCwuLgY/fv3x8KFC6u07ejoKP377jkAHn4eiB4FBjrRY+j333/H22+/jdWrV2PDhg0ICwvD7t27oVQqce3aNWRkZGD16tV45plnAAAHDhzQW9+nT5/GzZs3YWJiAgA4fPgwzM3N4ezsXKWuj48PKioqkJeXJ42lOs7OzpgwYQImTJiAWbNmYfXq1dUGOgAYGhoiMDAQgYGBiIiIgLW1Nfbs2YPnn38earUaWVlZ6NWrV7XbPvXUU/juu+/g5uYGQ0N+/JG88B1N1AiVlpYiJydHp8zQ0BB2dnaoqKjAiBEjEBQUhDFjxiA4OBheXl746KOPMGPGDNjY2MDW1haff/45HB0dkZWVhXfffVdvYysrK8PYsWMxZ84cXLhwAREREZg8eTKUyqrX2LZt2xbDhw/HqFGj8NFHH8HHxwdXrlxBYmIiOnbsiH79+uGtt95C37590bZtW/z111/Yu3cv2rdvX23fP/zwA/744w/07NkTNjY22L59O7RaLTw8PGBhYYHp06fj7bffhlarRY8ePVBYWIiDBw/C0tISYWFhmDRpElavXo3Q0FDpKvZz584hLi4OX3zxRZWzCESPEwY6USOUkJCgcwoYADw8PHD27Fm8//77yMzMxA8//ADgzqnizz//HKGhoejTpw+8vb0RFxeH8PBwPPnkk/Dw8MAnn3yCgIAAvYytd+/ecHd3R8+ePVFaWorQ0NAab+uKjY3F//3f/2HatGm4fPky7Ozs8PTTT+PFF18EAFRUVGDSpEm4dOkSLC0tERwcXOWagErW1tbYtGkTIiMjcevWLbi7u2P9+vXw9PQEALz33nto3rw5oqKi8Mcff8Da2hpPPfUU/v3vfwMAnJyccPDgQcycORN9+vRBaWkpXF1dERwcXO0fJESPE4UQQjT0IIjo8TB69GgUFBRgy5YtDT0UIroH/yQlIiKSAQY6ERGRDPCUOxERkQzwCJ2IiEgGGOhEREQywEAnIiKSAQa6Hvz888/o378/nJycoFAoqtzSI4TAvHnz4OjoCBMTEwQGBkpPmrrbtm3b4OfnBxMTE9jY2CAkJERnfVZWFvr16wdTU1PY29tjxowZuH37tk6dffv24amnnoJarUabNm2wdu3aKv2sWLECbm5uMDY2hp+fH5KTkx92CiT6mItff/0VAwcOhJ2dHSwtLdGjRw/s3btXp44c5mLTpk3o06cPbG1toVAocOrUqSpt3Lp1C5MmTYKtrS3Mzc0xePBg6RGplZrCXOTn52PKlCnw8PCAiYkJXFxcEB4ejsLCQp16TWEu7iaEQN++fattpynNRVJSEp577jmYmZnB0tISPXv2xM2bN6X1+fn5GD58OCwtLWFtbY2xY8dKPxVc6cyZM3jmmWdgbGwMZ2dnLFq0qEo/8fHxaNeuHYyNjeHl5VXjY34bRAM+GEY2tm/fLmbPni02bdokAIjNmzfrrP/ggw+ElZWV2LJlizh9+rQYMGCAaNWqlbh586ZUZ+PGjcLGxkasXLlSZGRkiF9++UVs2LBBWn/79m3x5JNPisDAQHHy5Emxfft2YWdnJz2xSggh/vjjD2FqaiqmTp0q0tLSxLJly4SBgYFISEiQ6sTFxQmVSiXWrFkjfvnlFzFu3DhhbW0tcnNzG81cuLu7ixdeeEGcPn1a/Prrr2LixInC1NRUZGdny2ou1q1bJ+bPny9Wr14tAIiTJ09WaWPChAnC2dlZJCYmimPHjomnn35adOvWTVrfVOYiJSVFvPTSS2Lr1q3i3LlzIjExUbi7u4vBgwc3ubm425IlS0Tfvn2rtNOU5uLQoUPC0tJSREVFidTUVHH27FmxYcMGcevWLalOcHCw8Pb2FocPHxb79+8Xbdq0kZ7AJ4QQhYWFwsHBQQwfPlykpqaK9evXCxMTE/HZZ59JdQ4ePCgMDAzEokWLRFpampgzZ44wMjKSnmDYGDDQ9ezeN6VWqxUajUZ8+OGHUllBQYFQq9Vi/fr1QgghysvLRYsWLXQeZXmv7du3C6VSKXJycqSylStXCktLS1FaWiqEEOKdd94Rnp6eOtsNGzZMBAUFSa99fX3FpEmTpNcVFRXCyclJREVF/bMdrsE/mYvKx3z+/PPPUp2ioiIBQOzatUsIIY+5uFvlo0zv/bAqKCgQRkZGIj4+XipLT08XAERSUpIQounMRXW+/fZboVKpRHl5uRCi6c3FyZMnRYsWLUR2dnaVdprSXPj5+Yk5c+bct920tDQBQBw9elQq+/HHH4VCoZAe6/vpp58KGxsbaW6EEGLmzJk6jw4eOnSo6NevX5W+X3/99drs3iPBU+717Pz588jJyUFgYKBUZmVlBT8/PyQlJQEATpw4gcuXL0OpVMLHxweOjo7o27cvUlNTpW2SkpLg5eUlPeISAIKCglBUVIRffvlFqnN3P5V1KvspKyvD8ePHdeoolUoEBgZKdepTbebC1tYWHh4eWLduHUpKSnD79m189tlnsLe3R+fOnQHIYy5q4/jx4ygvL9cZY7t27eDi4iKNsanMRXUKCwthaWkpPWSlKc3FjRs38Oqrr2LFihXQaDRV1jeVucjLy8ORI0dgb2+Pbt26wcHBAb169dJ5GFFSUhKsra3RpUsXqSwwMBBKpRJHjhyR6vTs2RMqlUqqExQUhIyMDPz1119SnZrmqzFgoNezygds3P0fVuXrynV//PEHACAyMhJz5szBDz/8ABsbGwQEBCA/P19qp7o27u7jfnWKiopw8+ZNXL16FRUVFTWOpT7VZi4UCgV2796NkydPwsLCAsbGxliyZAkSEhJgY2MjtfO4z0Vt5OTkQKVSwdraWqf87jE2lbm419WrV/Hee+9h/PjxUllTmou3334b3bp1w8CBA6td31Tm4u7PznHjxiEhIQFPPfUUevfuLV2bk5OTA3t7e53tDA0N0axZM738d9RY5gJgoDcKlc9Znj17NgYPHozOnTsjNjYWCoUC8fHxDTy6R0sIgUmTJsHe3h779+9HcnIyQkJC0L9/f2RnZzf08KgRKCoqQr9+/dChQ4caHwojV1u3bsWePXsQHR3d0ENpcJWfna+//jrGjBkDHx8fLF26FB4eHlizZk0Dj+7RY6DXs8rTYfdemZybmyutq3yqVocOHaT1arUarVu3RlZWltROdW3c3cf96lhaWsLExAR2dnYwMDCocSz1qTZzsWfPHvzwww+Ii4tD9+7d8dRTT+HTTz+FiYkJvvzyS6mdx30uakOj0aCsrAwFBQU65XePsanMRaXr168jODgYFhYW2Lx5M4yMjKR1TWUu9uzZg99//x3W1tYwNDSUvnIYPHiw9ES9pjIX1X12AkD79u11Pjvz8vJ01t++fRv5+fl6+e+oscwFwECvd61atYJGo0FiYqJUVlRUhCNHjsDf3x8A0LlzZ6jVamRkZEh1ysvLceHCBbi6ugIA/P39kZKSovPG3LVrFywtLaU3s7+/v04/lXUq+1GpVOjcubNOHa1Wi8TERKlOfarNXNy4cQMAqjzKUqlUSn+Ny2EuaqNz584wMjLSGWNGRgaysrKkMTaVuQDuvFf69OkDlUqFrVu3wtjYWGd9U5mLd999F2fOnMGpU6ekBQCWLl2K2NhYAE1nLtzc3ODk5KTz2QncufX17s/OgoICHD9+XFq/Z88eaLVa+Pn5SXV+/vlnlJeXS3V27doFDw8P6au+B81Xo9DQV+XJwfXr18XJkyfFyZMnBQCxZMkScfLkSZGZmSmEuHOrlrW1tfjf//4nzpw5IwYOHFjlVq0333xTtGjRQuzYsUOcPXtWjB07Vtjb24v8/HwhxN+3ofTp00ecOnVKJCQkiObNm1d7G8qMGTNEenq6WLFiRbW3oajVarF27VqRlpYmxo8fL6ytrXWuhm3Iubhy5YqwtbUVL730kjh16pTIyMgQ06dPF0ZGRuLUqVOymotr166JkydPim3btgkAIi4uTpw8eVK6PU+IO7etubi4iD179ohjx44Jf39/4e/vL61vKnNRWFgo/Pz8hJeXlzh37pzIzs6Wltu3bzepuagO7nPbWlOYi6VLlwpLS0sRHx8vfvvtNzFnzhxhbGwszp07J9UJDg4WPj4+4siRI+LAgQPC3d1d57a1goIC4eDgIEaOHClSU1NFXFycMDU1rXLbmqGhoVi8eLFIT08XERERvG1Njvbu3SsAVFnCwsKEEHdu15o7d65wcHAQarVa9O7dW2RkZOi0UVZWJqZNmybs7e2FhYWFCAwMFKmpqTp1Lly4IPr27StMTEyEnZ2dmDZtmnTLzt1j6dSpk1CpVKJ169YiNja2yniXLVsmXFxchEqlEr6+vuLw4cONai6OHj0q+vTpI5o1ayYsLCzE008/LbZv3y67uYiNja12fUREhNTGzZs3xcSJE4WNjY0wNTUVgwYNqvLB3hTm4n7bAxDnz59vUnNRnXsDXYimNRdRUVGiZcuWwtTUVPj7+4v9+/frrL927ZoIDQ0V5ubmwtLSUowZM0Zcv35dp87p06dFjx49hFqtFi1atBAffPBBlfF+++23om3btkKlUglPT0+xbds2vc2FPvBpa0RERDLA79CJiIhkgIFOREQkAwx0IiIiGWCgExERyQADnYiISAYY6ERERDLAQH8MlJaWIjIyEqWlpQ09lAbHufgb5+JvnIu/cS7+1tTmgvehPwaKiopgZWUlPS6yKeNc/I1z8TfOxd84F39ranPBI3QiIiIZYKATERHJgGFDD+Bxcfv2bZw8eRIODg5VngRW365fvw4AuHz5MoqKih5p340N5+JvnIu/cS7+xrn42+M2F1qtFrm5ufDx8ZEei1sX/A69lo4ePQpfX9+GHgYREclccnIyunbtWufteIReSw4ODgDuTLSjo2MDj4aIiOQmOzsbvr6+Ut7UFQO9lipPszs6OqJly5YNPBoiIpKrf/q1Li+KIyIikgEGOhERkQww0ImIiGSA36ETET1ARUUFysvLG3oY9JgzMjKCgYFBvbXPQCciug8hBHJyclBQUNDQQyGZsLa2hkajgUKh0HvbDHQiovuoDHN7e3uYmprWy4cwNQ1CCNy4cQN5eXkAUC+3PzPQiYiqUVFRIYW5ra1tQw+HZMDExAQAkJeXB3t7e72ffudFcURE1aj8ztzU1LSBR0JyUvl+qo9rMhjoREQ14Gl20qf6fD8x0ImIiGSgUQb6ihUr4ObmBmNjY/j5+SE5Ofm+dQMCAqBQKKos/fr1k+oUFxdj8uTJaNmyJUxMTNChQwesWrXqUewKEZEsuLm5ITo6utb19+3bB4VCUe93CKxduxbW1tb12sfjotEF+oYNGzB16lRERETgxIkT8Pb2RlBQkHRl4L02bdqE7OxsaUlNTYWBgQGGDBki1Zk6dSoSEhLw9ddfIz09HW+99RYmT56MrVu3PqrdIiJ6JKo7wLl7iYyM/EftHj16FOPHj691/W7duiE7OxtWVlb/qD+qu0YX6EuWLMG4ceMwZswY6Uja1NQUa9asqbZ+s2bNoNFopGXXrl0wNTXVCfRDhw4hLCwMAQEBcHNzw/jx4+Ht7V3jkT8R0ePo7gOc6OhoWFpa6pRNnz5dqiuEwO3bt2vVbvPmzet0gaBKpaq3+62peo0q0MvKynD8+HEEBgZKZUqlEoGBgUhKSqpVGzExMXjllVdgZmYmlXXr1g1bt27F5cuXIYTA3r178euvv6JPnz563wciooZ09wGOlZUVFAqF9Prs2bOwsLDAjz/+iM6dO0OtVuPAgQP4/fffMXDgQDg4OMDc3Bxdu3bF7t27ddq995S7QqHAF198gUGDBsHU1BTu7u46Zz3vPeVeeWp8x44daN++PczNzREcHIzs7Gxpm9u3byM8PBzW1tawtbXFzJkzERYWhpCQkDrNwcqVK/HEE09ApVLBw8MDX331lbROCIHIyEi4uLhArVbDyckJ4eHh0vpPP/0U7u7uMDY2hoODA15++eU69d2QGlWgX716FRUVFVWeBevg4ICcnJwHbp+cnIzU1FS89tprOuXLli1Dhw4d0LJlS6hUKgQHB2PFihXo2bPnfdsqLS1FUVGRtFy/fv2f7RQRyYYQAjfKbjfIIoTQ2368++67+OCDD5Ceno6OHTuiuLgYL7zwAhITE3Hy5EkEBwejf//+yMrKqrGd+fPnY+jQoThz5gxeeOEFDB8+HPn5+fetf+PGDSxevBhfffUVfv75Z2RlZemcMVi4cCG++eYbxMbG4uDBgygqKsKWLVvqtG+bN2/Gm2++iWnTpiE1NRWvv/46xowZg7179wIAvvvuOyxduhSfffYZfvvtN2zZsgVeXl4AgGPHjiE8PBwLFixARkYGEhISasyJxkZWPywTExMDLy8v+Pr66pQvW7YMhw8fxtatW+Hq6oqff/4ZkyZNgpOTk87ZgLtFRUVh/vz5j2LYRPSYuFlegQ7zdjRI32kLgmCq0s9H9oIFC/D8889Lr5s1awZvb2/p9XvvvYfNmzdj69atmDx58n3bGT16NEJDQwEA//nPf/DJJ58gOTkZwcHB1dYvLy/HqlWr8MQTTwAAJk+ejAULFkjrly1bhlmzZmHQoEEAgOXLl2P79u112rfFixdj9OjRmDhxIoA711AdPnwYixcvxrPPPousrCxoNBoEBgbCyMgILi4uUmZkZWXBzMwML774IiwsLODq6gofH5869d+QGtURup2dHQwMDJCbm6tTnpubC41GU+O2JSUliIuLw9ixY3XKb968iX//+99YsmQJ+vfvj44dO2Ly5MkYNmwYFi9efN/2Zs2ahcLCQmlJS0v75ztGRNSIdOnSRed1cXExpk+fjvbt28Pa2hrm5uZIT09/4BF6x44dpX+bmZnB0tLyvhcwA3d+VKUyzIE7P39aWb+wsBC5ubk6B2QGBgbo3LlznfYtPT0d3bt31ynr3r070tPTAQBDhgzBzZs30bp1a4wbNw6bN2+WriN4/vnn4erqitatW2PkyJH45ptvcOPGjTr135Aa1RG6SqVC586dkZiYKH1notVqkZiYWONfiQAQHx+P0tJSjBgxQqe8vLwc5eXlUCp1/3YxMDCAVqu9b3tqtRpqtVp6XVRUVMe9ISK5MTEyQNqCoAbrW1/uvsYIAKZPn45du3Zh8eLFaNOmDUxMTPDyyy+jrKysxnaMjIx0XisUiho/V6urr8+vEmrD2dkZGRkZ2L17N3bt2oWJEyfiww8/xE8//QQLCwucOHEC+/btw86dOzFv3jxERkbi6NGjj8WtcY3qCB24c3pk9erV+PLLL5Geno433ngDJSUlGDNmDABg1KhRmDVrVpXtYmJiEBISUuU3ly0tLdGrVy/MmDED+/btw/nz57F27VqsW7dOOq1DRFQbCoUCpirDBlnq82rxgwcPYvTo0Rg0aBC8vLyg0Whw4cKFeuuvOlZWVnBwcMDRo0elsoqKCpw4caJO7bRv3x4HDx7UKTt48CA6dOggvTYxMUH//v3xySefYN++fUhKSkJKSgoAwNDQEIGBgVi0aBHOnDmDCxcuYM+ePQ+xZ49OozpCB4Bhw4bhypUrmDdvHnJyctCpUyckJCRIF8plZWVVOdrOyMjAgQMHsHPnzmrbjIuLw6xZs6QLNlxdXfH+++9jwoQJ9b4/RESNnbu7OzZt2oT+/ftDoVBg7ty5NR5p15cpU6YgKioKbdq0Qbt27bBs2TL89ddfdfpjZsaMGRg6dCh8fHwQGBiI77//Hps2bZKu2l+7di0qKirg5+cHU1NTfP311zAxMYGrqyt++OEH/PHHH+jZsydsbGywfft2aLVaeHh41Ncu61WjC3TgzoUS9zvFvm/fviplHh4eNZ620Wg0iI2N1dfwiIhkZcmSJfjXv/6Fbt26wc7ODjNnzmyQrxlnzpyJnJwcjBo1CgYGBhg/fjyCgoLq9FSykJAQfPzxx1i8eDHefPNNtGrVCrGxsQgICABw53nkH3zwAaZOnYqKigp4eXnh+++/h62tLaytrbFp0yZERkbi1q1bcHd3x/r16+Hp6VlPe6xfCvGov8B4TF26dAnOzs64ePEiWrZs2dDDIaJ6duvWLZw/fx6tWrWCsbFxQw+nSdJqtWjfvj2GDh2K9957r6GHoxc1va8eNmca5RE6ERE1PZmZmdi5cyd69eqF0tJSLF++HOfPn8err77a0EN7LDS6i+KIiKhpUiqVWLt2Lbp27Yru3bsjJSUFu3fvRvv27Rt6aI8FHqETEVGj4OzsXOUKdao9HqETERHJAAOdiIhIBhjoREREMsBAJyIikgEGOhERkQww0ImIiGSAgU5ERFUEBATgrbfekl67ubkhOjq6xm0UCgW2bNny0H3rq52aREZGolOnTvXax6PGQCcikpH+/fsjODi42nX79++HQqHAmTNn6tzu0aNHMX78+Icdno77hWp2djb69u2r176aAgY6EZGMjB07Frt27cKlS5eqrIuNjUWXLl3QsWPHOrfbvHlzmJqa6mOID6TRaKBWqx9JX3LCQCcikpEXX3wRzZs3x9q1a3XKi4uLER8fj7Fjx+LatWsIDQ1FixYtYGpqCi8vL6xfv77Gdu895f7bb7+hZ8+eMDY2RocOHbBr164q28ycORNt27aFqakpWrdujblz56K8vBzAnceYzp8/H6dPn4ZCoYBCoZDGfO8p95SUFDz33HMwMTGBra0txo8fj+LiYmn96NGjERISgsWLF8PR0RG2traYNGmS1FdtaLVaLFiwAC1btoRarZYe3V2prKwMkydPhqOjI4yNjeHq6oqoqCgAgBACkZGRcHFxgVqthpOTE8LDw2vdt77wp1+JiOqqrKTu2xioAYP//5FbcRuoKAUUSsDI5MHtqsxq3Y2hoSFGjRqFtWvXYvbs2dKzxOPj41FRUYHQ0FAUFxejc+fOmDlzJiwtLbFt2zaMHDkSTzzxBHx9fR/Yh1arxUsvvQQHBwccOXIEhYWFOt+3V7KwsMDatWvh5OSElJQUjBs3DhYWFnjnnXcwbNgwpKamIiEhQXpWuZWVVZU2SkpKEBQUBH9/fxw9ehR5eXl47bXXMHnyZJ0/Wvbu3QtHR0fs3bsX586dw7Bhw9CpUyeMGzeuVvP28ccf46OPPsJnn30GHx8frFmzBgMGDMAvv/wCd3d3fPLJJ9i6dSu+/fZbuLi44OLFi7h48SIA4LvvvsPSpUsRFxcHT09P5OTk4PTp07XqV58Y6EREdfUfp7pvM2Qt4Dnozr/Pfg/EjwZcewBjtv1dJ9oLuHGt6raRhXXq6l//+hc+/PBD/PTTT9JzwGNjYzF48GBYWVnBysoK06dPl+pPmTIFO3bswLffflurQN+9ezfOnj2LHTt2wMnpzlz85z//qfK995w5c6R/u7m5Yfr06YiLi8M777wDExMTmJubw9DQEBqN5r59/fe//8WtW7ewbt06mJnd+cNm+fLl6N+/PxYuXAgHBwcAgI2NDZYvXw4DAwO0a9cO/fr1Q2JiYq0DffHixZg5cyZeeeUVAMDChQuxd+9eREdHY8WKFcjKyoK7uzt69OgBhUIBV1dXadusrCxoNBoEBgbCyMgILi4utZpHfeMpdyIimWnXrh26deuGNWvWAADOnTuH/fv3Y+zYsQCAiooKvPfee/Dy8kKzZs1gbm6OHTt2ICsrq1btp6enw9nZWQpzAPD3969Sb8OGDejevTs0Gg3Mzc0xZ86cWvdxd1/e3t5SmANA9+7dodVqkZGRIZV5enrCwMBAeu3o6Ii8vLxa9VFUVIQ///wT3bt31ynv3r070tPTAdw5rX/q1Cl4eHggPDwcO3fulOoNGTIEN2/eROvWrTFu3Dhs3rwZt2/frtN+6gOP0ImI6urff9Z9G4O7LvJq1/9OG4p7jqneSnm4cd1l7NixmDJlClasWIHY2Fg88cQT6NWrFwDgww8/xMcff4zo6Gh4eXnBzMwMb731FsrKyvTWf1JSEoYPH4758+cjKCgIVlZWiIuLw0cffaS3Pu5mZGSk81qhUECr1eqt/aeeegrnz5/Hjz/+iN27d2Po0KEIDAzExo0b4ezsjIyMDOzevRu7du3CxIkTpTMk946rPvEInYiorlRmdV8M7jp+MjC8U3b39+c1tfsPDB06FEqlEv/973+xbt06/Otf/5K+Tz948CAGDhyIESNGwNvbG61bt8avv/5a67bbt2+PixcvIjs7Wyo7fPiwTp1Dhw7B1dUVs2fPRpcuXeDu7o7MzEzd3VWpUFFR8cC+Tp8+jZKSv68vOHjwIJRKJTw8PGo95ppYWlrCycmpyqNbDx48iA4dOujUGzZsGFavXo0NGzbgu+++Q35+PgDAxMQE/fv3xyeffIJ9+/YhKSkJKSn6+wOtNniETkQkQ+bm5hg2bBhmzZqFoqIijB49Wlrn7u6OjRs34tChQ7CxscGSJUuQm5urE141CQwMRNu2bREWFoYPP/wQRUVFmD17tk4dd3d3ZGVlIS4uDl27dsW2bduwefNmnTpubm44f/48Tp06hZYtW8LCwqLK7WrDhw9HREQEwsLCEBkZiStXrmDKlCkYOXKk9P25PsyYMQMRERF44okn0KlTJ8TGxuLUqVP45ptvAABLliyBo6MjfHx8oFQqER8fD41GA2tra6xduxYVFRXw8/ODqakpvv76a5iYmOh8z/4o8AidiEimxo4di7/++gtBQUE633fPmTMHTz31FIKCghAQEACNRoOQkJBat6tUKrF582bcvHkTvr6+eO211/D+++/r1BkwYADefvttTJ48GZ06dcKhQ4cwd+5cnTqDBw9GcHAwnn32WTRv3rzaW+dMTU2xY8cO5Ofno2vXrnj55ZfRu3dvLF++vG6T8QDh4eGYOnUqpk2bBi8vLyQkJGDr1q1wd3cHcOeK/UWLFqFLly7o2rUrLly4gO3bt0OpVMLa2hqrV69G9+7d0bFjR+zevRvff/89bG1t9TrGB1EIIcQj7fExdenSJTg7O+PixYto2bJlQw+HiOrZrVu3cP78ebRq1QrGxsYNPRySiZreVw+bMzxCJyIikgEGOhERkQww0ImIiGSAgU5ERCQDDHQiIiIZYKATEdVAn782RlSf7yf+sAwRUTVUKhWUSiX+/PNPNG/eHCqVSvqlNaK6EkKgrKwMV65cgVKphEql0nsfDHQiomoolUq0atUK2dnZ+PPPf/Db7UTVMDU1hYuLC5RK/Z8gZ6ATEd2HSqWCi4sLbt++/cDfHCd6EAMDAxgaGtbbmR4GOhFRDRQKBYyMjB7pU7OI/gleFEdERCQDjTLQV6xYATc3NxgbG8PPzw/Jycn3rRsQEACFQlFl6devn0699PR0DBgwAFZWVjAzM0PXrl2RlZVV37tCRET0SDS6QN+wYQOmTp2KiIgInDhxAt7e3ggKCkJeXl619Tdt2oTs7GxpSU1NhYGBAYYMGSLV+f3339GjRw+0a9cO+/btw5kzZzB37lw+cIGIiGSj0T1tzc/PD127dpUejafVauHs7IwpU6bg3XfffeD20dHRmDdvHrKzs2FmZgYAeOWVV2BkZISvvvrqH4+LT1sjIqL6JKunrZWVleH48eMIDAyUypRKJQIDA5GUlFSrNmJiYvDKK69IYa7VarFt2za0bdsWQUFBsLe3h5+fH7Zs2VIfu0BERNQgGlWgX716FRUVFXBwcNApd3BwQE5OzgO3T05ORmpqKl577TWpLC8vD8XFxfjggw8QHByMnTt3YtCgQXjppZfw008/3bet0tJSFBUVScv169f/+Y4RERHVM1ndthYTEwMvLy/4+vpKZZU/szdw4EC8/fbbAIBOnTrh0KFDWLVqFXr16lVtW1FRUZg/f379D5qIiEgPGtURup2dHQwMDJCbm6tTnpubC41GU+O2JSUliIuLw9ixY6u0aWhoiA4dOuiUt2/fvsar3GfNmoXCwkJpSUtLq+PeEBERPTqNKtBVKhU6d+6MxMREqUyr1SIxMRH+/v41bhsfH4/S0lKMGDGiSptdu3ZFRkaGTvmvv/4KV1fX+7anVqthaWkpLRYWFv9gj4iIiB6NRnfKferUqQgLC0OXLl3g6+uL6OholJSUYMyYMQCAUaNGoUWLFoiKitLZLiYmBiEhIbC1ta3S5owZMzBs2DD07NkTzz77LBISEvD9999j3759j2KXiIiI6l2jC/Rhw4bhypUrmDdvHnJyctCpUyckJCRIF8plZWVV+VH7jIwMHDhwADt37qy2zUGDBmHVqlWIiopCeHg4PDw88N1336FHjx71vj9ERESPQqO7D72x4n3oRERUn2R1HzoRERH9Mwx0IiIiGWCgExERyQADnYiISAYY6ERERDLAQCciIpIBBjoREZEMMNCJiIhkgIFOREQkAwx0IiIiGWCgExERyQADnYiISAYY6ERERDLAQCciIpIBvQX6xYsXcenSJel1cnIy3nrrLXz++ef66oKIiIjuQ2+B/uqrr2Lv3r0AgJycHDz//PNITk7G7NmzsWDBAn11Q0RERNXQW6CnpqbC19cXAPDtt9/iySefxKFDh/DNN99g7dq1+uqGiIiIqqG3QC8vL4darQYA7N69GwMGDAAAtGvXDtnZ2frqhoiIiKqht0D39PTEqlWrsH//fuzatQvBwcEAgD///BO2trb66oaIiIiqobdAX7hwIT777DMEBAQgNDQU3t7eAICtW7dKp+KJiIiofhjqq6GAgABcvXoVRUVFsLGxkcrHjx8PU1NTfXVDRERE1dDbEfrNmzdRWloqhXlmZiaio6ORkZEBe3t7fXVDRERE1dBboA8cOBDr1q0DABQUFMDPzw8fffQRQkJCsHLlSn11Q0RERNXQW6CfOHECzzzzDABg48aNcHBwQGZmJtatW4dPPvlEX90QERFRNfQW6Ddu3ICFhQUAYOfOnXjppZegVCrx9NNPIzMzU1/dEBERUTX0Fuht2rTBli1bcPHiRezYsQN9+vQBAOTl5cHS0lJf3RAREVE19Bbo8+bNw/Tp0+Hm5gZfX1/4+/sDuHO07uPjo69uiIiIqBp6u23t5ZdfRo8ePZCdnS3dgw4AvXv3xqBBg/TVDREREVVDb4EOABqNBhqNRnrqWsuWLfmjMkRERI+A3k65a7VaLFiwAFZWVnB1dYWrqyusra3x3nvvQavV6qsbIiIiqobejtBnz56NmJgYfPDBB+jevTsA4MCBA4iMjMStW7fw/vvv66srIiIiuofeAv3LL7/EF198IT1lDQA6duyIFi1aYOLEiQx0IiKieqS3U+75+flo165dlfJ27dohPz9fX90QERFRNfQW6N7e3li+fHmV8uXLl6Njx451bm/FihVwc3ODsbEx/Pz8kJycfN+6AQEBUCgUVZZ+/fpVW3/ChAlQKBSIjo6u87iIiIgaI72dcl+0aBH69euH3bt3S/egJyUl4eLFi9i+fXud2tqwYQOmTp2KVatWwc/PD9HR0QgKCrrvg142bdqEsrIy6fW1a9fg7e2NIUOGVKm7efNmHD58GE5OTnXcQyIiosZLb0fovXr1wq+//opBgwahoKAABQUFeOmll/DLL7/gq6++qlNbS5Yswbhx4zBmzBh06NABq1atgqmpKdasWVNt/WbNmkm3zGk0GuzatQumpqZVAv3y5cuYMmUKvvnmGxgZGf3jfSUiImps9HofupOTU5WL306fPo2YmBh8/vnntWqjrKwMx48fx6xZs6QypVKJwMBAJCUl1aqNmJgYvPLKKzAzM5PKtFotRo4ciRkzZsDT07NW7RARET0u9Bro+nD16lVUVFTAwcFBp9zBwQFnz5594PbJyclITU1FTEyMTvnChQthaGiI8PDwWo2jtLQUpaWl0uvr16/XajsiIqKG0OgC/WHFxMTAy8tL5xfqjh8/jo8//hgnTpyAQqGoVTtRUVGYP39+fQ2TiIhIr/T2Hbq+2NnZwcDAALm5uTrlubm50Gg0NW5bUlKCuLg4jB07Vqd8//79yMvLg4uLCwwNDWFoaIjMzExMmzYNbm5u1bY1a9YsFBYWSktaWtpD7RcREVF9eugj9JdeeqnG9QUFBXVqT6VSoXPnzkhMTERISAiAO99/JyYmYvLkyTVuGx8fj9LSUowYMUKnfOTIkQgMDNQpCwoKwsiRIzFmzJhq21Kr1VCr1dLroqKiOu0HERHRo/TQgW5lZfXA9aNGjapTm1OnTkVYWBi6dOkCX19fREdHo6SkRArfUaNGoUWLFoiKitLZLiYmBiEhIbC1tdUpt7W1rVJmZGQEjUYDDw+POo2NiIioMXroQI+NjdXHOHQMGzYMV65cwbx585CTk4NOnTohISFBulAuKysLSqXutwUZGRk4cOAAdu7cqffxEBERNXYKIYRo6EE8Di5dugRnZ2dcvHgRLVu2bOjhEBGRzDxszjS6i+KIiIio7hjoREREMsBAJyIikgEGOhERkQww0ImIiGSAgU5ERCQDDHQiIiIZYKATERHJAAOdiIhIBhjoREREMsBAJyIikgEGOhERkQww0ImIiGSAgU5ERCQDDHQiIiIZYKATERHJAAOdiIhIBhjoREREMsBAJyIikgEGOhERkQww0ImIiGSAgU5ERCQDDHQiIiIZYKATERHJAAOdiIhIBhjoREREMsBAJyIikgEGOhERkQww0ImIiGSAgU5ERCQDDHQiIiIZYKATERHJAAOdiIhIBhptoK9YsQJubm4wNjaGn58fkpOT71s3ICAACoWiytKvXz8AQHl5OWbOnAkvLy+YmZnByckJo0aNwp9//vmodoeIiKheNcpA37BhA6ZOnYqIiAicOHEC3t7eCAoKQl5eXrX1N23ahOzsbGlJTU2FgYEBhgwZAgC4ceMGTpw4gblz5+LEiRPYtGkTMjIyMGDAgEe5W0RERPVGIYQQDT2Ie/n5+aFr165Yvnw5AECr1cLZ2RlTpkzBu++++8Dto6OjMW/ePGRnZ8PMzKzaOkePHoWvry8yMzPh4uLywDYvXboEZ2dnXLx4ES1btqzbDhERET3Aw+ZMoztCLysrw/HjxxEYGCiVKZVKBAYGIikpqVZtxMTE4JVXXrlvmANAYWEhFAoFrK2tH3bIREREDc6woQdwr6tXr6KiogIODg465Q4ODjh79uwDt09OTkZqaipiYmLuW+fWrVuYOXMmQkNDYWlpWW2d0tJSlJaWSq+vX79eyz0gIiJ69BrdEfrDiomJgZeXF3x9fatdX15ejqFDh0IIgZUrV963naioKFhZWUlLhw4d6mvIRERED63RBbqdnR0MDAyQm5urU56bmwuNRlPjtiUlJYiLi8PYsWOrXV8Z5pmZmdi1a9d9j84BYNasWSgsLJSWtLS0uu8MERHRI9LoAl2lUqFz585ITEyUyrRaLRITE+Hv71/jtvHx8SgtLcWIESOqrKsM899++w27d++Gra1tjW2p1WpYWlpKi4WFxT/bISIiokeg0X2HDgBTp05FWFgYunTpAl9fX0RHR6OkpARjxowBAIwaNQotWrRAVFSUznYxMTEICQmpEtbl5eV4+eWXceLECfzwww+oqKhATk4OAKBZs2ZQqVSPZseIiIjqSaMM9GHDhuHKlSuYN28ecnJy0KlTJyQkJEgXymVlZUGp1D25kJGRgQMHDmDnzp1V2rt8+TK2bt0KAOjUqZPOur179yIgIKBe9oOIiOhRaZT3oTdGvA+diIjqk+zuQyciIqK6Y6ATERHJAAOdiIhIBhjoREREMsBAJyIikgEGOhERkQww0ImIiGSAgU5ERCQDDHQiIiIZYKATERHJAAOdiIhIBhjoREREMsBAJyIikgEGOhERkQww0ImIiGSAgU5ERCQDDHQiIiIZYKATERHJAAOdiIhIBhjoREREMsBAJyIikgEGOhERkQww0ImIiGSAgU5ERCQDDHQiIiIZYKATERHJAAOdiIhIBhjoREREMsBAJyIikgEGOhERkQwYNvQAHhdarRYAkJ2d3cAjISIiOarMl8q8qSsGei3l5uYCAHx9fRt4JEREJGe5ublwcXGp83YKIYSoh/HIzu3bt3Hy5Ek4ODhAqZTfNxXXr19Hhw4dkJaWBgsLi4YeTqPFeao9zlXtca5qR+7zpNVqkZubCx8fHxga1v14m4FOAICioiJYWVmhsLAQlpaWDT2cRovzVHucq9rjXNUO56lm8jvUJCIiaoIY6ERERDLAQCcAgFqtRkREBNRqdUMPpVHjPNUe56r2OFe1w3mqGb9DJyIikgEeoRMREckAA52IiEgGGOhEREQywEBvIvLz8zF8+HBYWlrC2toaY8eORXFxcY3b3Lp1C5MmTYKtrS3Mzc0xePBg6Rfz7nXt2jW0bNkSCoUCBQUF9bAHj059zNXp06cRGhoKZ2dnmJiYoH379vj444/re1f0bsWKFXBzc4OxsTH8/PyQnJxcY/34+Hi0a9cOxsbG8PLywvbt23XWCyEwb948ODo6wsTEBIGBgfjtt9/qcxceCX3OU3l5OWbOnAkvLy+YmZnByckJo0aNwp9//lnfu/FI6Ps9dbcJEyZAoVAgOjpaz6NupAQ1CcHBwcLb21scPnxY7N+/X7Rp00aEhobWuM2ECROEs7OzSExMFMeOHRNPP/206NatW7V1Bw4cKPr27SsAiL/++qse9uDRqY+5iomJEeHh4WLfvn3i999/F1999ZUwMTERy5Ytq+/d0Zu4uDihUqnEmjVrxC+//CLGjRsnrK2tRW5ubrX1Dx48KAwMDMSiRYtEWlqamDNnjjAyMhIpKSlSnQ8++EBYWVmJLVu2iNOnT4sBAwaIVq1aiZs3bz6q3dI7fc9TQUGBCAwMFBs2bBBnz54VSUlJwtfXV3Tu3PlR7la9qI/3VKVNmzYJb29v4eTkJJYuXVrPe9I4MNCbgLS0NAFAHD16VCr78ccfhUKhEJcvX652m4KCAmFkZCTi4+OlsvT0dAFAJCUl6dT99NNPRa9evURiYuJjH+j1PVd3mzhxonj22Wf1N/h65uvrKyZNmiS9rqioEE5OTiIqKqra+kOHDhX9+vXTKfPz8xOvv/66EEIIrVYrNBqN+PDDD6X1BQUFQq1Wi/Xr19fDHjwa+p6n6iQnJwsAIjMzUz+DbiD1NVeXLl0SLVq0EKmpqcLV1bXJBDpPuTcBSUlJsLa2RpcuXaSywMBAKJVKHDlypNptjh8/jvLycgQGBkpl7dq1g4uLC5KSkqSytLQ0LFiwAOvWrZPFb9zX51zdq7CwEM2aNdPf4OtRWVkZjh8/rrOPSqUSgYGB993HpKQknfoAEBQUJNU/f/48cnJydOpYWVnBz8+vxnlrzOpjnqpTWFgIhUIBa2trvYy7IdTXXGm1WowcORIzZsyAp6dn/Qy+kXr8P4HpgXJycmBvb69TZmhoiGbNmiEnJ+e+26hUqiofGA4ODtI2paWlCA0NxYcffviPngzUGNXXXN3r0KFD2LBhA8aPH6+Xcde3q1evoqKiAg4ODjrlNe1jTk5OjfUr/7cubTZ29TFP97p16xZmzpyJ0NDQx/r3zOtrrhYuXAhDQ0OEh4frf9CNHAP9Mfbuu+9CoVDUuJw9e7be+p81axbat2+PESNG1Fsf+tLQc3W31NRUDBw4EBEREejTp88j6ZPkoby8HEOHDoUQAitXrmzo4TQ6x48fx8cff4y1a9dCoVA09HAeOT4P/TE2bdo0jB49usY6rVu3hkajQV5enk757du3kZ+fD41GU+12Go0GZWVlKCgo0DnyzM3NlbbZs2cPUlJSsHHjRgB3rlgGADs7O8yePRvz58//h3umfw09V5XS0tLQu3dvjB8/HnPmzPlH+9IQ7OzsYGBgUOUuh+r2sZJGo6mxfuX/5ubmwtHRUadOp06d9Dj6R6c+5qlSZZhnZmZiz549j/XROVA/c7V//37k5eXpnDGsqKjAtGnTEB0djQsXLuh3Jxqbhv4Sn+pf5YVex44dk8p27NhRqwu9Nm7cKJWdPXtW50Kvc+fOiZSUFGlZs2aNACAOHTp036tUG7v6mishhEhNTRX29vZixowZ9bcD9cjX11dMnjxZel1RUSFatGhR4wVML774ok6Zv79/lYviFi9eLK0vLCyUxUVx+pwnIYQoKysTISEhwtPTU+Tl5dXPwBuAvufq6tWrOp9JKSkpwsnJScycOVOcPXu2/nakkWCgNxHBwcHCx8dHHDlyRBw4cEC4u7vr3Ip16dIl4eHhIY4cOSKVTZgwQbi4uIg9e/aIY8eOCX9/f+Hv73/fPvbu3fvYX+UuRP3MVUpKimjevLkYMWKEyM7OlpbH6cM5Li5OqNVqsXbtWpGWlibGjx8vrK2tRU5OjhBCiJEjR4p3331Xqn/w4EFhaGgoFi9eLNLT00VERES1t61ZW1uL//3vf+LMmTNi4MCBsrhtTZ/zVFZWJgYMGCBatmwpTp06pfP+KS0tbZB91Jf6eE/dqyld5c5AbyKuXbsmQkNDhbm5ubC0tBRjxowR169fl9afP39eABB79+6Vym7evCkmTpwobGxshKmpqRg0aJDIzs6+bx9yCfT6mKuIiAgBoMri6ur6CPfs4S1btky4uLgIlUolfH19xeHDh6V1vXr1EmFhYTr1v/32W9G2bVuhUqmEp6en2LZtm856rVYr5s6dKxwcHIRarRa9e/cWGRkZj2JX6pU+56ny/Vbdcvd78HGl7/fUvZpSoPNpa0RERDLAq9yJiIhkgIFOREQkAwx0IiIiGWCgExERyQADnYiISAYY6ERERDLAQCciIpIBBjoREZEMMNCJqMEpFAps2bKloYdB9FhjoBM1caNHj672cbLBwcENPTQiqgM+PpWIEBwcjNjYWJ0ytVrdQKMhon+CR+hEBLVaDY1Go7PY2NgAuHM6fOXKlejbty9MTEzQunVrbNy4UWf7lJQUPPfcczAxMYGtrS3Gjx+P4uJinTpr1qyBp6cn1Go1HB0dMXnyZJ31V69exaBBg2Bqagp3d3ds3bpVWvfXX39h+PDhaN68OUxMTODu7l7lDxCipo6BTkQPNHfuXAwePBinT5/G8OHD8corryA9PR0AUFJSgqCgINjY2ODo0aOIj4/H7t27dQJ75cqVmDRpEsaPH4+UlBRs3boVbdq00elj/vz5GDp0KM6cOYMXXngBw4cPR35+vtR/WloafvzxR6Snp2PlypWws7N7dBNA9Dho6Me9EVHDCgsLEwYGBsLMzExnef/994UQQgAQEyZM0NnGz89PvPHGG0IIIT7//HNhY2MjiouLpfXbtm0TSqVSeq61k5OTmD179n3HAEDMmTNHel1cXCwAiB9//FEIIUT//v3FmDFj9LPDRDLF79CJCM8++yxWrlypU9asWTPp3/7+/jrr/P39cerUKQBAeno6vL29YWZmJq3v3r07tFotMjIyoFAo8Oeff6J37941jqFjx47Sv83MzGBpaYm8vDwAwBtvvIHBgwfjxIkT6NOnD0JCQtCtW7d/tK9EcsVAJyKYmZlVOQWuLyYmJrWqZ2RkpPNaoVBAq9UCAPr27YvMzExs374du3btQu/evTFp0iQsXrxY7+MlelzxO3QieqDDhw9Xed2+fXsAQPv27XH69GmUlJRI6w8ePAilUgkPDw9YWFjAzc0NiYmJDzWG5s2bIywsDF9//TWio6Px+eefP1R7RHLDI3QiQmlpKXJycnTKDA0NpQvP4uPj0aVLF/To0QPffPMNkpOTERMTAwAYPnw4IiIiEBYWhsjISFy5cgVTpkzByJEj4eDgAACIjIzEhAkTYG9vj759++L69es4ePAgpkyZUqvxzZs3D507d4anpydKS0vxww8/SH9QENEdDHQiQkJCAhwdHXXKPDw8cPbsWQB3rkCPi4vDxIkT4ejoiPXr16NDhw4AAFNTU+zYsQNvvvkmunbtClNTUwwePBhLliyR2goLC8OtW7ewdOlSTJ8+HXZ2dnj55ZdrPT6VSoVZs2bhwoULMDExwTPPPIO4uDg97DmRfCiEEKKhB0FEjZdCocDmzZsREhLS0EMhohrwO3QiIiIZYKATERHJAL9DJ6Ia8Vs5oscDj9CJiIhkgIFOREQkAwx0IiIiGWCgExERyQADnYiISAYY6ERERDLAQCciIpIBBjoREZEMMNCJiIhkgIFOREQkAwx0IiIiGWCgExERyQADnYiISAYY6ERERDLw/wBFZdpccSFQkQAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mplot\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'matplotlib.pyplot' from '/usr/local/lib/python3.12/site-packages/matplotlib/pyplot.py'>\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mFigure\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mAxis\u001b[39m\n",
       "\u001b[36mlossExamplesSeen\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mLong\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m111200L\u001b[39m)\n",
       "\u001b[36mtrainingLoss\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m0.7839783430099487\u001b[39m)\n",
       "\u001b[36mvalidationLoss\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m0.7070853114128113\u001b[39m)\n",
       "\u001b[36maccuracyExamplesSeen\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mLong\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m111200L\u001b[39m)\n",
       "\u001b[36mtrainingAccuracy\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m1.0\u001b[39m)\n",
       "\u001b[36mvalidationAccuracy\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m0.875\u001b[39m)\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mplotValues\u001b[39m"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plot = py.module(\"matplotlib.pyplot\")\n",
    "  \n",
    "type Figure = py.Dynamic\n",
    "type Axis = py.Dynamic\n",
    "\n",
    "val (lossExamplesSeen, trainingLoss, validationLoss) = trainingEpochs.flatMap(_.trainingSteps).map {\n",
    "  case TrainingStep(Loss(trainingLoss, validationLoss), examplesSeen) => (examplesSeen, trainingLoss, validationLoss)\n",
    "}.unzip3\n",
    "\n",
    "val (accuracyExamplesSeen, trainingAccuracy, validationAccuracy) = trainingEpochs.map {\n",
    "  case TrainingEpoch(trainingSteps, Accuracy(trainingAccuracy, validationAccuracy)) => \n",
    "    (trainingSteps.last.examplesSeen, trainingAccuracy, validationAccuracy)\n",
    "}.unzip3\n",
    "\n",
    "def plotValues(examplesSeen: List[Long], trainingValues: List[Double], validationValues: List[Double], label: String) =\n",
    "  try {\n",
    "    val epochs = torch.linspace(0, trainingEpochs.length, examplesSeen.length)\n",
    "    val (figure, axis1) = plot.subplots(figsize = (5, 3)).as[(Figure, Axis)]\n",
    "    axis1.plot(epochs, trainingValues.toPythonProxy, label = s\"Training $label\")\n",
    "    axis1.plot(epochs, validationValues.toPythonProxy, linestyle = \"-.\", label = s\"Validation $label\")\n",
    "    axis1.set_xlabel(\"Epochs\")\n",
    "    axis1.set_ylabel(label.capitalize)\n",
    "    axis1.legend()\n",
    "    val axis2 = axis1.twiny()\n",
    "    axis2.plot(examplesSeen.toPythonProxy, trainingValues.toPythonProxy, alpha = 0)\n",
    "    axis2.set_xlabel(\"Examples seen\")\n",
    "    figure.tight_layout()\n",
    "    DisplaySupport.showPlot(plot)\n",
    "  } catch {\n",
    "    case e: py.PythonException =>\n",
    "      println(\"(!) If the exception below says 'Numpy is not available', restart the Jupyter kernel. It's an issue with Matplotlib in Jupyter.\\n\")\n",
    "      throw e\n",
    "  }\n",
    "\n",
    "plotValues(lossExamplesSeen, trainingLoss, validationLoss, label = \"loss\")\n",
    "plotValues(accuracyExamplesSeen, trainingAccuracy, validationAccuracy, label = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64e012e0-e163-4934-bca9-8b9e91ab03d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 95.00%\n",
      "Validation accuracy: 82.50%\n",
      "Test accuracy: 91.25%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.95\u001b[39m\n",
       "\u001b[36mvalidationAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.825\u001b[39m\n",
       "\u001b[36mtestAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.9125\u001b[39m"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingAccuracy = calculateDataLoaderAccuracy(model, device)(trainingLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Training accuracy: ${trainingAccuracy * 100}%.2f%%\")\n",
    "val validationAccuracy = calculateDataLoaderAccuracy(model, device)(validationLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Validation accuracy: ${validationAccuracy * 100}%.2f%%\")\n",
    "val testAccuracy = calculateDataLoaderAccuracy(model, device)(testLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Test accuracy: ${testAccuracy * 100}%.2f%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "252ad17d-6123-4fa7-a604-bc506d66bdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a winner you have been specially\n",
      " selected to receive $1000 cash or a $2000 award.\n",
      "\n",
      "Hey, just wanted to check if we're still on\n",
      " for dinner tonight? Let me know!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mclassifySpam\u001b[39m\n",
       "\u001b[36mtext1\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"You are a winner you have been specially\n",
       " selected to receive $1000 cash or a $2000 award.\"\"\"\u001b[39m\n",
       "\u001b[36mtext2\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"Hey, just wanted to check if we're still on\n",
       " for dinner tonight? Let me know!\"\"\"\u001b[39m"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classifySpam(\n",
    "  model: Model,\n",
    "  tokenizer: Tokenizer,\n",
    "  maxLength: Option[Int] = None,\n",
    "  paddingTokenId: Int = 50_256\n",
    ")(\n",
    "  text: String\n",
    ") = {\n",
    "  model.eval()\n",
    "  val encodedText = tokenizer.encode(text).as[Seq[Int]].toVector\n",
    "  val padToLength = maxLength.getOrElse(trainingDataset.maxLength.as[Int])\n",
    "  val paddedEncodedText = encodedText.padTo(padToLength, paddingTokenId)\n",
    "  val inputTensor = torch.tensor(paddedEncodedText.toPythonProxy).unsqueeze(0)\n",
    "  val logits = py.`with`(torch.no_grad()) { _ =>\n",
    "    model(inputTensor)\n",
    "  }\n",
    "  val predictedClass = torch.argmax(py\"$logits[:, -1, :]\", dim = -1).item()\n",
    "  if (predictedClass == 1)\n",
    "    print(\"[SPAM] \")\n",
    "  println(text)\n",
    "}\n",
    "\n",
    "val text1 = \"You are a winner you have been specially\\n selected to receive $1000 cash or a $2000 award.\"\n",
    "classifySpam(model, tokenizer)(text1)\n",
    "\n",
    "println()\n",
    "\n",
    "val text2 = \"Hey, just wanted to check if we're still on\\n for dinner tonight? Let me know!\"\n",
    "classifySpam(model, tokenizer)(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880bd092-6191-4a9f-98c9-657fb36ade70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13.14",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
