{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73e9304-0b46-4a79-81f5-af4e977bf44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $file.^.Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87b69a7-66f9-475b-9cf1-b8e88f67ec29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mzipName\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"sms+spam+collection.zip\"\u001b[39m\n",
       "\u001b[36mdatasetUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\u001b[39m\n",
       "\u001b[36moutputDir\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/sms-spam-raw\"\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val zipName = \"sms+spam+collection.zip\"\n",
    "val datasetUrl = s\"https://archive.ics.uci.edu/static/public/228/$zipName\"\n",
    "val outputDir = \"data/sms-spam-raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048673b9-9ae6-4d7c-8d60-60a1a383f667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "100  198k    0  198k    0     0  98299      0 --:--:--  0:00:02 --:--:-- 98315\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"curl\", \"--create-dirs\", \"-O\", \"--output-dir\", outputDir, datasetUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fdc00a5-7737-4164-90b6-7914a4332ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/sms-spam-raw/sms+spam+collection.zip\n",
      "  inflating: data/sms-spam-raw/SMSSpamCollection  \n",
      "  inflating: data/sms-spam-raw/readme  \n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"unzip\", \"-o\", s\"$outputDir/$zipName\", \"-d\", outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28347282-363e-45e5-93c9-4385a6631506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam count: 747\n",
      "Not spam count: 4827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\u001b[39m\n",
       "\u001b[36mdatasetRaw\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
       "ham\tOk lar... Joking wif u oni...\n",
       "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
       "ham\tU dun say so early hor... U c already then say...\n",
       "ham\tNah I don't think he goes to usf, he lives around here though\n",
       "spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
       "ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
       "ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
       "spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
       "spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
       "ham\tI'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
       "spam\tSIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
       "spam\tURGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
       "ham\tI've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
       "ham\tI HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "spam\tXXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL\n",
       "ham\tOh k...i'm watching here:)\n",
       "ham\tEh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.\n",
       "ham\tFine if thats the way u feel. Thats the way its gota b\n",
       "spam\tEngland v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+\n",
       "ham\tIs that seriously how you spell his name?\n",
       "ham\tI‘m going to try for 2 months ha ha only joking\n",
       "\u001b[39m...\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mSmsSpamRecord\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mDataset\u001b[39m\n",
       "\u001b[36msmsSpamRecords\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Ok lar... Joking wif u oni...\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"U dun say so early hor... U c already then say...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Nah I don't think he goes to usf, he lives around here though\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Even my brother is not like to speak with me. They treat me like aids patent.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "...\n",
       "\u001b[36mspamRecords\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mSmsSpamRecord\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCB\u001b[39m...\n",
       "\u001b[36mnotSpamRecords\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mSmsSpamRecord\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Ok lar... Joking wif u oni...\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"U dun say so early hor... U c already then say...\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Nah I don't think he goes to usf, he lives around here though\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Even my brother is not like to speak with me. They treat me like aids patent.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"I HAVE A DATE ON SUNDAY WITH WILL!!\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Oh k...i'm watching here:)\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.io.Source\n",
    "\n",
    "val datasetRaw = Source.fromFile(s\"$outputDir/SMSSpamCollection\").mkString\n",
    "\n",
    "case class SmsSpamRecord(\n",
    "  text: String,\n",
    "  isSpam: Boolean\n",
    ")\n",
    "\n",
    "type Dataset = Vector[SmsSpamRecord]\n",
    "\n",
    "val smsSpamRecords: Dataset = datasetRaw.split(\"\\n\").map {\n",
    "  case s\"spam\\t$text\" => SmsSpamRecord(text, isSpam = true)\n",
    "  case s\"ham\\t$text\" => SmsSpamRecord(text, isSpam = false)\n",
    "}.toVector\n",
    "\n",
    "val (spamRecords, notSpamRecords) = smsSpamRecords.partition(_.isSpam)\n",
    "println(s\"Spam count: ${spamRecords.size}\")\n",
    "println(s\"Not spam count: ${notSpamRecords.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e244291-9733-4821-a534-f6cd331a4ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\u001b[39m\n",
       "\u001b[36mbalancedDataset\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCB\u001b[39m..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable\n",
    "import scala.util.Random\n",
    "\n",
    "val balancedDataset: Dataset = {\n",
    "\n",
    "  def sample(records: Vector[SmsSpamRecord], targetSize: Int): Vector[SmsSpamRecord] = {\n",
    "    val balancedDatasetSpam = mutable.Map[String, SmsSpamRecord]()\n",
    "    while (balancedDatasetSpam.size < targetSize) {\n",
    "      val randomRecord = records(Random.nextInt(records.size))\n",
    "      if (!balancedDatasetSpam.contains(randomRecord.text))\n",
    "        balancedDatasetSpam += randomRecord.text -> randomRecord\n",
    "    }\n",
    "    balancedDatasetSpam.values.toVector\n",
    "  }\n",
    "\n",
    "  if (spamRecords.size < notSpamRecords.size)\n",
    "    spamRecords ++ sample(notSpamRecords, targetSize = spamRecords.size)\n",
    "  else\n",
    "    notSpamRecords ++ sample(spamRecords, targetSize = notSpamRecords.size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba96609-d9fa-440e-9556-b3d0f3b104d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mTraining\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mValidation\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mTest\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mrandomSplit\u001b[39m\n",
       "\u001b[36mtraining\u001b[39m: \u001b[32mTraining\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"pdate_Now - Double mins and 1000 txts on Orange tariffs. Latest Motorola, SonyEricsson & Nokia & Bluetooth FREE! Call MobileUpd8 on 08000839402 or call2optout/!YHL\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"500 New Mobiles from 2004, MUST GO! Txt: NOKIA to No: 89545 & collect yours today!From ONLY £1 www.4-tc.biz 2optout 087187262701.50gbp/mtmsg18\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"FreeMsg Hey U, i just got 1 of these video/pic fones, reply WILD to this txt & ill send U my pics, hurry up Im so bored at work xxx (18 150p/rcvd STOP2stop)\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Now press conference da:)\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"You are guaranteed the latest Nokia Phone, a 40GB iPod MP3 player or a £500 prize! Txt word: COLLECT to No: 83355! IBHltd LdnW15H 150p/Mtmsgrcvd18+\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"We tried to contact you re our offer of New Video Phone 750 anytime any network mins HALF PRICE Rental camcorder call 08000930705 or reply for delivery Wed\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT We are trying to contact you Last weekends draw shows u have won a £1000 prize GUARANTEED Call 09064017295 Claim code K52 Valid 12hrs 150p pm\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT! We are trying to contact U. Todays draw shows that you have \u001b[39m...\n",
       "\u001b[36mvalidation\u001b[39m: \u001b[32mValidation\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"U were outbid by simonwatson5120 on the Shinco DVD Plyr. 2 bid again, visit sms. ac/smsrewards 2 end bid notifications, reply END OUT\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Got what it takes 2 take part in the WRC Rally in Oz? U can with Lucozade Energy! Text RALLY LE to 61200 (25p), see packs or lucozade.co.uk/wrc & itcould be u!\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"You are a winner you have been specially selected to receive £1000 cash or a £2000 award. Speak to a live operator to claim call 087147123779am-7pm. Cost 10p\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Sex up ur mobile with a FREE sexy pic of Jordan! Just text BABE to 88600. Then every wk get a sexy celeb! PocketBabe.co.uk 4 more pics. 16 £3/wk 087016248\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"The world is running and i am still.maybe all are feeling the same,so be it.or i have to admit,i am mad.then where is the correction?or let me call this is life.and keep running with the world,may be u r also running.lets run.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"WIN a year supply of CDs 4 a store of ur choice worth £500 & enter our £100 Weekly draw txt MUSIC to 87066 Ts&Cs www.Ldew.com.subs16+1win150ppmx3\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Wat's my dear doing? Sleeping ah?\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Must come later.. I normally bathe him in da afternoon mah..\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "...\n",
       "\u001b[36mtest\u001b[39m: \u001b[32mTest\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"URGENT! Your Mobile No 07808726822 was awarded a £2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Pls call me da. What happen.\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"I'm going for bath will msg you next  &lt;#&gt;  min..\"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"BIG BROTHER ALERT! The computer has selected u for 10k cash or #150 voucher. Call 09064018838. NTT PO Box CRO1327 18+ BT Landline Cost 150ppm mobiles vary\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(text = \u001b[32m\"Are you staying in town ?\"\u001b[39m, isSpam = \u001b[32mfalse\u001b[39m),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Okies... I'll go yan jiu too... We can skip ard oso, go cine den go mrt one, blah blah blah... \"\u001b[39m,\n",
       "    isSpam = \u001b[32mfalse\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Adult 18 Content Your video will be with you shortly\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "  ),\n",
       "  \u001b[33mSmsSpamRecord\u001b[39m(\n",
       "    text = \u001b[32m\"Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out!\"\u001b[39m,\n",
       "    isSpam = \u001b[32mtrue\u001b[39m\n",
       "..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Training = Dataset\n",
    "type Validation = Dataset\n",
    "type Test = Dataset\n",
    "\n",
    "def randomSplit(dataset: Vector[SmsSpamRecord], trainingFraction: Double, validationFraction: Double): (Training, Validation, Test) = {\n",
    "  val shuffledDataset = Random.shuffle(dataset)\n",
    "  val trainingSize = (shuffledDataset.size * trainingFraction).floor.toInt\n",
    "  val validationSize = (shuffledDataset.size * validationFraction).floor.toInt\n",
    "\n",
    "  val (training, remainingRecords) = shuffledDataset.splitAt(trainingSize)\n",
    "  val (validation, test) = remainingRecords.splitAt(validationSize)\n",
    "  (training, validation, test)\n",
    "}\n",
    "\n",
    "val (training, validation, test) = randomSplit(balancedDataset, trainingFraction = 0.7, validationFraction = 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c33bb0b-ea20-4a02-8606-a28dab16f9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Using\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.github.tototoshi.csv.CSVWriter\u001b[39m\n",
       "\u001b[36mtextHeader\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Text\"\u001b[39m\n",
       "\u001b[36mlabelHeader\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Label\"\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mwriteToCsv\u001b[39m\n",
       "\u001b[36mtrainingCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/training.csv\"\u001b[39m\n",
       "\u001b[36mvalidationCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/validation.csv\"\u001b[39m\n",
       "\u001b[36mtestCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/test.csv\"\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.github.tototoshi::scala-csv:2.0.0`\n",
    "\n",
    "import scala.util.Using\n",
    "import com.github.tototoshi.csv.CSVWriter\n",
    "\n",
    "val textHeader = \"Text\"\n",
    "val labelHeader = \"Label\"\n",
    "\n",
    "def writeToCsv(path: String, dataset: Dataset): Unit = {\n",
    "  val headers = Vector(textHeader, labelHeader)\n",
    "\n",
    "  Using.resource(CSVWriter.open(path)) { writer =>\n",
    "    val rows = dataset.map {\n",
    "      case SmsSpamRecord(text, isSpam) => Vector(text, if (isSpam) \"1\" else \"0\")\n",
    "    }\n",
    "    writer.writeAll(headers +: rows)\n",
    "  }\n",
    "}\n",
    "\n",
    "val trainingCsv = \"data/training.csv\"\n",
    "writeToCsv(trainingCsv, training)\n",
    "val validationCsv = \"data/validation.csv\"\n",
    "writeToCsv(validationCsv, validation)\n",
    "val testCsv = \"data/test.csv\"\n",
    "writeToCsv(testCsv, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ba9697-4121-41ec-ad86-4ca468d8caad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken==0.7.* in /usr/local/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/site-packages (from tiktoken==0.7.*) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/site-packages (from tiktoken==0.7.*) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.*) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"tiktoken==0.7.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac863ee-648b-40f4-bb1d-275a7b2657bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mme.shadaj.scalapy.py\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mpy.SeqConverters\u001b[39m\n",
       "\u001b[36mtiktoken\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'tiktoken' from '/usr/local/lib/python3.12/site-packages/tiktoken/__init__.py'>\n",
       "\u001b[36mtokenizer\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <Encoding 'gpt2'>\n",
       "\u001b[36mendOfTextToken\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"<|endoftext|>\"\u001b[39m\n",
       "\u001b[36mencodedEndOfTextToken\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = [50256]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`dev.scalapy::scalapy-core:0.5.3`\n",
    "\n",
    "import me.shadaj.scalapy.py\n",
    "import py.SeqConverters\n",
    "\n",
    "val tiktoken = py.module(\"tiktoken\")\n",
    "\n",
    "val tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "val endOfTextToken = \"<|endoftext|>\"\n",
    "val encodedEndOfTextToken = tokenizer.encode(endOfTextToken, allowed_special = py.Dynamic.global.set(Seq(endOfTextToken).toPythonProxy))\n",
    "println(encodedEndOfTextToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67d18733-4b85-41ed-8717-07f261b5ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.4.* in /usr/local/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (75.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch==2.4.*) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy->torch==2.4.*) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"torch==2.4.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910a813f-f2c6-4410-9c73-8687f41294ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mcom.github.tototoshi.csv.CSVReader\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mpy.PyQuote\u001b[39m\n",
       "\u001b[36mtorch\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'torch' from '/usr/local/lib/python3.12/site-packages/torch/__init__.py'>\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mTokenizer\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mSpamDataset\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.github.tototoshi.csv.CSVReader\n",
    "import py.PyQuote\n",
    "\n",
    "val torch = py.module(\"torch\")\n",
    "\n",
    "type Tokenizer = py.Dynamic\n",
    "\n",
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"from torch.utils.data import Dataset\n",
    "     |\n",
    "     |class SpamDataset(Dataset):\n",
    "     |  def __init__(self, init):\n",
    "     |    init(self)\n",
    "     |\n",
    "     |  def __getitem__(self, index):\n",
    "     |    return self.getItem(index)\n",
    "     |  \n",
    "     |  def __len__(self):\n",
    "     |    return self.len()\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def SpamDataset(\n",
    "  csvPath: String,\n",
    "  tokenizer: Tokenizer,\n",
    "  maxLength: Option[Int] = None,\n",
    "  paddingTokenId: Int = 50_256\n",
    "): py.Dynamic = {\n",
    "  val smsSpamRecords = Using.resource(CSVReader.open(csvPath)) { csvReader =>\n",
    "    csvReader.iteratorWithHeaders.map { row =>\n",
    "      SmsSpamRecord(text = row(textHeader), isSpam = row(labelHeader).toInt > 0)\n",
    "    }.toVector\n",
    "  }\n",
    "  val encodedTexts = {\n",
    "    val encodedTexts = smsSpamRecords.map(_.text).map(tokenizer.encode(_).as[Seq[Int]].toVector)\n",
    "    val padToLength = maxLength.getOrElse(encodedTexts.map(_.length).max)\n",
    "    encodedTexts.map(_.padTo(padToLength, paddingTokenId))\n",
    "  }\n",
    "    \n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.maxLength = encodedTexts.head.length\n",
    "    \n",
    "    val getItem = (index: Int) => {\n",
    "      val textTensor = torch.tensor(encodedTexts(index).toPythonProxy, dtype = torch.long)\n",
    "      val labelTensor = torch.tensor(if (smsSpamRecords(index).isSpam) 1 else 0, dtype = torch.long)\n",
    "      (textTensor, labelTensor)\n",
    "    }\n",
    "    self.getItem = getItem\n",
    "\n",
    "    val len = () => smsSpamRecords.size\n",
    "    self.len = len\n",
    "  }\n",
    "  py.Dynamic.global.SpamDataset(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db6947e-949f-465d-90f3-2588cd796fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingDataset\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <SpamDataset object at 0xffff62f24a70>\n",
       "\u001b[36mvalidationDataset\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <SpamDataset object at 0xffff62f24ef0>\n",
       "\u001b[36mtestDataset\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <SpamDataset object at 0xffff62f253a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingDataset = SpamDataset(trainingCsv, tokenizer)\n",
    "val validationDataset = SpamDataset(validationCsv, tokenizer, maxLength = Some(trainingDataset.maxLength.as[Int]))\n",
    "val testDataset = SpamDataset(testCsv, tokenizer, maxLength = Some(trainingDataset.maxLength.as[Int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9939eb92-a199-4019-91c4-67833cc92e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mbatchSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m8\u001b[39m\n",
       "\u001b[36mres14_1\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xffff7d328790>\n",
       "\u001b[36mtrainingLoader\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch.utils.data.dataloader.DataLoader object at 0xffff63311790>\n",
       "\u001b[36mvalidationLoader\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch.utils.data.dataloader.DataLoader object at 0xffff7020ccb0>\n",
       "\u001b[36mtestLoader\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch.utils.data.dataloader.DataLoader object at 0xffff7035c1d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val batchSize = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "val trainingLoader = torch.utils.data.DataLoader(\n",
    "  dataset = trainingDataset, \n",
    "  batch_size = batchSize,\n",
    "  shuffle = true,\n",
    "  num_workers = 0,\n",
    "  drop_last = true\n",
    ")\n",
    "val validationLoader = torch.utils.data.DataLoader(\n",
    "  dataset = validationDataset, \n",
    "  batch_size = batchSize,\n",
    "  num_workers = 0,\n",
    "  drop_last = false\n",
    ")\n",
    "val testLoader = torch.utils.data.DataLoader(\n",
    "  dataset = testDataset, \n",
    "  batch_size = batchSize,\n",
    "  num_workers = 0,\n",
    "  drop_last = false\n",
    ")\n",
    "\n",
    "println(s\"${py.Dynamic.global.len(trainingLoader)} training batches\")\n",
    "println(s\"${py.Dynamic.global.len(validationLoader)} validation batches\")\n",
    "println(s\"${py.Dynamic.global.len(testLoader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d34644-7ac9-4277-9ae4-b6aaa38bc6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mGPTConfig\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class GPTConfig(\n",
    "  vocabularySize: Int,\n",
    "  contextLength: Int,\n",
    "  embeddingDimension: Int,\n",
    "  attentionHeadsCount: Int,\n",
    "  layersCount: Int,\n",
    "  dropoutRate: Double,\n",
    "  queryKeyValueBias: Boolean\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2dfd43d-f02c-4c1a-8eb3-817c92b539a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mTorchTensor\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mMultiHeadAttention\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type TorchTensor = py.Dynamic\n",
    "\n",
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class MultiHeadAttention(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def MultiHeadAttention(\n",
    "  inputDimension: Int,\n",
    "  outputDimension: Int,\n",
    "  dropoutProbability: Double,\n",
    "  contextLength: Int,\n",
    "  headsCount: Int,\n",
    "  queryKeyValueBias: Boolean\n",
    "): py.Dynamic = {\n",
    "  assert(outputDimension % headsCount == 0, \"Output dimension must be a multiple of heads count\")\n",
    "  val headDimension = outputDimension / headsCount\n",
    "    \n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.weightsQuery = torch.nn.Linear(inputDimension, outputDimension, bias = queryKeyValueBias)\n",
    "    self.weightsKey = torch.nn.Linear(inputDimension, outputDimension, bias = queryKeyValueBias)\n",
    "    self.weightsValue = torch.nn.Linear(inputDimension, outputDimension, bias = queryKeyValueBias)\n",
    "    self.outputProjection = torch.nn.Linear(outputDimension, outputDimension)\n",
    "    self.dropout = torch.nn.Dropout(dropoutProbability)\n",
    "    self.register_buffer(\"mask\", torch.triu(torch.ones(contextLength, contextLength), diagonal = 1))\n",
    "      \n",
    "    val forward = (batchedInputs: TorchTensor) => {\n",
    "      val (batchesCount, tokensCount, tokenDimension) = batchedInputs.shape.as[(Int, Int, Int)]\n",
    "      val queries = self.weightsQuery(batchedInputs)\n",
    "        .view(batchesCount, tokensCount, headsCount, headDimension)\n",
    "        .transpose(1, 2)\n",
    "      val keys = self.weightsKey(batchedInputs)\n",
    "        .view(batchesCount, tokensCount, headsCount, headDimension)\n",
    "        .transpose(1, 2)\n",
    "      val values = self.weightsValue(batchedInputs)\n",
    "        .view(batchesCount, tokensCount, headsCount, headDimension)\n",
    "        .transpose(1, 2)\n",
    "      val attentionScores = py\"$queries @ $keys.transpose(2, 3)\"\n",
    "      attentionScores.masked_fill_(py\"${self.mask}.bool()[:$tokensCount, :$tokensCount]\", -torch.inf)\n",
    "      val attentionWeights = self.dropout(torch.softmax(py\"$attentionScores / $headDimension**0.5\", dim = -1))\n",
    "      self.outputProjection(\n",
    "        py\"$attentionWeights @ $values\"\n",
    "          .transpose(1, 2)\n",
    "          .reshape(batchesCount, tokensCount, outputDimension)\n",
    "      )\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.MultiHeadAttention(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7799670d-e179-4188-b8c9-d9393033d141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mGELU\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "// Because it mostly uses Python operators, it's implemented fully in Python\n",
    "py.exec {\n",
    "  s\"\"\"import torch\n",
    "     |import torch.nn as nn\n",
    "     |\n",
    "     |class GELU(nn.Module):\n",
    "     |  def __init__(self):\n",
    "     |    super().__init__()\n",
    "     |\n",
    "     |  def forward(self, inputs):\n",
    "     |    return 0.5 * inputs * (\n",
    "     |      1 + torch.tanh(\n",
    "     |        torch.sqrt(torch.tensor(2.0 / torch.pi)) * (inputs + 0.044715 * torch.pow(inputs, 3))\n",
    "     |      )\n",
    "     |    )\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def GELU() = py.Dynamic.global.GELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb61e38-8be9-4729-9e86-6c90eb8de235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mFeedForward\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class FeedForward(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def FeedForward(\n",
    "  embeddingDimension: Int\n",
    "): py.Dynamic = {\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.layers = torch.nn.Sequential(\n",
    "      torch.nn.Linear(embeddingDimension, 4 * embeddingDimension),\n",
    "      GELU(),\n",
    "      torch.nn.Linear(4 * embeddingDimension, embeddingDimension)\n",
    "    )\n",
    "      \n",
    "    val forward = (inputs: TorchTensor) => self.layers(inputs)\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.FeedForward(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3a80736-2a99-4310-b59f-20edb7bbac85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mNormalizationLayer\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class NormalizationLayer(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def NormalizationLayer(\n",
    "  embeddingDimension: Int\n",
    "): py.Dynamic = {\n",
    "  val epsilon = 1e-5\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.scale = torch.nn.Parameter(torch.ones(embeddingDimension))\n",
    "    self.shift = torch.nn.Parameter(torch.zeros(embeddingDimension))\n",
    "      \n",
    "    val forward = (inputs: TorchTensor) => {\n",
    "      val mean = inputs.mean(dim = -1, keepdim = true)\n",
    "      val variance = inputs.`var`(dim = -1, keepdim = true, unbiased = false)\n",
    "      val normalizedInputs = py\"($inputs - $mean) / torch.sqrt($variance + $epsilon)\"\n",
    "      py\"${self.scale} * $normalizedInputs + ${self.shift}\"\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.NormalizationLayer(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1b07cba-e201-4209-9980-21948569c2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.chaining._\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mTransformerBlock\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.util.chaining._\n",
    "\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class TransformerBlock(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "def TransformerBlock(\n",
    "  config: GPTConfig\n",
    "): py.Dynamic = {\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.multiHeadAttention = MultiHeadAttention(\n",
    "      inputDimension = config.embeddingDimension,\n",
    "      outputDimension = config.embeddingDimension,\n",
    "      dropoutProbability = config.dropoutRate,\n",
    "      contextLength = config.contextLength,\n",
    "      headsCount = config.attentionHeadsCount,\n",
    "      queryKeyValueBias = config.queryKeyValueBias\n",
    "    )\n",
    "    self.feedForward = FeedForward(config.embeddingDimension)\n",
    "    self.normalization1 = NormalizationLayer(config.embeddingDimension)\n",
    "    self.normalization2 = NormalizationLayer(config.embeddingDimension)\n",
    "    self.dropoutShortcut = torch.nn.Dropout(config.dropoutRate)\n",
    "    \n",
    "    val forward = (inputs: TorchTensor) => {\n",
    "      val shortcut = inputs\n",
    "      val newShortcut = inputs\n",
    "        .pipe(self.normalization1(_))\n",
    "        .pipe(self.multiHeadAttention(_))\n",
    "        .pipe(self.dropoutShortcut(_))\n",
    "        .pipe(o => py\"$o + $shortcut\")\n",
    "      newShortcut\n",
    "        .pipe(self.normalization2(_))\n",
    "        .pipe(self.feedForward(_))\n",
    "        .pipe(self.dropoutShortcut(_))\n",
    "        .pipe(o => py\"$o + $newShortcut\")\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.TransformerBlock(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2974f19c-5b76-4ed2-a6d7-5bca875ddaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mModel\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mGPTModel\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class GPTModel(nn.Module):\n",
    "     |  def __init__(self, init):\n",
    "     |    super().__init__()\n",
    "     |    init(self)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "type Model = py.Dynamic\n",
    "def GPTModel(\n",
    "  config: GPTConfig\n",
    "): Model = {\n",
    "  val transformerBlocks = Seq.fill(config.layersCount)(TransformerBlock(config))\n",
    "  val init = (self: py.Dynamic) => {\n",
    "    self.tokenEmbeddingLayer = torch.nn.Embedding(config.vocabularySize, config.embeddingDimension)\n",
    "    self.positionEmbeddingLayer = torch.nn.Embedding(config.contextLength, config.embeddingDimension)\n",
    "    self.dropoutEmbeddingLayer = torch.nn.Dropout(config.dropoutRate)\n",
    "    self.transformerBlocksLayer = py\"nn.Sequential(*${transformerBlocks.toPythonProxy})\"\n",
    "    self.finalNormalizationLayer = NormalizationLayer(config.embeddingDimension)\n",
    "    self.outputLayer = torch.nn.Linear(config.embeddingDimension, config.vocabularySize, bias = false)\n",
    "      \n",
    "    val forward = (batchedInputs: TorchTensor) => {\n",
    "      val (_, sequenceLength) = batchedInputs.shape.as[(Int, Int)]\n",
    "      val tokenEmbeddings = self.tokenEmbeddingLayer(batchedInputs)\n",
    "      val positionEmbeddings = self.positionEmbeddingLayer(torch.arange(sequenceLength, device = batchedInputs.device))\n",
    "      py\"$tokenEmbeddings + $positionEmbeddings\"\n",
    "        .pipe(self.dropoutEmbeddingLayer(_))\n",
    "        .pipe(self.transformerBlocksLayer(_))\n",
    "        .pipe(self.finalNormalizationLayer(_))\n",
    "        .pipe(self.outputLayer(_))\n",
    "    }\n",
    "    self.forward = forward\n",
    "  }\n",
    "  py.Dynamic.global.GPTModel(init)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e2bb752-7eb2-4fcb-9e0d-425bbb51f8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbaseUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2/124M\"\u001b[39m\n",
       "\u001b[36mhparamsFilename\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"hparams.json\"\u001b[39m\n",
       "\u001b[36mfilenames\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m\"checkpoint\"\u001b[39m,\n",
       "  \u001b[32m\"encoder.json\"\u001b[39m,\n",
       "  \u001b[32m\"hparams.json\"\u001b[39m,\n",
       "  \u001b[32m\"model.ckpt.data-00000-of-00001\"\u001b[39m,\n",
       "  \u001b[32m\"model.ckpt.index\"\u001b[39m,\n",
       "  \u001b[32m\"model.ckpt.meta\"\u001b[39m,\n",
       "  \u001b[32m\"vocab.bpe\"\u001b[39m\n",
       ")\n",
       "\u001b[36moutputDir\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data/openai124M\"\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val baseUrl = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2/124M\"\n",
    "// val baseUrl = \"https://openaipublic.blob.core.windows.net/gpt-2/models/124M\" // backup\n",
    "val hparamsFilename = \"hparams.json\"\n",
    "val filenames = List(\"checkpoint\", \"encoder.json\", hparamsFilename, \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\", \"model.ckpt.meta\", \"vocab.bpe\")\n",
    "\n",
    "val outputDir = \"data/openai124M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff93551d-b4f8-42e8-8ff7-9394cb75125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    77  100    77    0     0     82      0 --:--:-- --:--:-- --:--:--    82\n",
      "100    77  100    77    0     0     82      0 --:--:-- --:--:-- --:--:--    82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading encoder.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 56 1017k   56  575k    0     0   301k      0  0:00:03  0:00:01  0:00:02  301k\n",
      "100 1017k  100 1017k    0     0   494k      0  0:00:02  0:00:02 --:--:--  494k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading hparams.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    90  100    90    0     0    125      0 --:--:-- --:--:-- --:--:--   125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model.ckpt.data-00000-of-00001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  474M    0 56845    0     0  51370      0  2:41:29  0:00:01  2:41:28 51350\n",
      "  0  474M    0 2455k    0     0  1167k      0  0:06:56  0:00:02  0:06:54 1167k\n",
      "  3  474M    3 16.5M    0     0  5459k      0  0:01:29  0:00:03  0:01:26 5459k\n",
      "  6  474M    6 30.9M    0     0  7718k      0  0:01:02  0:00:04  0:00:58 7717k\n",
      "  9  474M    9 46.3M    0     0  9281k      0  0:00:52  0:00:05  0:00:47 9728k\n",
      " 12  474M   12 61.5M    0     0  10.0M      0  0:00:47  0:00:06  0:00:41 12.2M\n",
      " 16  474M   16 76.8M    0     0  10.8M      0  0:00:43  0:00:07  0:00:36 14.8M\n",
      " 19  474M   19 91.6M    0     0  11.2M      0  0:00:42  0:00:08  0:00:34 14.9M\n",
      " 22  474M   22  104M    0     0  11.5M      0  0:00:41  0:00:09  0:00:32 14.7M\n",
      " 25  474M   25  120M    0     0  11.8M      0  0:00:40  0:00:10  0:00:30 14.6M\n",
      " 28  474M   28  135M    0     0  12.1M      0  0:00:39  0:00:11  0:00:28 14.6M\n",
      " 31  474M   31  149M    0     0  12.2M      0  0:00:38  0:00:12  0:00:26 14.2M\n",
      " 33  474M   33  158M    0     0  12.0M      0  0:00:39  0:00:13  0:00:26 13.4M\n",
      " 36  474M   36  174M    0     0  12.3M      0  0:00:38  0:00:14  0:00:24 13.7M\n",
      " 39  474M   39  188M    0     0  12.4M      0  0:00:38  0:00:15  0:00:23 13.7M\n",
      " 42  474M   42  203M    0     0  12.6M      0  0:00:37  0:00:16  0:00:21 13.6M\n",
      " 45  474M   45  218M    0     0  12.7M      0  0:00:37  0:00:17  0:00:20 13.8M\n",
      " 49  474M   49  233M    0     0  12.8M      0  0:00:36  0:00:18  0:00:18 14.8M\n",
      " 52  474M   52  248M    0     0  13.0M      0  0:00:36  0:00:19  0:00:17 14.9M\n",
      " 55  474M   55  263M    0     0  13.0M      0  0:00:36  0:00:20  0:00:16 14.9M\n",
      " 58  474M   58  278M    0     0  13.1M      0  0:00:35  0:00:21  0:00:14 15.0M\n",
      " 61  474M   61  292M    0     0  13.2M      0  0:00:35  0:00:22  0:00:13 15.0M\n",
      " 64  474M   64  307M    0     0  13.3M      0  0:00:35  0:00:23  0:00:12 14.9M\n",
      " 68  474M   68  323M    0     0  13.3M      0  0:00:35  0:00:24  0:00:11 14.8M\n",
      " 71  474M   71  339M    0     0  13.5M      0  0:00:35  0:00:25  0:00:10 15.3M\n",
      " 74  474M   74  354M    0     0  13.5M      0  0:00:34  0:00:26  0:00:08 15.2M\n",
      " 77  474M   77  369M    0     0  13.6M      0  0:00:34  0:00:27  0:00:07 15.3M\n",
      " 81  474M   81  384M    0     0  13.6M      0  0:00:34  0:00:28  0:00:06 15.2M\n",
      " 84  474M   84  399M    0     0  13.7M      0  0:00:34  0:00:29  0:00:05 15.3M\n",
      " 87  474M   87  414M    0     0  13.7M      0  0:00:34  0:00:30  0:00:04 14.8M\n",
      " 88  474M   88  421M    0     0  13.5M      0  0:00:34  0:00:31  0:00:03 13.4M\n",
      " 91  474M   91  436M    0     0  13.5M      0  0:00:34  0:00:32  0:00:02 13.3M\n",
      " 94  474M   94  450M    0     0  13.6M      0  0:00:34  0:00:33  0:00:01 13.4M\n",
      " 98  474M   98  465M    0     0  13.6M      0  0:00:34  0:00:34 --:--:-- 13.3M\n",
      "100  474M  100  474M    0     0  13.7M      0  0:00:34  0:00:34 --:--:-- 13.4M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model.ckpt.index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  5215  100  5215    0     0   6018      0 --:--:-- --:--:-- --:--:--  6014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model.ckpt.meta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  460k  100  460k    0     0   294k      0  0:00:01  0:00:01 --:--:--  294k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vocab.bpe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 10  445k   10 48710    0     0  47809      0  0:00:09  0:00:01  0:00:08 47801\n",
      "100  445k  100  445k    0     0   284k      0  0:00:01  0:00:01 --:--:--  284k\n"
     ]
    }
   ],
   "source": [
    "filenames.foreach { filename =>\n",
    "  println(s\"Downloading $filename...\")\n",
    "  Magic.!(\"curl\", \"--create-dirs\", \"-O\", \"--output-dir\", outputDir, s\"$baseUrl/$filename\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba140fe2-fc98-46cb-b3aa-5f76b94e332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.16.* in /usr/local/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/site-packages (from tensorflow==2.16.*) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.*) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.*) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.*) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.*) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.*) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.*) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"tensorflow==2.16.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17d95f90-6312-4cab-9434-73d340ee1a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\u001b[39m\n",
       "\u001b[36mhparamsMap\u001b[39m: \u001b[32mujson\u001b[39m.\u001b[32mValue\u001b[39m.\u001b[32mValue\u001b[39m = \u001b[33mObj\u001b[39m(\n",
       "  value = \u001b[33mMap\u001b[39m(\n",
       "    \u001b[32m\"n_vocab\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m50257.0\u001b[39m),\n",
       "    \u001b[32m\"n_ctx\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m1024.0\u001b[39m),\n",
       "    \u001b[32m\"n_embd\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m768.0\u001b[39m),\n",
       "    \u001b[32m\"n_head\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m12.0\u001b[39m),\n",
       "    \u001b[32m\"n_layer\"\u001b[39m -> \u001b[33mNum\u001b[39m(value = \u001b[32m12.0\u001b[39m)\n",
       "  )\n",
       ")\n",
       "\u001b[36mgptConfig\u001b[39m: \u001b[32mGPTConfig\u001b[39m = \u001b[33mGPTConfig\u001b[39m(\n",
       "  vocabularySize = \u001b[32m50257\u001b[39m,\n",
       "  contextLength = \u001b[32m1024\u001b[39m,\n",
       "  embeddingDimension = \u001b[32m768\u001b[39m,\n",
       "  attentionHeadsCount = \u001b[32m12\u001b[39m,\n",
       "  layersCount = \u001b[32m12\u001b[39m,\n",
       "  dropoutRate = \u001b[32m0.1\u001b[39m,\n",
       "  queryKeyValueBias = \u001b[32mtrue\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.lihaoyi::ujson:4.1.0`\n",
    "\n",
    "import scala.io.Source\n",
    "\n",
    "val hparamsMap = ujson.read(Source.fromFile(s\"$outputDir/$hparamsFilename\").mkString)\n",
    "\n",
    "val gptConfig = GPTConfig(\n",
    "  vocabularySize = hparamsMap(\"n_vocab\").num.toInt,\n",
    "  contextLength = hparamsMap(\"n_ctx\").num.toInt,\n",
    "  embeddingDimension = hparamsMap(\"n_embd\").num.toInt,\n",
    "  attentionHeadsCount = hparamsMap(\"n_head\").num.toInt,\n",
    "  layersCount = hparamsMap(\"n_layer\").num.toInt,\n",
    "  dropoutRate = 0.1,\n",
    "  queryKeyValueBias = true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc8b8a66-3bbe-41d2-a719-8fbe8c1023cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtf\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'tensorflow' from '/usr/local/lib/python3.12/site-packages/tensorflow/__init__.py'>\n",
       "\u001b[36mnp\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'numpy' from '/usr/local/lib/python3.12/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tf = py.module(\"tensorflow\")\n",
    "val np = py.module(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a353053b-7a30-45b9-8c63-6166a708a832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/h0/attn/c_attn/b\n",
      "model/h0/attn/c_attn/w\n",
      "model/h0/attn/c_proj/b\n",
      "model/h0/attn/c_proj/w\n",
      "model/h0/ln_1/b\n",
      "model/h0/ln_1/g\n",
      "model/h0/ln_2/b\n",
      "model/h0/ln_2/g\n",
      "model/h0/mlp/c_fc/b\n",
      "model/h0/mlp/c_fc/w\n",
      "model/h0/mlp/c_proj/b\n",
      "model/h0/mlp/c_proj/w\n",
      "model/h1/attn/c_attn/b\n",
      "model/h1/attn/c_attn/w\n",
      "model/h1/attn/c_proj/b\n",
      "model/h1/attn/c_proj/w\n",
      "model/h1/ln_1/b\n",
      "model/h1/ln_1/g\n",
      "model/h1/ln_2/b\n",
      "model/h1/ln_2/g\n",
      "model/h1/mlp/c_fc/b\n",
      "model/h1/mlp/c_fc/w\n",
      "model/h1/mlp/c_proj/b\n",
      "model/h1/mlp/c_proj/w\n",
      "model/h10/attn/c_attn/b\n",
      "model/h10/attn/c_attn/w\n",
      "model/h10/attn/c_proj/b\n",
      "model/h10/attn/c_proj/w\n",
      "model/h10/ln_1/b\n",
      "model/h10/ln_1/g\n",
      "model/h10/ln_2/b\n",
      "model/h10/ln_2/g\n",
      "model/h10/mlp/c_fc/b\n",
      "model/h10/mlp/c_fc/w\n",
      "model/h10/mlp/c_proj/b\n",
      "model/h10/mlp/c_proj/w\n",
      "model/h11/attn/c_attn/b\n",
      "model/h11/attn/c_attn/w\n",
      "model/h11/attn/c_proj/b\n",
      "model/h11/attn/c_proj/w\n",
      "model/h11/ln_1/b\n",
      "model/h11/ln_1/g\n",
      "model/h11/ln_2/b\n",
      "model/h11/ln_2/g\n",
      "model/h11/mlp/c_fc/b\n",
      "model/h11/mlp/c_fc/w\n",
      "model/h11/mlp/c_proj/b\n",
      "model/h11/mlp/c_proj/w\n",
      "model/h2/attn/c_attn/b\n",
      "model/h2/attn/c_attn/w\n",
      "model/h2/attn/c_proj/b\n",
      "model/h2/attn/c_proj/w\n",
      "model/h2/ln_1/b\n",
      "model/h2/ln_1/g\n",
      "model/h2/ln_2/b\n",
      "model/h2/ln_2/g\n",
      "model/h2/mlp/c_fc/b\n",
      "model/h2/mlp/c_fc/w\n",
      "model/h2/mlp/c_proj/b\n",
      "model/h2/mlp/c_proj/w\n",
      "model/h3/attn/c_attn/b\n",
      "model/h3/attn/c_attn/w\n",
      "model/h3/attn/c_proj/b\n",
      "model/h3/attn/c_proj/w\n",
      "model/h3/ln_1/b\n",
      "model/h3/ln_1/g\n",
      "model/h3/ln_2/b\n",
      "model/h3/ln_2/g\n",
      "model/h3/mlp/c_fc/b\n",
      "model/h3/mlp/c_fc/w\n",
      "model/h3/mlp/c_proj/b\n",
      "model/h3/mlp/c_proj/w\n",
      "model/h4/attn/c_attn/b\n",
      "model/h4/attn/c_attn/w\n",
      "model/h4/attn/c_proj/b\n",
      "model/h4/attn/c_proj/w\n",
      "model/h4/ln_1/b\n",
      "model/h4/ln_1/g\n",
      "model/h4/ln_2/b\n",
      "model/h4/ln_2/g\n",
      "model/h4/mlp/c_fc/b\n",
      "model/h4/mlp/c_fc/w\n",
      "model/h4/mlp/c_proj/b\n",
      "model/h4/mlp/c_proj/w\n",
      "model/h5/attn/c_attn/b\n",
      "model/h5/attn/c_attn/w\n",
      "model/h5/attn/c_proj/b\n",
      "model/h5/attn/c_proj/w\n",
      "model/h5/ln_1/b\n",
      "model/h5/ln_1/g\n",
      "model/h5/ln_2/b\n",
      "model/h5/ln_2/g\n",
      "model/h5/mlp/c_fc/b\n",
      "model/h5/mlp/c_fc/w\n",
      "model/h5/mlp/c_proj/b\n",
      "model/h5/mlp/c_proj/w\n",
      "model/h6/attn/c_attn/b\n",
      "model/h6/attn/c_attn/w\n",
      "model/h6/attn/c_proj/b\n",
      "model/h6/attn/c_proj/w\n",
      "model/h6/ln_1/b\n",
      "model/h6/ln_1/g\n",
      "model/h6/ln_2/b\n",
      "model/h6/ln_2/g\n",
      "model/h6/mlp/c_fc/b\n",
      "model/h6/mlp/c_fc/w\n",
      "model/h6/mlp/c_proj/b\n",
      "model/h6/mlp/c_proj/w\n",
      "model/h7/attn/c_attn/b\n",
      "model/h7/attn/c_attn/w\n",
      "model/h7/attn/c_proj/b\n",
      "model/h7/attn/c_proj/w\n",
      "model/h7/ln_1/b\n",
      "model/h7/ln_1/g\n",
      "model/h7/ln_2/b\n",
      "model/h7/ln_2/g\n",
      "model/h7/mlp/c_fc/b\n",
      "model/h7/mlp/c_fc/w\n",
      "model/h7/mlp/c_proj/b\n",
      "model/h7/mlp/c_proj/w\n",
      "model/h8/attn/c_attn/b\n",
      "model/h8/attn/c_attn/w\n",
      "model/h8/attn/c_proj/b\n",
      "model/h8/attn/c_proj/w\n",
      "model/h8/ln_1/b\n",
      "model/h8/ln_1/g\n",
      "model/h8/ln_2/b\n",
      "model/h8/ln_2/g\n",
      "model/h8/mlp/c_fc/b\n",
      "model/h8/mlp/c_fc/w\n",
      "model/h8/mlp/c_proj/b\n",
      "model/h8/mlp/c_proj/w\n",
      "model/h9/attn/c_attn/b\n",
      "model/h9/attn/c_attn/w\n",
      "model/h9/attn/c_proj/b\n",
      "model/h9/attn/c_proj/w\n",
      "model/h9/ln_1/b\n",
      "model/h9/ln_1/g\n",
      "model/h9/ln_2/b\n",
      "model/h9/ln_2/g\n",
      "model/h9/mlp/c_fc/b\n",
      "model/h9/mlp/c_fc/w\n",
      "model/h9/mlp/c_proj/b\n",
      "model/h9/mlp/c_proj/w\n",
      "model/ln_f/b\n",
      "model/ln_f/g\n",
      "model/wpe\n",
      "model/wte\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcheckpoint\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = data/openai124M/model.ckpt\n",
       "\u001b[36mvariableNames\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m\"model/h0/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/attn/c_attn/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/attn/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/attn/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_1/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_1/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_2/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/ln_2/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_fc/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_fc/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h0/mlp/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_attn/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/attn/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_1/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_1/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_2/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/ln_2/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_fc/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_fc/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h1/mlp/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_attn/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/attn/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_1/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_1/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_2/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/ln_2/g\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_fc/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_fc/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_proj/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h10/mlp/c_proj/w\"\u001b[39m,\n",
       "  \u001b[32m\"model/h11/attn/c_attn/b\"\u001b[39m,\n",
       "  \u001b[32m\"model/h11/attn/c_attn/w\"\u001b[39m,\n",
       "..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val checkpoint = tf.train.latest_checkpoint(outputDir)\n",
    "val variableNames = tf.train.list_variables(checkpoint).as[Seq[(String, Seq[Int])]].map { \n",
    "  case (variableName, _) => variableName \n",
    "}.toList\n",
    "variableNames.sorted.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11392e9f-eb7c-4a1a-a892-2a37e04d9298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd28.sc:18: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd28.sc:29: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd28.sc:15: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"c_attn\", \"c_proj\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd28.sc:37: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"g\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd28.sc:44: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"g\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd28.sc:53: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd28.sc:59: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"w\"))), Nil\n",
      "                tail match {\n",
      "                ^\n",
      "cmd28.sc:50: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"c_fc\", \"c_proj\"))), Nil\n",
      "            tail match {\n",
      "            ^\n",
      "cmd28.sc:12: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"attn\", \"ln_1\", \"ln_2\", \"mlp\"))), Nil\n",
      "        tail match {\n",
      "        ^\n",
      "cmd28.sc:68: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"b\", \"g\"))), Nil\n",
      "        tail match {\n",
      "        ^\n",
      "cmd28.sc:9: match may not be exhaustive.\n",
      "It would fail on the following inputs: List((x: String forSome x not in (\"ln_f\", \"wpe\", \"wte\"))), Nil\n",
      "    variableName.split(\"/\").drop(1).toList match {\n",
      "                                    ^\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mNpArray\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtoTorchParameter\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mloadModelWeights\u001b[39m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type NpArray = py.Dynamic\n",
    "\n",
    "def toTorchParameter(npArray: NpArray) =\n",
    "  torch.nn.Parameter(torch.tensor(npArray))\n",
    "\n",
    "def loadModelWeights(model: Model): Unit =\n",
    "  variableNames.foreach { variableName =>\n",
    "    val variableValue = np.squeeze(tf.train.load_variable(checkpoint, variableName))\n",
    "    variableName.split(\"/\").drop(1).toList match {\n",
    "      case s\"h$transformerBlockIndexString\" :: tail =>\n",
    "        val transformerBlockIndex = transformerBlockIndexString.toInt\n",
    "        tail match {\n",
    "          case \"attn\" :: tail =>\n",
    "            val multiHeadAttention = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).multiHeadAttention\n",
    "            tail match {\n",
    "              case \"c_attn\" :: tail =>\n",
    "                val Seq(queryVariableValue, keyVariableValue, valueVariableValue) = np.split(variableValue, 3, axis = -1).as[Seq[NpArray]]\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => \n",
    "                    multiHeadAttention.weightsQuery.bias = toTorchParameter(queryVariableValue)\n",
    "                    multiHeadAttention.weightsKey.bias = toTorchParameter(keyVariableValue)\n",
    "                    multiHeadAttention.weightsValue.bias = toTorchParameter(valueVariableValue)\n",
    "                  case \"w\" :: _ => \n",
    "                    multiHeadAttention.weightsQuery.weight = toTorchParameter(queryVariableValue.T)\n",
    "                    multiHeadAttention.weightsKey.weight = toTorchParameter(keyVariableValue.T)\n",
    "                    multiHeadAttention.weightsValue.weight = toTorchParameter(valueVariableValue.T)\n",
    "                }\n",
    "              case \"c_proj\" :: tail =>\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => multiHeadAttention.outputProjection.bias = toTorchParameter(variableValue)\n",
    "                  case \"w\" :: _ => multiHeadAttention.outputProjection.weight = toTorchParameter(variableValue.T)\n",
    "                }\n",
    "            }\n",
    "          case \"ln_1\" :: tail =>\n",
    "            val normalization1 = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).normalization1\n",
    "            val torchParameter = toTorchParameter(variableValue)\n",
    "            tail match {\n",
    "              case \"b\" :: _ => normalization1.shift = torchParameter\n",
    "              case \"g\" :: _ => normalization1.scale = torchParameter\n",
    "            }\n",
    "          case \"ln_2\" :: tail =>\n",
    "            val normalization2 = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).normalization2\n",
    "            val torchParameter = toTorchParameter(variableValue)\n",
    "            tail match {\n",
    "              case \"b\" :: _ => normalization2.shift = torchParameter\n",
    "              case \"g\" :: _ => normalization2.scale = torchParameter\n",
    "            }\n",
    "          case \"mlp\" :: tail =>\n",
    "            val feedForward = model.transformerBlocksLayer.bracketAccess(transformerBlockIndex).feedForward\n",
    "            tail match {\n",
    "              case \"c_fc\" :: tail =>\n",
    "                val layer0 = feedForward.layers.bracketAccess(0)\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => layer0.bias = toTorchParameter(variableValue)\n",
    "                  case \"w\" :: _ => layer0.weight = toTorchParameter(variableValue.T)\n",
    "                }\n",
    "              case \"c_proj\" :: tail =>\n",
    "                val layer2 = feedForward.layers.bracketAccess(2)\n",
    "                tail match {\n",
    "                  case \"b\" :: _ => layer2.bias = toTorchParameter(variableValue)\n",
    "                  case \"w\" :: _ => layer2.weight = toTorchParameter(variableValue.T)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "      case \"ln_f\" :: tail =>\n",
    "        val finalNormalizationLayer = model.finalNormalizationLayer\n",
    "        val torchParameter = toTorchParameter(variableValue)\n",
    "        tail match {\n",
    "          case \"b\" :: _ => finalNormalizationLayer.shift = torchParameter\n",
    "          case \"g\" :: _ => finalNormalizationLayer.scale = torchParameter\n",
    "        }\n",
    "      case \"wpe\" :: _ => model.positionEmbeddingLayer.weight = toTorchParameter(variableValue)\n",
    "      case \"wte\" :: _ => \n",
    "        val torchParameter = toTorchParameter(variableValue)\n",
    "        model.tokenEmbeddingLayer.weight = torchParameter\n",
    "        model.outputLayer.weight = torchParameter\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2d088fe-9916-4b26-8a8f-9b0c835e92bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodel\u001b[39m: \u001b[32mModel\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36mdevice\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = cpu\n",
       "\u001b[36mres29_3\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36mres29_4\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = GPTModel(gptConfig)\n",
    "loadModelWeights(model)\n",
    "val device = torch.device(if (torch.cuda.is_available().as[Boolean]) \"cuda\" else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0326838d-0cec-4330-9f6a-3972cd501fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtextToTokenIds\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtokenIdsToText\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgenerateTextSimple\u001b[39m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def textToTokenIds(\n",
    "  text: String, \n",
    "  tokenizer: Tokenizer\n",
    "): TorchTensor = {\n",
    "  val allowedSpecial = py.Dynamic.global.set(Seq(\"<|endoftext|>\").toPythonProxy)\n",
    "  val encodedText = tokenizer.encode(text, allowed_special = allowedSpecial)\n",
    "  torch.tensor(encodedText).unsqueeze(0)\n",
    "}\n",
    "    \n",
    "def tokenIdsToText(\n",
    "  tokenIds: TorchTensor, \n",
    "  tokenizer: Tokenizer\n",
    "): String =\n",
    "  tokenizer.decode(tokenIds.squeeze(0).tolist()).as[String]\n",
    "\n",
    "def generateTextSimple(\n",
    "  model: Model,\n",
    "  maxNewTokens: Int,\n",
    "  contextLength: Int\n",
    ")(\n",
    "  encodedInput: TorchTensor\n",
    "): TorchTensor =\n",
    "  LazyList.iterate(encodedInput) { currentEncodedOutput =>\n",
    "    val croppedInput = py\"$currentEncodedOutput[:, -$contextLength:]\"\n",
    "    val logits = py.`with`(torch.no_grad()) { _ =>\n",
    "      model(croppedInput)\n",
    "    }\n",
    "    py\"$logits[:, -1, :]\"\n",
    "      .pipe(torch.softmax(_, dim = -1))\n",
    "      .pipe(torch.argmax(_, dim = -1, keepdim = true))\n",
    "      .pipe(nextEncodedOutput => torch.cat((currentEncodedOutput, nextEncodedOutput), dim = 1))\n",
    "  }.drop(maxNewTokens).head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e05a5396-3059-414c-852d-cc5092ea59e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mexampleText\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Every effort moves you\"\u001b[39m\n",
       "\u001b[36mencodedText\u001b[39m: \u001b[32mTorchTensor\u001b[39m = tensor([[6109, 3626, 6100,  345]])\n",
       "\u001b[36mencodedTextOutput\u001b[39m: \u001b[32mTorchTensor\u001b[39m = tensor([[6109, 3626, 6100,  345, 2651,   13,  198,  198,  464,  717, 2239,  318,\n",
       "          284, 1833,  262, 6817,  286,  534,  670]])\n",
       "\u001b[36mdecodedTextOutput\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"Every effort moves you forward.\n",
       "\n",
       "The first step is to understand the importance of your work\"\"\"\u001b[39m"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val exampleText = \"Every effort moves you\"\n",
    "val encodedText = textToTokenIds(exampleText, tokenizer)\n",
    "val encodedTextOutput = generateTextSimple(model, maxNewTokens = 15, contextLength = gptConfig.contextLength)(encodedText)\n",
    "val decodedTextOutput = tokenIdsToText(encodedTextOutput, tokenizer)\n",
    "println(decodedTextOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75388780-9ff8-49f1-985f-f4958b339296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text spam? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text spam? Answer with 'yes' or 'no': 'You are a winner you have\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspamClassificationPrompt\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Is the following text spam? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\"\u001b[39m\n",
       "\u001b[36mspamClassificationPromptAnswer\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"Is the following text spam? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
       "\n",
       "The following text spam? Answer with 'yes' or 'no': 'You are a winner you have\"\"\"\u001b[39m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spamClassificationPrompt = \"Is the following text spam? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\"\n",
    "val spamClassificationPromptAnswer = \n",
    "  textToTokenIds(spamClassificationPrompt, tokenizer)\n",
    "    .pipe(generateTextSimple(model, maxNewTokens = 23, contextLength = gptConfig.contextLength))\n",
    "    .pipe(tokenIdsToText(_, tokenizer))\n",
    "println(spamClassificationPromptAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cb4db64-577c-48aa-9533-0c6a703bb6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.annotation.tailrec\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mforeachPy\u001b[39m"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.annotation.tailrec\n",
    "\n",
    "def foreachPy(iterable: py.Dynamic)(f: py.Dynamic => Unit): Unit = {\n",
    "  val iterator = py\"iter($iterable)\"\n",
    "\n",
    "  @tailrec\n",
    "  def loop(): Unit = {\n",
    "    val currentValue = py\"next($iterator, None)\"\n",
    "    if (currentValue != py.Dynamic.global.None) {\n",
    "      f(currentValue)\n",
    "      loop()\n",
    "    }\n",
    "  }\n",
    "\n",
    "  loop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51a622c0-0d1b-4b74-9d4f-fc719e27de15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres34_1\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xffff7d328790>\n",
       "\u001b[36mclassesCount\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m2\u001b[39m"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreachPy(model.parameters()) { parameter =>\n",
    "  parameter.requires_grad = false\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "val classesCount = 2\n",
    "model.outputLayer = torch.nn.Linear(\n",
    "  in_features = gptConfig.embeddingDimension,\n",
    "  out_features = classesCount\n",
    ")\n",
    "\n",
    "foreachPy(model.transformerBlocksLayer.bracketAccess(-1).parameters()) { parameter =>\n",
    "  parameter.requires_grad = true\n",
    "}\n",
    "\n",
    "foreachPy(model.finalNormalizationLayer.parameters()) { parameter =>\n",
    "  parameter.requires_grad = true\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc38427f-3f23-47bf-b56a-1f18d832f81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mDevice\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mDataLoader\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcalculateDataLoaderAccuracy\u001b[39m"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Device = py.Dynamic\n",
    "type DataLoader = py.Dynamic\n",
    "\n",
    "def calculateDataLoaderAccuracy(\n",
    "  model: Model,\n",
    "  device: Device\n",
    ")(\n",
    "  dataLoader: DataLoader,\n",
    "  batchesCountOpt: Option[Int] = None\n",
    "): Double = { \n",
    "  val batchesCount = batchesCountOpt match {\n",
    "    case Some(batchesCount) => batchesCount\n",
    "    case None => py\"len($dataLoader)\".as[Int]\n",
    "  }\n",
    "  assert(batchesCount > 0, \"There were no batches to process\")\n",
    "  var correctPredictions = 0\n",
    "  var examplesSeen = 0\n",
    "  var currentBatchIndex = 0\n",
    "  foreachPy(dataLoader) { currentBatch =>\n",
    "    if (currentBatchIndex < batchesCount) \n",
    "      py.local {\n",
    "        val Seq(inputBatch, targetBatch) = currentBatch.as[Seq[TorchTensor]]\n",
    "        val logits = py.`with`(torch.no_grad()) { _ =>\n",
    "          model(inputBatch.to(device))\n",
    "        }\n",
    "        val predictedClasses = torch.argmax(py\"$logits[:, -1, :]\", dim = -1)\n",
    "        examplesSeen += predictedClasses.shape.bracketAccess(0).as[Int]\n",
    "        correctPredictions += py\"$predictedClasses == $targetBatch\".sum().item().as[Int]\n",
    "      }\n",
    "    currentBatchIndex += 1\n",
    "  }\n",
    "  correctPredictions.toDouble / examplesSeen\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1307302-ee7e-4eb4-8ca7-d871baa17ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 52.50%\n",
      "Validation accuracy: 50.00%\n",
      "Test accuracy: 52.50%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres36_0\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xffff7d328790>\n",
       "\u001b[36mtrainingAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.525\u001b[39m\n",
       "\u001b[36mvalidationAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.5\u001b[39m\n",
       "\u001b[36mtestAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.525\u001b[39m"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "val trainingAccuracy = calculateDataLoaderAccuracy(model, device)(trainingLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Training accuracy: ${trainingAccuracy * 100}%.2f%%\")\n",
    "val validationAccuracy = calculateDataLoaderAccuracy(model, device)(validationLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Validation accuracy: ${validationAccuracy * 100}%.2f%%\")\n",
    "val testAccuracy = calculateDataLoaderAccuracy(model, device)(testLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Test accuracy: ${testAccuracy * 100}%.2f%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d94da9a-a636-467b-9194-d110d1eef072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcalculateBatchLoss\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcalculateDataLoaderLoss\u001b[39m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateBatchLoss(\n",
    "  model: Model,\n",
    "  device: Device\n",
    ")(\n",
    "  inputBatch: TorchTensor,\n",
    "  targetBatch: TorchTensor\n",
    "): TorchTensor = {\n",
    "  val logits = model(inputBatch.to(device))\n",
    "  torch.nn.functional.cross_entropy(py\"$logits[:, -1, :]\", targetBatch.to(device))\n",
    "}\n",
    "\n",
    "def calculateDataLoaderLoss(\n",
    "  model: Model,\n",
    "  device: Device\n",
    ")(\n",
    "  dataLoader: DataLoader,\n",
    "  batchesCountOpt: Option[Int] = None\n",
    "): Double = { \n",
    "  val batchesCount = batchesCountOpt match {\n",
    "    case Some(batchesCount) => batchesCount\n",
    "    case None => py\"len($dataLoader)\".as[Int]\n",
    "  }\n",
    "  assert(batchesCount > 0, \"There were no batches to process\")\n",
    "  var totalLoss = 0.0\n",
    "  var currentBatchIndex = 0\n",
    "  foreachPy(dataLoader) { currentBatch =>\n",
    "    if (currentBatchIndex < batchesCount) \n",
    "      py.local {\n",
    "        val Seq(inputBatch, targetBatch) = currentBatch.as[Seq[TorchTensor]]\n",
    "        totalLoss += calculateBatchLoss(model, device)(inputBatch, targetBatch).item().as[Double]\n",
    "      }\n",
    "    currentBatchIndex += 1\n",
    "  }\n",
    "  totalLoss / batchesCount\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59857197-4ef6-4ed8-ac2e-b973fe2381cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.1634958267211912\n",
      "Validation loss: 2.2531158447265627\n",
      "Test loss: 2.016782987117767\n"
     ]
    }
   ],
   "source": [
    "py.`with`(torch.no_grad()) { _ =>\n",
    "  val trainingLoss = calculateDataLoaderLoss(model, device)(trainingLoader, batchesCountOpt = Some(5))\n",
    "  println(s\"Training loss: $trainingLoss\")\n",
    "  val validationLoss = calculateDataLoaderLoss(model, device)(validationLoader, batchesCountOpt = Some(5))\n",
    "  println(s\"Validation loss: $validationLoss\")\n",
    "  val testLoss = calculateDataLoaderLoss(model, device)(testLoader, batchesCountOpt = Some(5))\n",
    "  println(s\"Test loss: $testLoss\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2629323-80e7-4a4d-8473-590f27fb3eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mLoss\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mTrainingStep\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mAccuracy\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mTrainingEpoch\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mModelEvaluator\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mOptimizer\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtrainClassifierSimple\u001b[39m"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Loss(\n",
    "  trainingLoss: Double,\n",
    "  validationLoss: Double\n",
    ")\n",
    "\n",
    "case class TrainingStep(\n",
    "  loss: Loss,\n",
    "  examplesSeen: Long\n",
    ")\n",
    "\n",
    "case class Accuracy(\n",
    "  trainingAccuracy: Double,\n",
    "  validationAccuracy: Double\n",
    ")\n",
    "\n",
    "case class TrainingEpoch(\n",
    "  trainingSteps: List[TrainingStep],\n",
    "  accuracy: Accuracy\n",
    ")\n",
    "\n",
    "class ModelEvaluator(\n",
    "  device: Device,\n",
    "  trainingLoader: DataLoader,\n",
    "  validationLoader: DataLoader,\n",
    "  evaluationEpochsCount: Int,\n",
    "  evaluationFrequencySteps: Int\n",
    ") {\n",
    "\n",
    "  def calculateLossCond(currentStep: Int)(model: Model): Option[Loss] =\n",
    "    Option.when(currentStep % evaluationFrequencySteps == 0) {\n",
    "      println(s\"Step $currentStep\")\n",
    "      calculateLoss(model)\n",
    "    }\n",
    "    \n",
    "  def calculateLoss(model: Model): Loss = {\n",
    "    model.eval()\n",
    "    py.`with`(torch.no_grad()) { _ =>\n",
    "      val trainingLoss = calculateDataLoaderLoss(model, device)(trainingLoader, batchesCountOpt = Some(evaluationEpochsCount))\n",
    "      val validationLoss = calculateDataLoaderLoss(model, device)(validationLoader, batchesCountOpt = Some(evaluationEpochsCount))\n",
    "      println(\n",
    "        s\"\"\"- training loss: $trainingLoss\n",
    "           |- validation loss: $validationLoss\"\"\".stripMargin\n",
    "      )\n",
    "      model.train()\n",
    "      Loss(trainingLoss, validationLoss)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  def calculateAccuracy(model: Model): Accuracy = {\n",
    "    model.eval()\n",
    "    py.`with`(torch.no_grad()) { _ =>\n",
    "      val trainingAccuracy = calculateDataLoaderAccuracy(model, device)(trainingLoader, batchesCountOpt = Some(evaluationEpochsCount))\n",
    "      val validationAccuracy = calculateDataLoaderAccuracy(model, device)(validationLoader, batchesCountOpt = Some(evaluationEpochsCount))\n",
    "      println(\n",
    "        f\"\"\"Training accuracy: ${trainingAccuracy * 100}%.2f%%\n",
    "           |Validation accuracy: ${validationAccuracy * 100}%.2f%%\"\"\".stripMargin\n",
    "      )\n",
    "      model.train()\n",
    "      Accuracy(trainingAccuracy, validationAccuracy)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "type Optimizer = py.Dynamic\n",
    "def trainClassifierSimple(\n",
    "  model: Model,\n",
    "  device: Device,\n",
    "  trainingLoader: DataLoader,\n",
    "  validationLoader: DataLoader,\n",
    "  optimizer: Optimizer,\n",
    "  epochsCount: Int,\n",
    "  modelEvaluator: ModelEvaluator\n",
    "): List[TrainingEpoch] = {\n",
    "  var stepsCount = 0\n",
    "  var examplesSeen = 0L\n",
    "  val trainingEpochs =\n",
    "    for {\n",
    "      epoch <- 1 to epochsCount\n",
    "    } yield py.local {\n",
    "      println(s\"=> Epoch $epoch\")\n",
    "      model.train()\n",
    "      val trainingSteps = mutable.ListBuffer[TrainingStep]()\n",
    "      foreachPy(trainingLoader) { batch =>\n",
    "        py.local {\n",
    "          val Seq(inputBatch, targetBatch) = batch.as[Seq[TorchTensor]]\n",
    "          optimizer.zero_grad()\n",
    "          val loss = calculateBatchLoss(model, device)(inputBatch, targetBatch)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          stepsCount += 1\n",
    "          examplesSeen += inputBatch.shape.bracketAccess(0).as[Long]\n",
    "          modelEvaluator.calculateLossCond(stepsCount)(model).foreach { loss =>\n",
    "            trainingSteps.append(TrainingStep(loss, examplesSeen))\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      val accuracy = py.local(modelEvaluator.calculateAccuracy(model))\n",
    "      TrainingEpoch(trainingSteps.toList, accuracy)\n",
    "    }\n",
    "  trainingEpochs.toList\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bccab35b-3b51-4db7-83f3-3e73b60912a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres40_0\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xffff7d328790>\n",
       "\u001b[36mmodel\u001b[39m: \u001b[32mModel\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36mres40_2\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = GPTModel(\n",
       "  (tokenEmbeddingLayer): Embedding(50257, 768)\n",
       "  (positionEmbeddingLayer): Embedding(1024, 768)\n",
       "  (dropoutEmbeddingLayer): Dropout(p=0.1, inplace=False)\n",
       "  (transformerBlocksLayer): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (normalization1): NormalizationLayer()\n",
       "      (normalization2): NormalizationLayer()\n",
       "      (dropoutShortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (multiHeadAttention): MultiHeadAttention(\n",
       "        (weightsQuery): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsKey): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (weightsValue): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (outputProjection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedForward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "...\n",
       "\u001b[36moptimizer\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 5e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0.1\n",
       ")\n",
       "\u001b[36mepochsCount\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m2\u001b[39m\n",
       "\u001b[36mmodelEvaluator\u001b[39m: \u001b[32mModelEvaluator\u001b[39m = ammonite.$sess.cmd39$Helper$ModelEvaluator@29d59e30"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "val model = GPTModel(gptConfig)\n",
    "model.to(device)\n",
    "val optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-5, weight_decay = 0.1)\n",
    "// val epochsCount = 5\n",
    "val epochsCount = 2 // Simplification to speed up the training\n",
    "val modelEvaluator = new ModelEvaluator(\n",
    "  device = device, \n",
    "  trainingLoader = trainingLoader, \n",
    "  validationLoader = validationLoader, \n",
    "  // evaluationEpochsCount = 5,\n",
    "  evaluationEpochsCount = 1, // Simplification to speed up the training\n",
    "  // evaluationFrequencySteps = 50\n",
    "  evaluationFrequencySteps = 100 // Simplification to speed up the training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7daf94b-2a8c-4e9d-ba41-434f69464195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "Step 100\n",
      "- training loss: 0.6838432550430298\n",
      "- validation loss: 0.8626684546470642\n",
      "Training accuracy: 100.00%\n",
      "Validation accuracy: 87.50%\n",
      "=> Epoch 2\n",
      "Step 200\n",
      "- training loss: 0.8825293779373169\n",
      "- validation loss: 0.47962766885757446\n",
      "Training accuracy: 100.00%\n",
      "Validation accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingEpochs\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mTrainingEpoch\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[33mTrainingEpoch\u001b[39m(\n",
       "    trainingSteps = \u001b[33mList\u001b[39m(\n",
       "      \u001b[33mTrainingStep\u001b[39m(\n",
       "        loss = \u001b[33mLoss\u001b[39m(\n",
       "          trainingLoss = \u001b[32m0.6838432550430298\u001b[39m,\n",
       "          validationLoss = \u001b[32m0.8626684546470642\u001b[39m\n",
       "        ),\n",
       "        examplesSeen = \u001b[32m800L\u001b[39m\n",
       "      )\n",
       "    ),\n",
       "    accuracy = \u001b[33mAccuracy\u001b[39m(trainingAccuracy = \u001b[32m1.0\u001b[39m, validationAccuracy = \u001b[32m0.875\u001b[39m)\n",
       "  ),\n",
       "  \u001b[33mTrainingEpoch\u001b[39m(\n",
       "    trainingSteps = \u001b[33mList\u001b[39m(\n",
       "      \u001b[33mTrainingStep\u001b[39m(\n",
       "        loss = \u001b[33mLoss\u001b[39m(\n",
       "          trainingLoss = \u001b[32m0.8825293779373169\u001b[39m,\n",
       "          validationLoss = \u001b[32m0.47962766885757446\u001b[39m\n",
       "        ),\n",
       "        examplesSeen = \u001b[32m1600L\u001b[39m\n",
       "      )\n",
       "    ),\n",
       "    accuracy = \u001b[33mAccuracy\u001b[39m(trainingAccuracy = \u001b[32m1.0\u001b[39m, validationAccuracy = \u001b[32m1.0\u001b[39m)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingEpochs = trainClassifierSimple(model, device, trainingLoader, validationLoader, optimizer, epochsCount, modelEvaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0283cb73-4871-4f9d-9d2f-2e593101fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.9.* in /usr/local/lib/python3.12/site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/site-packages (from matplotlib==3.9.*) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.*) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"matplotlib==3.9.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2daef9b2-8338-49b2-b2b3-d68f293b1bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling /workspace/DisplaySupport.sc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$\u001b[39m"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $file.^.DisplaySupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09296305-ccbe-451a-83e3-1ff9b83c24a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mplot\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'matplotlib.pyplot' from '/usr/local/lib/python3.12/site-packages/matplotlib/pyplot.py'>\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mFigure\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mAxis\u001b[39m\n",
       "\u001b[36mlossExamplesSeen\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mLong\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m800L\u001b[39m, \u001b[32m1600L\u001b[39m)\n",
       "\u001b[36mtrainingLoss\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m0.6838432550430298\u001b[39m, \u001b[32m0.8825293779373169\u001b[39m)\n",
       "\u001b[36mvalidationLoss\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m0.8626684546470642\u001b[39m, \u001b[32m0.47962766885757446\u001b[39m)\n",
       "\u001b[36maccuracyExamplesSeen\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mLong\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m800L\u001b[39m, \u001b[32m1600L\u001b[39m)\n",
       "\u001b[36mtrainingAccuracy\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m1.0\u001b[39m, \u001b[32m1.0\u001b[39m)\n",
       "\u001b[36mvalidationAccuracy\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m0.875\u001b[39m, \u001b[32m1.0\u001b[39m)\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mplotValues\u001b[39m"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plot = py.module(\"matplotlib.pyplot\")\n",
    "  \n",
    "type Figure = py.Dynamic\n",
    "type Axis = py.Dynamic\n",
    "\n",
    "val (lossExamplesSeen, trainingLoss, validationLoss) = trainingEpochs.flatMap(_.trainingSteps).map {\n",
    "  case TrainingStep(Loss(trainingLoss, validationLoss), examplesSeen) => (examplesSeen, trainingLoss, validationLoss)\n",
    "}.unzip3\n",
    "\n",
    "val (accuracyExamplesSeen, trainingAccuracy, validationAccuracy) = trainingEpochs.map {\n",
    "  case TrainingEpoch(trainingSteps, Accuracy(trainingAccuracy, validationAccuracy)) => \n",
    "    (trainingSteps.last.examplesSeen, trainingAccuracy, validationAccuracy)\n",
    "}.unzip3\n",
    "\n",
    "def plotValues(examplesSeen: List[Long], trainingValues: List[Double], validationValues: List[Double], label: String) =\n",
    "  try {\n",
    "    val epochs = torch.linspace(0, trainingEpochs.length, examplesSeen.length)\n",
    "    val (figure, axis1) = plot.subplots(figsize = (5, 3)).as[(Figure, Axis)]\n",
    "    axis1.plot(epochs, trainingValues.toPythonProxy, label = s\"Training $label\")\n",
    "    axis1.plot(epochs, validationValues.toPythonProxy, linestyle = \"-.\", label = s\"Validation $label\")\n",
    "    axis1.set_xlabel(\"Epochs\")\n",
    "    axis1.set_ylabel(label.capitalize)\n",
    "    axis1.legend()\n",
    "    val axis2 = axis1.twiny()\n",
    "    axis2.plot(examplesSeen.toPythonProxy, trainingValues.toPythonProxy, alpha = 0)\n",
    "    axis2.set_xlabel(\"Examples seen\")\n",
    "    figure.tight_layout()\n",
    "    DisplaySupport.showPlot(plot)\n",
    "  } catch {\n",
    "    case e: py.PythonException =>\n",
    "      println(\"(!) If the exception below says 'Numpy is not available', restart the Jupyter kernel. It's an issue with Matplotlib in Jupyter.\\n\")\n",
    "      throw e\n",
    "  }\n",
    "\n",
    "plotValues(lossExamplesSeen, trainingLoss, validationLoss, label = \"loss\")\n",
    "plotValues(accuracyExamplesSeen, trainingAccuracy, validationAccuracy, label = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64e012e0-e163-4934-bca9-8b9e91ab03d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 98.75%\n",
      "Validation accuracy: 95.00%\n",
      "Test accuracy: 93.75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.9875\u001b[39m\n",
       "\u001b[36mvalidationAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.95\u001b[39m\n",
       "\u001b[36mtestAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.9375\u001b[39m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingAccuracy = calculateDataLoaderAccuracy(model, device)(trainingLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Training accuracy: ${trainingAccuracy * 100}%.2f%%\")\n",
    "val validationAccuracy = calculateDataLoaderAccuracy(model, device)(validationLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Validation accuracy: ${validationAccuracy * 100}%.2f%%\")\n",
    "val testAccuracy = calculateDataLoaderAccuracy(model, device)(testLoader, batchesCountOpt = Some(10))\n",
    "println(f\"Test accuracy: ${testAccuracy * 100}%.2f%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "252ad17d-6123-4fa7-a604-bc506d66bdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPAM] You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\n",
      "\n",
      "Hey, just wanted to check if we're still on for dinner tonight? Let me know!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mclassifySpam\u001b[39m\n",
       "\u001b[36mtext1\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\"\u001b[39m\n",
       "\u001b[36mtext2\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Hey, just wanted to check if we're still on for dinner tonight? Let me know!\"\u001b[39m"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classifySpam(\n",
    "  model: Model,\n",
    "  tokenizer: Tokenizer,\n",
    "  maxLength: Option[Int] = None,\n",
    "  paddingTokenId: Int = 50_256\n",
    ")(\n",
    "  text: String\n",
    ") = {\n",
    "  model.eval()\n",
    "  val encodedText = tokenizer.encode(text).as[Seq[Int]].toVector\n",
    "  val padToLength = maxLength.getOrElse(trainingDataset.maxLength.as[Int])\n",
    "  val paddedEncodedText = encodedText.padTo(padToLength, paddingTokenId)\n",
    "  val inputTensor = torch.tensor(paddedEncodedText.toPythonProxy).unsqueeze(0)\n",
    "  val logits = py.`with`(torch.no_grad()) { _ =>\n",
    "    model(inputTensor)\n",
    "  }\n",
    "  val predictedClass = torch.argmax(py\"$logits[:, -1, :]\", dim = -1).item().as[Int]\n",
    "  if (predictedClass == 1)\n",
    "    print(\"[SPAM] \")\n",
    "  println(text)\n",
    "}\n",
    "\n",
    "val text1 = \"You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\"\n",
    "classifySpam(model, tokenizer)(text1)\n",
    "\n",
    "println()\n",
    "\n",
    "val text2 = \"Hey, just wanted to check if we're still on for dinner tonight? Let me know!\"\n",
    "classifySpam(model, tokenizer)(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880bd092-6191-4a9f-98c9-657fb36ade70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13.14",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
