{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43422675-d20a-48f9-b6fd-de7c6ff15e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling /workspace/Magic.sc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $file.^.Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e49e87a-5c99-462f-b5a0-cff300073cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.4.* in /usr/local/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch==2.4.*) (75.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch==2.4.*) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy->torch==2.4.*) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "Magic.!(\"pip\", \"install\", \"torch==2.4.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5b2722-e6a8-4de4-a1cc-7babf95c0cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`dev.scalapy::scalapy-core:0.5.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020af021-e9d2-4b9d-a0fe-9e5d89e8ecd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mme.shadaj.scalapy.py\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mpy.SeqConverters\u001b[39m\n",
       "\u001b[36mtorch\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mModule\u001b[39m = <module 'torch' from '/usr/local/lib/python3.12/site-packages/torch/__init__.py'>\n",
       "\u001b[36minputs\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = tensor([[0.4300, 0.1500, 0.8900],\n",
       "        [0.5500, 0.8700, 0.6600],\n",
       "        [0.5700, 0.8500, 0.6400],\n",
       "        [0.2200, 0.5800, 0.3300],\n",
       "        [0.7700, 0.2500, 0.1000],\n",
       "        [0.0500, 0.8000, 0.5500]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import me.shadaj.scalapy.py\n",
    "import py.SeqConverters\n",
    "\n",
    "val torch = py.module(\"torch\")\n",
    "\n",
    "val inputs = torch.tensor(\n",
    "  Seq(\n",
    "    Seq(0.43, 0.15, 0.89), // word1\n",
    "    Seq(0.55, 0.87, 0.66), // word2\n",
    "    Seq(0.57, 0.85, 0.64), // word3\n",
    "    Seq(0.22, 0.58, 0.33), // word4\n",
    "    Seq(0.77, 0.25, 0.10), // word5\n",
    "    Seq(0.05, 0.80, 0.55)  // word6\n",
    "  ).toPythonProxy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6227db2f-bd46-4436-ad67-dafd35a25c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mpy.PyQuote\u001b[39m\n",
       "\u001b[36mattentionScores\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import py.PyQuote\n",
    "\n",
    "val attentionScores = py\"$inputs @ $inputs.T\"\n",
    "println(attentionScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad86a2e-f634-4b62-9d87-46225fd8d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mattentionWeights\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val attentionWeights = torch.softmax(attentionScores, dim = -1)\n",
    "println(attentionWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52b98dfb-d6de-4dc4-95ba-7f357624871a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcontextVectors\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val contextVectors = py\"$attentionWeights @ $inputs\"\n",
    "println(contextVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bce060a7-571a-4bb0-a9f9-d8fbbf2502ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mTorchTensor\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mSelfAttentionV1\u001b[39m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Workaround to define a class that inherits from a Python class\n",
    "py.exec {\n",
    "  s\"\"\"import torch.nn as nn\n",
    "     |\n",
    "     |class SelfAttention(nn.Module):\n",
    "     |  def __init__(self, forward_method):\n",
    "     |    super().__init__()\n",
    "     |    self.forward_method = forward_method\n",
    "     |  \n",
    "     |  def forward(self, inputs):\n",
    "     |    return self.forward_method(inputs)\n",
    "     |\"\"\".stripMargin\n",
    "}\n",
    "type TorchTensor = py.Dynamic\n",
    "def SelfAttentionV1(\n",
    "  inputDimension: Int,\n",
    "  outputDimension: Int\n",
    "): py.Dynamic = {\n",
    "  val weightsQuery = torch.nn.Parameter(torch.rand(inputDimension, outputDimension))\n",
    "  val weightsKey = torch.nn.Parameter(torch.rand(inputDimension, outputDimension))\n",
    "  val weightsValue = torch.nn.Parameter(torch.rand(inputDimension, outputDimension))\n",
    "  val forwardMethod = (inputs: TorchTensor) => {\n",
    "    val queries = py\"$inputs @ $weightsQuery\"\n",
    "    val keys = py\"$inputs @ $weightsKey\"\n",
    "    val values = py\"$inputs @ $weightsValue\"\n",
    "    val attentionScores = py\"$queries @ $keys.T\"\n",
    "    val attentionWeights = torch.softmax(py\"$attentionScores / $outputDimension**0.5\", dim = -1)\n",
    "    py\"$attentionWeights @ $values\"\n",
    "  }\n",
    "  py.Dynamic.global.SelfAttention(forwardMethod)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48f9887e-2dcf-46a9-bbb5-0918e26aa9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres29_0\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xfffeb3d798f0>\n",
       "\u001b[36mselfAttentionV1\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = SelfAttention()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "val selfAttentionV1 = SelfAttentionV1(inputDimension = inputs.shape.bracketAccess(1).as[Int], outputDimension = 2)\n",
    "println(selfAttentionV1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75391d89-b663-4ff6-9946-3e28e9f340d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mSelfAttentionV2\u001b[39m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SelfAttentionV2(\n",
    "  inputDimension: Int,\n",
    "  outputDimension: Int\n",
    "): py.Dynamic = {\n",
    "  val weightsQuery = torch.nn.Linear(inputDimension, outputDimension, bias = false)\n",
    "  val weightsKey = torch.nn.Linear(inputDimension, outputDimension, bias = false)\n",
    "  val weightsValue = torch.nn.Linear(inputDimension, outputDimension, bias = false)\n",
    "  val forwardMethod = (inputs: TorchTensor) => {\n",
    "    val queries = weightsQuery(inputs)\n",
    "    val keys = weightsKey(inputs)\n",
    "    val values = weightsValue(inputs)\n",
    "    val attentionScores = py\"$queries @ $keys.T\"\n",
    "    val attentionWeights = torch.softmax(py\"$attentionScores / $outputDimension**0.5\", dim = -1)\n",
    "    py\"$attentionWeights @ $values\"\n",
    "  }\n",
    "  py.Dynamic.global.SelfAttentionV1(forwardMethod)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a9e8578-2cd4-4c2f-adc0-064fbb0849e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres31_0\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = <torch._C.Generator object at 0xfffeb3d798f0>\n",
       "\u001b[36mselfAttentionV2\u001b[39m: \u001b[32mpy\u001b[39m.\u001b[32mDynamic\u001b[39m = SelfAttentionV1()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "val selfAttentionV2 = SelfAttentionV2(inputDimension = inputs.shape.bracketAccess(1).as[Int], outputDimension = 2)\n",
    "println(selfAttentionV2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19173e51-51f8-4afd-b467-152c4cffd9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13.14",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
